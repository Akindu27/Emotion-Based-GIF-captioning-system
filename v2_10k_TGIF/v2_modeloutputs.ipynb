{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNybpYrRVB7vs4nRoMmMvmd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0be65ad88df643b8a61e9d335ea70da0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2405c36847a6402095d92927f6594778","IPY_MODEL_0c5d93c7091747d686ae5739d4bd5ca9","IPY_MODEL_5a9a9509dc0c4f07a47f6e2c0e784c58"],"layout":"IPY_MODEL_40c6469e79164c828606186993802bd9"}},"2405c36847a6402095d92927f6594778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_131a457237d64d758f1b0b9cc85815fb","placeholder":"​","style":"IPY_MODEL_d1e7e82e21784ec59f952b4906cf62e7","value":"preprocessor_config.json: 100%"}},"0c5d93c7091747d686ae5739d4bd5ca9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_22658ebd89c8457092c1ebffc99ec90d","max":271,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7e5b9e2d504639ab5b49373c9b9d2a","value":271}},"5a9a9509dc0c4f07a47f6e2c0e784c58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02aa23334ed2433ea2b681fb327b7715","placeholder":"​","style":"IPY_MODEL_4fc1d1e1783e4508bce675b9255e6363","value":" 271/271 [00:00&lt;00:00, 16.4kB/s]"}},"40c6469e79164c828606186993802bd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"131a457237d64d758f1b0b9cc85815fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1e7e82e21784ec59f952b4906cf62e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22658ebd89c8457092c1ebffc99ec90d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f7e5b9e2d504639ab5b49373c9b9d2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02aa23334ed2433ea2b681fb327b7715":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fc1d1e1783e4508bce675b9255e6363":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eca090f148b040cbb6651480be0bd3a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbe1e7fefd5a4ff69a9bf8a8c15b2e0b","IPY_MODEL_4994acc92aea4d4e994780d15abcb32a","IPY_MODEL_1d85a5ef953b4e8a849972687a18a585"],"layout":"IPY_MODEL_e8d9fef642a9460d8c49a5546ff1aa32"}},"fbe1e7fefd5a4ff69a9bf8a8c15b2e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8608194981b4f66acdd6feea4cfb127","placeholder":"​","style":"IPY_MODEL_3a029921117b41a08f904f60b06d2936","value":"config.json: 100%"}},"4994acc92aea4d4e994780d15abcb32a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6dff860872f4ddfac04ae1c52099339","max":725,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62584f343bed44ee821989dd77ef3079","value":725}},"1d85a5ef953b4e8a849972687a18a585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88a1c8e016be461a92d429992ecc42bb","placeholder":"​","style":"IPY_MODEL_6bd8f016766d4a21a5e9476518c63532","value":" 725/725 [00:00&lt;00:00, 49.5kB/s]"}},"e8d9fef642a9460d8c49a5546ff1aa32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8608194981b4f66acdd6feea4cfb127":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a029921117b41a08f904f60b06d2936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6dff860872f4ddfac04ae1c52099339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62584f343bed44ee821989dd77ef3079":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88a1c8e016be461a92d429992ecc42bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bd8f016766d4a21a5e9476518c63532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08c1e904a79543cd85c41a1f3e363ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6c937205efc43d3ab6d0bdb9f16e067","IPY_MODEL_c6a1d3ff4d744f8c8244ba63f1c6a983","IPY_MODEL_54b8830cafb04362a1102ea4087e02c4"],"layout":"IPY_MODEL_413526f013014c21a8b9cca7ff4822c0"}},"f6c937205efc43d3ab6d0bdb9f16e067":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab3378eacd234375984019afec6946e7","placeholder":"​","style":"IPY_MODEL_bdbb74e49469407fbef2fa112373d940","value":"model.safetensors: 100%"}},"c6a1d3ff4d744f8c8244ba63f1c6a983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c607837ecdc149b18fb6f510d80eaa2d","max":376873760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_697cf2c52c164223a2a743a61cc8f9e2","value":376873760}},"54b8830cafb04362a1102ea4087e02c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b341b50e7c05461a92ee7f1bef4fe1fb","placeholder":"​","style":"IPY_MODEL_f0e3eb7a9d7e42789617d10807950c43","value":" 377M/377M [00:07&lt;00:00, 39.9MB/s]"}},"413526f013014c21a8b9cca7ff4822c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3378eacd234375984019afec6946e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdbb74e49469407fbef2fa112373d940":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c607837ecdc149b18fb6f510d80eaa2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"697cf2c52c164223a2a743a61cc8f9e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b341b50e7c05461a92ee7f1bef4fe1fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0e3eb7a9d7e42789617d10807950c43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"365f622af0174edab47693af03dfb98c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d36fe3260694751a9a1e4d789f1d453","IPY_MODEL_7ef9174fa7514e7e90eb8f0fe4bf70b0","IPY_MODEL_93fea6af6f6b4299a3e9ac94dbc1a664"],"layout":"IPY_MODEL_b1cd510b9c1245ab8c2480408a1fe24f"}},"4d36fe3260694751a9a1e4d789f1d453":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e8bcdff0b344e00b7a83b9074c761a1","placeholder":"​","style":"IPY_MODEL_2e0047a0d35b4db3bc5dfc1acec4579e","value":"preprocessor_config.json: 100%"}},"7ef9174fa7514e7e90eb8f0fe4bf70b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15aaded6409d422e8b9ead6b4a33113c","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_768ef16e67b94ed4add954cee51f7a46","value":160}},"93fea6af6f6b4299a3e9ac94dbc1a664":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37ff53a42de7404ab5fa10ad58ab6326","placeholder":"​","style":"IPY_MODEL_4ad9e02280bb46ce96bd7eb80d7f66f5","value":" 160/160 [00:00&lt;00:00, 12.6kB/s]"}},"b1cd510b9c1245ab8c2480408a1fe24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e8bcdff0b344e00b7a83b9074c761a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0047a0d35b4db3bc5dfc1acec4579e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15aaded6409d422e8b9ead6b4a33113c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"768ef16e67b94ed4add954cee51f7a46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37ff53a42de7404ab5fa10ad58ab6326":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ad9e02280bb46ce96bd7eb80d7f66f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip uninstall -y transformers accelerate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMKnP_cJYAyW","executionInfo":{"status":"ok","timestamp":1768794630099,"user_tz":-330,"elapsed":2607,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"34864f18-7025-48b9-c5a1-709f82501c11"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: transformers 4.57.3\n","Uninstalling transformers-4.57.3:\n","  Successfully uninstalled transformers-4.57.3\n","Found existing installation: accelerate 1.12.0\n","Uninstalling accelerate-1.12.0:\n","  Successfully uninstalled accelerate-1.12.0\n"]}]},{"cell_type":"code","source":["!pip install transformers==4.38.2 accelerate==0.27.2\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":914},"id":"OATNlnvBYBeS","executionInfo":{"status":"ok","timestamp":1768794667655,"user_tz":-330,"elapsed":31796,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"bc27d72e-c26f-46f2-ec6d-315f99a431e2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.38.2\n","  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/130.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.27.2\n","  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2.32.4)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n","  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.27.2) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.27.2) (2.9.0+cpu)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.6)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (2026.1.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.3)\n","Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, accelerate, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.2\n","    Uninstalling tokenizers-0.22.2:\n","      Successfully uninstalled tokenizers-0.22.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.2.0 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.27.2 tokenizers-0.15.2 transformers-4.38.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tokenizers","transformers"]},"id":"6e49a98ea49f4a4ab2ad120ce6356c8d"}},"metadata":{}}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMfglOL4W3fr","executionInfo":{"status":"ok","timestamp":1768794685431,"user_tz":-330,"elapsed":7169,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"5467b187-ce60-4ce4-ab7f-0189650c6056"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import torch\n","import torch.nn as nn\n","import os\n","from google.colab import drive\n","\n","# Mount Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# --- CONFIGURATION ---\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","FEATURE_DIR = \"/content/drive/MyDrive/FYP_Full_Project/features\"\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import GPT2LMHeadModel\n","\n","class VideoGPT2Captioner(nn.Module):\n","    def __init__(self, visual_dim=2304, gpt2_dim=768, prefix_len=5):\n","        super().__init__()\n","\n","        self.prefix_len = prefix_len\n","        self.gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","        # Visual → GPT2 space (multi-token)\n","        self.projection = nn.Sequential(\n","            nn.Linear(visual_dim, gpt2_dim * prefix_len),\n","            nn.LayerNorm(gpt2_dim * prefix_len)\n","        )\n","\n","        # Learned start token (VERY important)\n","        self.start_token = nn.Parameter(torch.randn(1, 1, gpt2_dim))\n","\n","    def encode_visual(self, visual_features):\n","        \"\"\"\n","        visual_features: [B, 2304]\n","        returns: [B, prefix_len+1, 768]\n","        \"\"\"\n","        B = visual_features.size(0)\n","\n","        proj = self.projection(visual_features)\n","        prefix = proj.view(B, self.prefix_len, 768)\n","\n","        start = self.start_token.expand(B, -1, -1)\n","        return torch.cat([start, prefix], dim=1)\n"],"metadata":{"id":"j-McpUggW4Xe","executionInfo":{"status":"ok","timestamp":1768796798600,"user_tz":-330,"elapsed":67,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","TEST_CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\"\n","df = pd.read_csv(TEST_CSV_PATH)\n","print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldAP2letW_VU","executionInfo":{"status":"ok","timestamp":1768794719209,"user_tz":-330,"elapsed":1551,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"0e8b59ff-8f9d-4a5d-d945-ca85c815798e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['path', 'caption', 'gif_id'], dtype='object')\n"]}]},{"cell_type":"code","source":["GIF_DIR = \"/content/drive/MyDrive/FYP_Full_Project/gifs\"\n","os.makedirs(GIF_DIR, exist_ok=True)\n"],"metadata":{"id":"3WFIygBWZQrh","executionInfo":{"status":"ok","timestamp":1768794954310,"user_tz":-330,"elapsed":13,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import os\n","import requests\n","from tqdm import tqdm\n","\n","def download_gif(url, save_path):\n","    try:\n","        r = requests.get(url, timeout=20)\n","        if r.status_code == 200:\n","            with open(save_path, \"wb\") as f:\n","                f.write(r.content)\n","            return True\n","    except Exception as e:\n","        return False\n","\n","for idx, row in tqdm(df.iterrows(), total=len(df)):\n","    gif_id = row[\"gif_id\"]\n","    url = row[\"path\"]\n","\n","    save_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","\n","    if not os.path.exists(save_path):\n","        download_gif(url, save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgziTZOgZR4a","executionInfo":{"status":"ok","timestamp":1768795175156,"user_tz":-330,"elapsed":210313,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"5e7807e0-a1e0-493c-999a-97e21949d08c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [03:30<00:00,  4.76it/s]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class GifCaptionDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.df = pd.read_csv(csv_file)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        gif_id = self.df.iloc[idx][\"gif_id\"]\n","        caption = self.df.iloc[idx][\"caption\"]\n","\n","        gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","        image = Image.open(gif_path).convert(\"RGB\")\n","\n","        return {\n","            \"image\": image,      # raw PIL\n","            \"caption\": caption,\n","            \"gif_id\": gif_id\n","        }\n","\n"],"metadata":{"id":"uZTWOE11YpkC","executionInfo":{"status":"ok","timestamp":1768795890759,"user_tz":-330,"elapsed":29,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["import torchvision.transforms as T\n","\n","transform = T.Compose([\n","    T.Resize((224, 224)),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225])\n","])\n","\n","TEST_CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\"\n","\n","test_ds = GifCaptionDataset(\n","    csv_file=TEST_CSV_PATH,\n","    gif_dir=GIF_DIR,\n","    transform=transform\n",")\n","\n"],"metadata":{"id":"yvv96ezhYuRQ","executionInfo":{"status":"ok","timestamp":1768795192554,"user_tz":-330,"elapsed":28,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["sample = test_ds[0]\n","\n","print(sample[\"gif_id\"])\n","print(sample[\"image\"].shape)\n","print(sample[\"caption\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHsU0e0NYyCF","executionInfo":{"status":"ok","timestamp":1768795198006,"user_tz":-330,"elapsed":252,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"a83756cf-edb1-4ef2-97d6-fa2f37740537"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["gif_4343\n","torch.Size([3, 224, 224])\n","a man is making symbols with his hands and dancing\n"]}]},{"cell_type":"code","source":["\n","from transformers import VideoMAEModel, ViTModel, AutoImageProcessor\n","\n","# vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n","# vit.to(DEVICE)\n","# vit.eval()\n","\n","# --- A. Load Extractors ---\n","print(\"Loading Feature Extractors...\")\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["0be65ad88df643b8a61e9d335ea70da0","2405c36847a6402095d92927f6594778","0c5d93c7091747d686ae5739d4bd5ca9","5a9a9509dc0c4f07a47f6e2c0e784c58","40c6469e79164c828606186993802bd9","131a457237d64d758f1b0b9cc85815fb","d1e7e82e21784ec59f952b4906cf62e7","22658ebd89c8457092c1ebffc99ec90d","1f7e5b9e2d504639ab5b49373c9b9d2a","02aa23334ed2433ea2b681fb327b7715","4fc1d1e1783e4508bce675b9255e6363","eca090f148b040cbb6651480be0bd3a3","fbe1e7fefd5a4ff69a9bf8a8c15b2e0b","4994acc92aea4d4e994780d15abcb32a","1d85a5ef953b4e8a849972687a18a585","e8d9fef642a9460d8c49a5546ff1aa32","c8608194981b4f66acdd6feea4cfb127","3a029921117b41a08f904f60b06d2936","e6dff860872f4ddfac04ae1c52099339","62584f343bed44ee821989dd77ef3079","88a1c8e016be461a92d429992ecc42bb","6bd8f016766d4a21a5e9476518c63532","08c1e904a79543cd85c41a1f3e363ab1","f6c937205efc43d3ab6d0bdb9f16e067","c6a1d3ff4d744f8c8244ba63f1c6a983","54b8830cafb04362a1102ea4087e02c4","413526f013014c21a8b9cca7ff4822c0","ab3378eacd234375984019afec6946e7","bdbb74e49469407fbef2fa112373d940","c607837ecdc149b18fb6f510d80eaa2d","697cf2c52c164223a2a743a61cc8f9e2","b341b50e7c05461a92ee7f1bef4fe1fb","f0e3eb7a9d7e42789617d10807950c43","365f622af0174edab47693af03dfb98c","4d36fe3260694751a9a1e4d789f1d453","7ef9174fa7514e7e90eb8f0fe4bf70b0","93fea6af6f6b4299a3e9ac94dbc1a664","b1cd510b9c1245ab8c2480408a1fe24f","7e8bcdff0b344e00b7a83b9074c761a1","2e0047a0d35b4db3bc5dfc1acec4579e","15aaded6409d422e8b9ead6b4a33113c","768ef16e67b94ed4add954cee51f7a46","37ff53a42de7404ab5fa10ad58ab6326","4ad9e02280bb46ce96bd7eb80d7f66f5"]},"id":"SD6SkVHJa09K","executionInfo":{"status":"ok","timestamp":1768795753104,"user_tz":-330,"elapsed":24599,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"e4b90c38-1766-4b38-836d-b83d5f6b97b2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Feature Extractors...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0be65ad88df643b8a61e9d335ea70da0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca090f148b040cbb6651480be0bd3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/377M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c1e904a79543cd85c41a1f3e363ab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"365f622af0174edab47693af03dfb98c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from PIL import Image, ImageSequence\n","import torch\n","\n","def load_gif_frames(gif_path, num_frames=16):\n","    gif = Image.open(gif_path)\n","\n","    frames = []\n","    for frame in ImageSequence.Iterator(gif):\n","        frames.append(frame.convert(\"RGB\"))\n","\n","    # Uniform sampling\n","    if len(frames) >= num_frames:\n","        idx = torch.linspace(0, len(frames) - 1, num_frames).long()\n","        frames = [frames[i] for i in idx]\n","    else:\n","        # Pad if too short\n","        frames = frames + [frames[-1]] * (num_frames - len(frames))\n","\n","    return frames\n"],"metadata":{"id":"pTtO_zcTbT8F","executionInfo":{"status":"ok","timestamp":1768795500027,"user_tz":-330,"elapsed":13,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def extract_vit_feature(image):\n","    inputs = vit_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = vit_model(**inputs)\n","    cls_feat = outputs.last_hidden_state[:, 0, :]  # [1, 768]\n","    return cls_feat.squeeze(0)\n"],"metadata":{"id":"O43N4iIGbXSi","executionInfo":{"status":"ok","timestamp":1768795509781,"user_tz":-330,"elapsed":38,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def extract_action_feature(frames):\n","    inputs = action_proc(\n","        images=frames,\n","        return_tensors=\"pt\"\n","    ).to(DEVICE)\n","\n","    outputs = action_model(**inputs)\n","\n","    # Temporal average pooling\n","    feat = outputs.last_hidden_state.mean(dim=1)  # [1, 768]\n","    return feat.squeeze(0)\n"],"metadata":{"id":"KqJJTVRVbZoi","executionInfo":{"status":"ok","timestamp":1768795518546,"user_tz":-330,"elapsed":27,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def extract_emotion_feature(image):\n","    return extract_vit_feature(image)\n"],"metadata":{"id":"hFmZFfxsbc5d","executionInfo":{"status":"ok","timestamp":1768795527132,"user_tz":-330,"elapsed":16,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def extract_visual_features(sample):\n","    image = sample[\"image\"]\n","    gif_id = sample[\"gif_id\"]\n","\n","    gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","\n","    frames = load_gif_frames(gif_path)\n","\n","    f_app = extract_vit_feature(image)\n","    f_act = extract_action_feature(frames)\n","    f_emo = extract_emotion_feature(image)\n","\n","    visual_feat = torch.cat([f_app, f_act, f_emo], dim=-1)  # [2304]\n","\n","    return visual_feat\n"],"metadata":{"id":"f4O3G_TBbfio","executionInfo":{"status":"ok","timestamp":1768795764950,"user_tz":-330,"elapsed":43,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = VideoGPT2Captioner(\n","    visual_dim=2304,\n","    prefix_len=5\n",").to(DEVICE)\n","\n","checkpoint_path = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","state = torch.load(checkpoint_path, map_location=DEVICE)\n","\n","# This is OK even if the old model didn't have start_token\n","model.load_state_dict(state, strict=False)\n","\n","model.eval()\n","print(\"✅ Model loaded successfully\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1oO6MFPXIFX","executionInfo":{"status":"ok","timestamp":1768796809535,"user_tz":-330,"elapsed":5560,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"cb33a42e-69a3-44b2-e6f4-c05da3e45ecb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model loaded successfully\n"]}]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate_caption(model, visual_feat):\n","    \"\"\"\n","    visual_feat: [2304] tensor\n","    \"\"\"\n","\n","    model.eval()\n","\n","    visual_feat = visual_feat.unsqueeze(0).to(DEVICE)\n","\n","    # Encode visual prefix\n","    prefix_embeds = model.encode_visual(visual_feat)\n","\n","    prefix_len = prefix_embeds.size(1)\n","    attention_mask = torch.ones((1, prefix_len), device=DEVICE)\n","\n","    output_ids = model.gpt2.generate(\n","        inputs_embeds=prefix_embeds,\n","        attention_mask=attention_mask,\n","\n","        max_new_tokens=20,\n","\n","        # 🔒 ALIGNMENT SETTINGS (IMPORTANT)\n","        do_sample=False,       # ❌ no sampling\n","        num_beams=3,           # ✅ beam search\n","        repetition_penalty=1.8,\n","\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"],"metadata":{"id":"5c5TlvJyXZDH","executionInfo":{"status":"ok","timestamp":1768795572307,"user_tz":-330,"elapsed":10,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(\"🎬 FINAL MODEL OUTPUTS\\n\")\n","\n","for i in [0, 50, 100]:\n","    sample = test_ds[i]\n","\n","    visual_feat = extract_visual_features(sample)\n","    pred = generate_caption(model, visual_feat)\n","\n","    print(f\"Sample {i} | GIF: {sample['gif_id']}\")\n","    print(\"GT :\", sample[\"caption\"])\n","    print(\"PR :\", pred)\n","    print(\"-\" * 60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"TtIKupEiblGn","executionInfo":{"status":"error","timestamp":1768795772701,"user_tz":-330,"elapsed":251,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"2f4b231f-42e3-49cc-d331-f9feacabd2f7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["🎬 FINAL MODEL OUTPUTS\n","\n"]},{"output_type":"error","ename":"ValueError","evalue":"The image to be converted to a PIL image contains values outside the range [0, 1], got [-1.878157377243042, 2.640000104904175] which cannot be converted to uint8.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2713298850.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvisual_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_visual_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2333176043.py\u001b[0m in \u001b[0;36mextract_visual_features\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gif_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgif_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_vit_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mf_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_action_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mf_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_emotion_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3920716592.py\u001b[0m in \u001b[0;36mextract_vit_feature\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_vit_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcls_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [1, 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;34m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/vit/image_processing_vit.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_resize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             images = [\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/vit/image_processing_vit.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, image, size, resample, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The `size` dictionary must contain the keys `height` and `width`. Got {size.keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         return resize(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, size, resample, reducing_gap, data_format, return_numpy, input_data_format)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mdo_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mdo_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rescale_for_pil_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_rescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_rescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m_rescale_for_pil_conversion\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mdo_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;34m\"The image to be converted to a PIL image contains values outside the range [0, 1], \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;34mf\"got [{image.min()}, {image.max()}] which cannot be converted to uint8.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The image to be converted to a PIL image contains values outside the range [0, 1], got [-1.878157377243042, 2.640000104904175] which cannot be converted to uint8."]}]},{"cell_type":"code","source":["print(\"🎬 FINAL MODEL OUTPUTS\\n\")\n","\n","for i in [0, 50, 100]:\n","    sample = test_ds[i]\n","\n","    image = sample[\"image\"]\n","    gt_caption = sample[\"caption\"]\n","\n","    visual_feat = extract_visual_features(image)\n","\n","    pred = generate_caption(model, visual_feat)\n","\n","    print(f\"Sample {i}\")\n","    print(\"GT :\", gt_caption)\n","    print(\"PR :\", pred)\n","    print(\"-\" * 50)\n","\n"],"metadata":{"id":"z1E3AUPCXaG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image, ImageSequence\n","from transformers import AutoImageProcessor, ViTModel, VideoMAEModel, GPT2Tokenizer\n","\n","# -------------------\n","# 1️⃣ Setup\n","# -------------------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","GIF_DIR = \"/content/drive/MyDrive/FYP_Full_Project/gifs\"\n","TEST_CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\"\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","\n","# -------------------\n","# 2️⃣ Load Feature Extractors\n","# -------------------\n","print(\"Loading Feature Extractors...\")\n","\n","# Action/Video features\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","# Appearance features\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","# -------------------\n","# 3️⃣ Load Caption Model & Tokenizer\n","# -------------------\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = VideoGPT2Captioner(\n","    visual_dim=2304,\n","    prefix_len=5\n",").to(DEVICE)\n","\n","state = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","print(\"✅ Caption model loaded successfully\")\n","\n","# -------------------\n","# 4️⃣ Dataset\n","# -------------------\n","import pandas as pd\n","\n","class GifCaptionDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.df = pd.read_csv(csv_file)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        gif_id = self.df.iloc[idx][\"gif_id\"]\n","        caption = self.df.iloc[idx][\"caption\"]\n","        gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","        image = Image.open(gif_path).convert(\"RGB\")\n","        return {\n","            \"image\": image,     # raw PIL image\n","            \"caption\": caption,\n","            \"gif_id\": gif_id\n","        }\n","\n","test_ds = GifCaptionDataset(TEST_CSV_PATH)\n","\n","# -------------------\n","# 5️⃣ Helper Functions\n","# -------------------\n","# Load multiple frames from a GIF\n","def load_gif_frames(gif_path, num_frames=16):\n","    gif = Image.open(gif_path)\n","    frames = [frame.convert(\"RGB\") for frame in ImageSequence.Iterator(gif)]\n","\n","    # Uniform sampling / padding\n","    if len(frames) >= num_frames:\n","        idx = torch.linspace(0, len(frames) - 1, num_frames).long()\n","        frames = [frames[i] for i in idx]\n","    else:\n","        frames = frames + [frames[-1]] * (num_frames - len(frames))\n","\n","    return frames\n","\n","# Extract ViT feature (appearance)\n","@torch.no_grad()\n","def extract_vit_feature(image):\n","    inputs = vit_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = vit_model(**inputs)\n","    cls_feat = outputs.last_hidden_state[:, 0, :]\n","    return cls_feat.squeeze(0)\n","\n","# Extract VideoMAE feature (action)\n","@torch.no_grad()\n","def extract_action_feature(frames):\n","    inputs = action_proc(images=frames, return_tensors=\"pt\").to(DEVICE)\n","    outputs = action_model(**inputs)\n","    feat = outputs.last_hidden_state.mean(dim=1)\n","    return feat.squeeze(0)\n","\n","# Extract emotion feature (placeholder, optional)\n","def extract_emotion_feature(image):\n","    return extract_vit_feature(image)\n","\n","# Fuse features to 2304-dim\n","def extract_visual_features(sample):\n","    image = sample[\"image\"]\n","    gif_id = sample[\"gif_id\"]\n","    gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","\n","    frames = load_gif_frames(gif_path)\n","\n","    f_app = extract_vit_feature(image)\n","    f_act = extract_action_feature(frames)\n","    f_emo = extract_emotion_feature(image)\n","\n","    visual_feat = torch.cat([f_app, f_act, f_emo], dim=-1)  # [2304]\n","    return visual_feat\n","\n","# -------------------\n","# 6️⃣ Caption Generation\n","# -------------------\n","@torch.no_grad()\n","def generate_caption(model, visual_feat, max_len=20):\n","    visual_feat = visual_feat.unsqueeze(0).to(DEVICE)\n","    prefix_embeds = model.encode_visual(visual_feat)\n","    prefix_len = prefix_embeds.size(1)\n","    attention_mask = torch.ones((1, prefix_len), device=DEVICE)\n","\n","    output_ids = model.gpt2.generate(\n","        inputs_embeds=prefix_embeds,\n","        attention_mask=attention_mask,\n","        max_new_tokens=max_len,\n","        do_sample=False,\n","        num_beams=3,\n","        repetition_penalty=1.8,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# -------------------\n","# 7️⃣ Run Inference\n","# -------------------\n","print(\"🎬 Running Inference...\\n\")\n","\n","for i in [0, 50, 100]:  # sample indices\n","    sample = test_ds[i]\n","    visual_feat = extract_visual_features(sample)\n","    pred = generate_caption(model, visual_feat)\n","\n","    print(f\"Sample {i} | GIF: {sample['gif_id']}\")\n","    print(\"GT :\", sample[\"caption\"])\n","    print(\"PR :\", pred)\n","    print(\"-\" * 60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NKhmWkTdHhS","executionInfo":{"status":"ok","timestamp":1768796183314,"user_tz":-330,"elapsed":68560,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"1abecb95-9c04-4588-b443-8b83adcef3b0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"]},{"output_type":"stream","name":"stdout","text":["Loading Feature Extractors...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Caption model loaded successfully\n","🎬 Running Inference...\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n","  return torch.tensor(value)\n"]},{"output_type":"stream","name":"stdout","text":["Sample 0 | GIF: gif_4343\n","GT : a man is making symbols with his hands and dancing\n","PR : a man in a white shirt and black hat is smiling.\n","------------------------------------------------------------\n","Sample 50 | GIF: gif_5044\n","GT : two men in front of microphones are nodding at each other.\n","PR : a man is talking to a woman and she smiles at him.\n","------------------------------------------------------------\n","Sample 100 | GIF: gif_248\n","GT : woman with in black outfit poses and blinks.\n","PR : a man is talking to a woman and she is smiling.\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image, ImageSequence\n","from transformers import (\n","    AutoImageProcessor,\n","    ViTModel,\n","    VideoMAEModel,\n","    GPT2Tokenizer,\n","    AutoFeatureExtractor,\n","    AutoModel\n",")\n","\n","# -------------------\n","# 1️⃣ Setup\n","# -------------------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","GIF_DIR = \"/content/drive/MyDrive/FYP_Full_Project/gifs\"\n","TEST_CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\"\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","\n","# -------------------\n","# 2️⃣ Load Feature Extractors\n","# -------------------\n","print(\"Loading Feature Extractors...\")\n","\n","# Appearance features (ViT)\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","# Action features (VideoMAE)\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","# Emotion features (example: FER+ pre-trained)\n","emotion_proc = AutoFeatureExtractor.from_pretrained(\"nateraw/ferplus\")  # placeholder\n","emotion_model = AutoModel.from_pretrained(\"nateraw/ferplus\").to(DEVICE).eval()\n","\n","# -------------------\n","# 3️⃣ Load Caption Model & Tokenizer\n","# -------------------\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = VideoGPT2Captioner(\n","    visual_dim=2304 + 128,  # 2304 + emotion embedding dim\n","    prefix_len=5\n",").to(DEVICE)\n","\n","state = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","print(\"✅ Caption model loaded successfully\")\n","\n","# -------------------\n","# 4️⃣ Dataset\n","# -------------------\n","import pandas as pd\n","\n","class GifCaptionDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.df = pd.read_csv(csv_file)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        gif_id = self.df.iloc[idx][\"gif_id\"]\n","        caption = self.df.iloc[idx][\"caption\"]\n","        gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","        image = Image.open(gif_path).convert(\"RGB\")\n","        return {\n","            \"image\": image,\n","            \"caption\": caption,\n","            \"gif_id\": gif_id\n","        }\n","\n","test_ds = GifCaptionDataset(TEST_CSV_PATH)\n","\n","# -------------------\n","# 5️⃣ Helper Functions\n","# -------------------\n","\n","def load_gif_frames(gif_path, num_frames=16):\n","    gif = Image.open(gif_path)\n","    frames = [frame.convert(\"RGB\") for frame in ImageSequence.Iterator(gif)]\n","\n","    # Uniform sampling / padding\n","    if len(frames) >= num_frames:\n","        idx = torch.linspace(0, len(frames) - 1, num_frames).long()\n","        frames = [frames[i] for i in idx]\n","    else:\n","        frames = frames + [frames[-1]] * (num_frames - len(frames))\n","\n","    return frames\n","\n","# Appearance feature\n","@torch.no_grad()\n","def extract_vit_feature(image):\n","    inputs = vit_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = vit_model(**inputs)\n","    cls_feat = outputs.last_hidden_state[:, 0, :]\n","    return cls_feat.squeeze(0)\n","\n","# Action feature\n","@torch.no_grad()\n","def extract_action_feature(frames):\n","    inputs = action_proc(images=frames, return_tensors=\"pt\").to(DEVICE)\n","    outputs = action_model(**inputs)\n","    feat = outputs.last_hidden_state.mean(dim=1)\n","    return feat.squeeze(0)\n","\n","# Emotion feature\n","@torch.no_grad()\n","def extract_emotion_feature(image):\n","    inputs = emotion_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = emotion_model(**inputs)\n","    feat = outputs.last_hidden_state.mean(dim=1)\n","    return feat.squeeze(0)\n","\n","# Fuse all features\n","def extract_visual_features(sample):\n","    image = sample[\"image\"]\n","    gif_id = sample[\"gif_id\"]\n","    gif_path = os.path.join(GIF_DIR, f\"{gif_id}.gif\")\n","\n","    frames = load_gif_frames(gif_path)\n","\n","    f_app = extract_vit_feature(image)\n","    f_act = extract_action_feature(frames)\n","    f_emo = extract_emotion_feature(image)  # real emotion embedding\n","\n","    visual_feat = torch.cat([f_app, f_act, f_emo], dim=-1)\n","    return visual_feat\n","\n","# -------------------\n","# 6️⃣ Caption Generation\n","# -------------------\n","@torch.no_grad()\n","def generate_caption(model, visual_feat, max_len=20):\n","    visual_feat = visual_feat.unsqueeze(0).to(DEVICE)\n","    prefix_embeds = model.encode_visual(visual_feat)\n","    prefix_len = prefix_embeds.size(1)\n","    attention_mask = torch.ones((1, prefix_len), device=DEVICE)\n","\n","    output_ids = model.gpt2.generate(\n","        inputs_embeds=prefix_embeds,\n","        attention_mask=attention_mask,\n","        max_new_tokens=max_len,\n","        do_sample=False,\n","        num_beams=5,  # more beams -> better predictions\n","        repetition_penalty=1.8,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# -------------------\n","# 7️⃣ Run Inference\n","# -------------------\n","print(\"🎬 Running Emotion-aware Inference...\\n\")\n","\n","for i in [0, 50, 100]:\n","    sample = test_ds[i]\n","    visual_feat = extract_visual_features(sample)\n","    pred = generate_caption(model, visual_feat)\n","\n","    print(f\"Sample {i} | GIF: {sample['gif_id']}\")\n","    print(\"GT :\", sample[\"caption\"])\n","    print(\"PR :\", pred)\n","    print(\"-\" * 60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":897},"id":"4sxsislHepSf","executionInfo":{"status":"error","timestamp":1768796383518,"user_tz":-330,"elapsed":8905,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"c30b757d-8593-4ecf-84b0-9c27ec1c732c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Feature Extractors...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"]},{"output_type":"error","ename":"OSError","evalue":"nateraw/ferplus is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/nateraw/ferplus/resolve/main/preprocessor_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    451\u001b[0m             )\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-696db0df-5bcd29bf1a4c0c6f1aeaeb69;9bf44d4b-e4f3-4287-aa12-28d24ecd7d62)\n\nRepository Not Found for url: https://huggingface.co/nateraw/ferplus/resolve/main/preprocessor_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2374148493.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Emotion features (example: FER+ pre-trained)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0memotion_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nateraw/ferplus\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0memotion_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nateraw/ferplus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/feature_extraction_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_extractor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0mfeature_extractor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_extractor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mfeature_extractor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/feature_extraction_utils.py\u001b[0m in \u001b[0;36mget_feature_extractor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 resolved_feature_extractor_file = cached_file(\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0mfeature_extractor_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         ) from e\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: nateraw/ferplus is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"code","source":["!pip install transformers opencv-python facenet-pytorch moviepy deepface\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xbfyyU1hbae","executionInfo":{"status":"ok","timestamp":1768797108709,"user_tz":-330,"elapsed":15439,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"6036cc8c-8d83-47c3-cece-8c2ce680a6ff"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.38.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.12/dist-packages (2.5.3)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Collecting deepface\n","  Downloading deepface-0.0.97-py3-none-any.whl.metadata (33 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (0.24.0+cpu)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (11.3.0)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.2.2)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (5.2.0)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.19.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.10.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.1.2)\n","Collecting flask-cors>=4.0.1 (from deepface)\n","  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (1.0.0)\n","Collecting retina-face>=0.0.14 (from deepface)\n","  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n","Collecting fire>=0.4.0 (from deepface)\n","  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting gunicorn>=20.1.0 (from deepface)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting lightphe>=0.0.15 (from deepface)\n","  Downloading lightphe-0.0.20-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (1.2.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.4.0->deepface) (3.3.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (8.3.1)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (4.13.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.2.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (3.15.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.18.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.5.4)\n","Requirement already satisfied: sympy>=1.12 in /usr/local/lib/python3.12/dist-packages (from lightphe>=0.0.15->deepface) (1.14.0)\n","Collecting lightecc (from lightphe>=0.0.15->deepface)\n","  Downloading lightecc-0.0.4-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.3)\n","Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (25.12.19)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.0.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.19.0)\n","Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->facenet-pytorch) (2.9.0+cpu)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision->facenet-pytorch) (3.6.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.12->lightphe>=0.0.15->deepface) (1.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (0.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.8.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n","Downloading deepface-0.0.97-py3-none-any.whl (160 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n","Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightphe-0.0.20-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n","Downloading lightecc-0.0.4-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightecc, gunicorn, fire, lightphe, flask-cors, retina-face, deepface\n","Successfully installed deepface-0.0.97 fire-0.7.1 flask-cors-6.0.2 gunicorn-23.0.0 lightecc-0.0.4 lightphe-0.0.20 retina-face-0.0.17\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoImageProcessor, ViTModel, VideoMAEModel, GPT2Tokenizer\n","import numpy as np\n","from PIL import Image, ImageSequence\n","import pandas as pd\n","import os\n","from deepface import DeepFace\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ------------------- Feature Extractors -------------------\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","# ------------------- Dataset -------------------\n","class GifCaptionDataset(torch.utils.data.Dataset):\n","    def __init__(self, csv_file, gif_dir):\n","        self.df = pd.read_csv(csv_file)\n","        self.gif_dir = gif_dir\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        gif_id = row[\"gif_id\"]\n","        caption = row[\"caption\"]\n","        gif_path = os.path.join(self.gif_dir, f\"{gif_id}.gif\")\n","        image = Image.open(gif_path).convert(\"RGB\")\n","        return {\"image\": image, \"caption\": caption, \"gif_id\": gif_id}\n","\n","# ------------------- Utilities -------------------\n","def load_gif_frames(gif_path, num_frames=16):\n","    gif = Image.open(gif_path)\n","    frames = [frame.convert(\"RGB\") for frame in ImageSequence.Iterator(gif)]\n","    if len(frames) >= num_frames:\n","        idx = torch.linspace(0, len(frames)-1, num_frames).long()\n","        frames = [frames[i] for i in idx]\n","    else:\n","        frames += [frames[-1]] * (num_frames - len(frames))\n","    return frames\n","\n","@torch.no_grad()\n","def extract_vit_feature(image):\n","    inputs = vit_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = vit_model(**inputs)\n","    return outputs.last_hidden_state[:, 0, :].squeeze(0)\n","\n","@torch.no_grad()\n","def extract_action_feature(frames):\n","    inputs = action_proc(images=frames, return_tensors=\"pt\").to(DEVICE)\n","    outputs = action_model(**inputs)\n","    return outputs.last_hidden_state.mean(dim=1).squeeze(0)\n","\n","def extract_emotion_feature(image):\n","    img_np = np.array(image)\n","    try:\n","        # Use DeepFace to predict emotions\n","        analysis = DeepFace.analyze(img_np, actions=['emotion'], enforce_detection=False)\n","        emotions = analysis['emotion']\n","        # Convert dict to tensor\n","        prob = torch.tensor(list(emotions.values()), dtype=torch.float32)\n","    except Exception:\n","        prob = torch.zeros(7)\n","        prob[0] = 1.0  # fallback neutral\n","    return prob.to(DEVICE)\n","\n","def extract_visual_features(sample):\n","    image = sample[\"image\"]\n","    gif_path = f\"/content/drive/MyDrive/FYP_Full_Project/gifs/{sample['gif_id']}.gif\"\n","    frames = load_gif_frames(gif_path)\n","    f_app = extract_vit_feature(image)\n","    f_act = extract_action_feature(frames)\n","    f_emo = extract_emotion_feature(image)\n","    return torch.cat([f_app, f_act, f_emo], dim=-1)\n","\n","# ------------------- GPT2 Caption -------------------\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = VideoGPT2Captioner(visual_dim=2304+7, prefix_len=5).to(DEVICE)\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\", map_location=DEVICE), strict=False)\n","model.eval()\n","\n","@torch.no_grad()\n","def generate_caption(model, visual_feat, max_len=20):\n","    visual_feat = visual_feat.unsqueeze(0).to(DEVICE)\n","    prefix_embeds = model.encode_visual(visual_feat)\n","    attention_mask = torch.ones((1, prefix_embeds.size(1)), device=DEVICE)\n","\n","    output_ids = model.gpt2.generate(\n","        inputs_embeds=prefix_embeds,\n","        attention_mask=attention_mask,\n","        max_new_tokens=max_len,\n","        do_sample=False,\n","        num_beams=5,\n","        repetition_penalty=1.8,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# ------------------- Run Inference -------------------\n","test_ds = GifCaptionDataset(\"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\",\n","                            \"/content/drive/MyDrive/FYP_Full_Project/gifs\")\n","\n","for i in [0, 50, 100]:\n","    sample = test_ds[i]\n","    visual_feat = extract_visual_features(sample)\n","    pred = generate_caption(model, visual_feat)\n","    print(f\"Sample {i} | GIF: {sample['gif_id']}\")\n","    print(\"GT :\", sample[\"caption\"])\n","    print(\"PR :\", pred)\n","    print(\"-\"*50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"id":"Z3YK3G3_hcTq","executionInfo":{"status":"error","timestamp":1768797203841,"user_tz":-330,"elapsed":40943,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"70922cd2-04e1-4aaa-d06b-69edaf902580"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n","Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n","To: /root/.deepface/weights/facial_expression_model_weights.h5\n"]},{"output_type":"stream","name":"stdout","text":["26-01-19 04:33:23 - 🔗 facial_expression_model_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5 to /root/.deepface/weights/facial_expression_model_weights.h5...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.98M/5.98M [00:00<00:00, 72.4MB/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (1x1543 and 2311x3840)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-988044248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mvisual_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_visual_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sample {i} | GIF: {sample['gif_id']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GT :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caption\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-988044248.py\u001b[0m in \u001b[0;36mgenerate_caption\u001b[0;34m(model, visual_feat, max_len)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mvisual_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisual_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mprefix_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_visual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1483622630.py\u001b[0m in \u001b[0;36mencode_visual\u001b[0;34m(self, visual_features)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1543 and 2311x3840)"]}]},{"cell_type":"code","source":["# ----------------------------\n","# 1️⃣ Imports & Device Setup\n","# ----------------------------\n","import torch\n","import torch.nn as nn\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import ViTModel, ViTFeatureExtractor\n","from transformers import VideoMAEModel, VideoMAEFeatureExtractor\n","from fer import FER\n","import cv2\n","import numpy as np\n","from PIL import Image\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ----------------------------\n","# 2️⃣ Load GPT2 tokenizer & trained model\n","# ----------------------------\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# This class must match what you trained\n","class VideoGPT2Captioner(nn.Module):\n","    def __init__(self, visual_dim=2304, prefix_len=5):\n","        super().__init__()\n","        self.gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","        self.visual_proj = nn.Linear(visual_dim, self.gpt2.config.n_embd)\n","        self.prefix_len = prefix_len\n","\n","    def forward(self, visual_feat, input_ids=None):\n","        # Project visual features to GPT2 embeddings\n","        prefix_emb = self.visual_proj(visual_feat).unsqueeze(1)  # (B, 1, n_embd)\n","        batch_size = prefix_emb.shape[0]\n","\n","        # Create dummy input for GPT2 if none provided\n","        if input_ids is None:\n","            input_ids = torch.full(\n","                (batch_size, 1), tokenizer.pad_token_id, dtype=torch.long\n","            ).to(DEVICE)\n","\n","        # Embed input_ids\n","        inputs_embeds = self.gpt2.transformer.wte(input_ids)\n","        # Concatenate visual prefix\n","        inputs_embeds = torch.cat([prefix_emb, inputs_embeds], dim=1)\n","        outputs = self.gpt2(inputs_embeds=inputs_embeds)\n","        return outputs\n","\n","# Load trained model\n","model = VideoGPT2Captioner(visual_dim=2304, prefix_len=5).to(DEVICE)\n","checkpoint_path = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","state = torch.load(checkpoint_path, map_location=DEVICE)\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","print(\"✅ GPT2 trained captioner loaded successfully\")\n","\n","# ----------------------------\n","# 3️⃣ Load Visual Feature Extractors\n","# ----------------------------\n","print(\"Loading ViT (frame-level visual features)...\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE)\n","vit_model.eval()\n","vit_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n","\n","print(\"Loading VideoMAE (temporal motion features)...\")\n","videomae_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE)\n","videomae_model.eval()\n","videomae_extractor = VideoMAEFeatureExtractor.from_pretrained(\"MCG-NJU/videomae-base\")\n","\n","# ----------------------------\n","# 4️⃣ Load Emotion Detector\n","# ----------------------------\n","print(\"Loading FER (emotion features)...\")\n","fer_detector = FER(mtcnn=False)  # works with numpy images\n","\n","# ----------------------------\n","# 5️⃣ Helper Functions\n","# ----------------------------\n","\n","def extract_visual_features(sample_frames):\n","    \"\"\"\n","    Input: list of frames (H x W x C)\n","    Output: concatenated ViT + VideoMAE features\n","    \"\"\"\n","    # ViT features (frame-level)\n","    vit_feats = []\n","    for frame in sample_frames:\n","        frame_pil = Image.fromarray(frame)\n","        inputs = vit_extractor(images=frame_pil, return_tensors=\"pt\").to(DEVICE)\n","        with torch.no_grad():\n","            feat = vit_model(**inputs).last_hidden_state[:, 0, :]  # CLS token\n","        vit_feats.append(feat)\n","    vit_feats = torch.stack(vit_feats).mean(0)  # average over frames\n","\n","    # VideoMAE features (temporal)\n","    video_input = videomae_extractor(\n","        sample_frames, return_tensors=\"pt\", do_normalize=True\n","    ).pixel_values.to(DEVICE)  # shape: (B, C, T, H, W)\n","    with torch.no_grad():\n","        vid_feat = videomae_model(video_input).last_hidden_state.mean(1)  # mean pooling\n","    vid_feat = vid_feat.squeeze(0)\n","\n","    # Concatenate ViT + VideoMAE features\n","    visual_feat = torch.cat([vit_feats, vid_feat], dim=-1)\n","    return visual_feat\n","\n","def extract_emotion_features(frame):\n","    \"\"\"\n","    Returns a vector of emotion probabilities\n","    \"\"\"\n","    emotions = fer_detector.detect_emotions(frame)\n","    if emotions:\n","        return torch.tensor(list(emotions[0][\"emotions\"].values()), dtype=torch.float32).to(DEVICE)\n","    else:\n","        return torch.zeros(7).to(DEVICE)  # 7 emotion classes\n","\n","def fuse_visual_emotion(visual_feat, emotion_feat):\n","    \"\"\"\n","    Simple concatenation fusion of visual and emotion features\n","    \"\"\"\n","    return torch.cat([visual_feat, emotion_feat], dim=-1)\n","\n","def generate_caption(model, fused_feat, max_len=30):\n","    \"\"\"\n","    Generate a caption from fused visual+emotion features\n","    \"\"\"\n","    model.eval()\n","    input_ids = torch.full((1, 1), tokenizer.pad_token_id, dtype=torch.long).to(DEVICE)\n","    generated = input_ids\n","    for _ in range(max_len):\n","        outputs = model(fused_feat.unsqueeze(0), generated)\n","        next_token = outputs.logits[:, -1, :].argmax(-1)\n","        generated = torch.cat([generated, next_token.unsqueeze(0)], dim=1)\n","        if next_token.item() == tokenizer.eos_token_id:\n","            break\n","    caption = tokenizer.decode(generated.squeeze().tolist(), skip_special_tokens=True)\n","    return caption\n","\n","# ----------------------------\n","# 6️⃣ Example Usage\n","# ----------------------------\n","# Sample GIF/Video frames as numpy arrays (H x W x C)\n","# For example, frames = [frame0, frame1, frame2, ...]\n","# Here you can extract frames using cv2.VideoCapture for GIF/MP4\n","\n","frames = []  # TODO: load your video frames here as numpy arrays\n","if len(frames) == 0:\n","    print(\"⚠️ No frames loaded! Please provide frames from a video/GIF.\")\n","\n","# Example with first frame for emotion\n","if len(frames) > 0:\n","    emotion_feat = extract_emotion_features(frames[0])\n","    visual_feat = extract_visual_features(frames)\n","    fused_feat = fuse_visual_emotion(visual_feat, emotion_feat)\n","    caption = generate_caption(model, fused_feat)\n","    print(\"🎬 Generated caption (emotion-aware):\", caption)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xPevBP7mzHn","executionInfo":{"status":"ok","timestamp":1768798515522,"user_tz":-330,"elapsed":13136,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"13c4097f-abd3-46ba-e812-c84854e81965"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ GPT2 trained captioner loaded successfully\n","Loading ViT (frame-level visual features)...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loading VideoMAE (temporal motion features)...\n","Loading FER (emotion features)...\n","⚠️ No frames loaded! Please provide frames from a video/GIF.\n"]}]},{"cell_type":"code","source":["# ==========================================\n","# Emotion-aware GIF/Video Captioning Pipeline\n","# ==========================================\n","\n","# 1️⃣ Install dependencies (run once)\n","!pip install torch torchvision transformers opencv-python pillow facenet-pytorch fer\n","\n","# 2️⃣ Imports\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","from transformers import ViTModel, VideoMAEModel, GPT2Tokenizer\n","from fer import FER\n","from PIL import Image, ImageSequence\n","import numpy as np\n","import cv2\n","\n","# 3️⃣ Device & tokenizer\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# 4️⃣ Load feature models\n","print(\"Loading ViT...\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE)\n","vit_model.eval()\n","\n","print(\"Loading VideoMAE...\")\n","videomae_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE)\n","videomae_model.eval()\n","\n","print(\"Loading FER (emotion)...\")\n","fer_detector = FER(mtcnn=True)\n","print(\"✅ Feature models loaded\\n\")\n","\n","\n","INPUT_DIM = 2304 + 768 + 128  # appearance + action + emotion dims\n","VOCAB_SIZE = len(tokenizer)\n","\n","model = VideoGPT2Captioner(visual_dim=INPUT_DIM, prefix_len=5).to(DEVICE)\n","checkpoint_path = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","state = torch.load(checkpoint_path, map_location=DEVICE)\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","print(\"✅ Trained GPT2 Captioner loaded\\n\")\n","\n","# 6️⃣ Helper functions\n","\n","@torch.no_grad()\n","def extract_appearance_feature(image):\n","    transform = T.Compose([\n","        T.Resize((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","    ])\n","    img_tensor = transform(image).unsqueeze(0).to(DEVICE)\n","    feat = vit_model(img_tensor).last_hidden_state.mean(dim=1)  # 1 x 768\n","    return feat\n","\n","@torch.no_grad()\n","def extract_action_feature(frames):\n","    transform = T.Compose([\n","        T.Resize((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","    ])\n","    frame_tensor = torch.stack([transform(f) for f in frames]).unsqueeze(0).to(DEVICE)\n","    feat = videomae_model(frame_tensor).last_hidden_state.mean(dim=1)  # 1 x 768\n","    return feat\n","\n","@torch.no_grad()\n","def extract_emotion_feature(image):\n","    np_img = np.array(image)\n","    results = fer_detector.detect_emotions(np_img)\n","    if len(results) == 0:\n","        return torch.zeros(128).to(DEVICE)\n","    emo_probs = list(results[0][\"emotions\"].values())\n","    emo_feat = torch.tensor(emo_probs, dtype=torch.float32).to(DEVICE)\n","    if len(emo_feat) < 128:\n","        emo_feat = torch.cat([emo_feat, torch.zeros(128-len(emo_feat)).to(DEVICE)])\n","    return emo_feat.unsqueeze(0)\n","\n","@torch.no_grad()\n","def generate_caption(model, visual_feat, max_len=50):\n","    tokens = model.generate(visual_feat, max_length=max_len, tokenizer=tokenizer)\n","    caption = tokenizer.decode(tokens[0], skip_special_tokens=True)\n","    return caption\n","\n","def gif_to_frames(gif_path, num_frames=8):\n","    gif = Image.open(gif_path)\n","    frames = []\n","    total_frames = getattr(gif, \"n_frames\", 1)  # get total frames safely\n","    step = max(1, total_frames // num_frames)\n","\n","    for i in range(total_frames):\n","        gif.seek(i)\n","        if i % step == 0:\n","            frames.append(gif.convert(\"RGB\"))\n","        if len(frames) == num_frames:\n","            break\n","    return frames\n","\n","# 7️⃣ Run inference on a GIF/video\n","gif_path = \"/content/tumblr_l876j3kjpF1qcw5xjo1_250.gif\"  # Replace with your GIF/video path\n","frames = gif_to_frames(gif_path, num_frames=8)\n","image = frames[0]  # first frame for emotion + appearance\n","\n","# Extract features\n","f_app = extract_appearance_feature(image)\n","f_act = extract_action_feature(frames)\n","f_emo = extract_emotion_feature(image)\n","\n","# Concatenate all features\n","visual_feat = torch.cat([f_app, f_act, f_emo], dim=-1)\n","\n","# Generate caption\n","caption = generate_caption(model, visual_feat)\n","print(\"🎬 Emotion-aware Caption:\", caption)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oHtXi7hioJYq","executionInfo":{"status":"error","timestamp":1768799152428,"user_tz":-330,"elapsed":21383,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"a88da1b2-805b-4391-c413-eb871e105077"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.38.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.12/dist-packages (2.5.3)\n","Requirement already satisfied: fer in /usr/local/lib/python3.12/dist-packages (20.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from fer) (3.10.0)\n","Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.12/dist-packages (from fer) (2.19.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from fer) (4.12.0.88)\n","Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from fer) (3.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fer) (2.2.2)\n","Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from fer) (1.0.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.2.0)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->fer) (1.5.3)\n","Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->fer) (4.4.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (25.12.19)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (0.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (5.29.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (2.0.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (2.19.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.14->fer) (0.5.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->fer) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->fer) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->fer) (0.18.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fer) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fer) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fer) (2025.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.14->fer) (0.45.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.14->fer) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.14->fer) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.14->fer) (3.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->fer) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->fer) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->fer) (0.1.2)\n","Loading ViT...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loading VideoMAE...\n","Loading FER (emotion)...\n","✅ Feature models loaded\n","\n","✅ Trained GPT2 Captioner loaded\n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-520089974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mf_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_appearance_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mf_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_action_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mf_emo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_emotion_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-520089974.py\u001b[0m in \u001b[0;36mextract_action_feature\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     66\u001b[0m     ])\n\u001b[1;32m     67\u001b[0m     \u001b[0mframe_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideomae_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1 x 768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# add position embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# only keep visible patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoImageProcessor, ViTModel, GPT2Tokenizer\n","from transformers import VideoMAEFeatureExtractor, VideoMAEModel\n","from PIL import Image, ImageSequence\n","import pandas as pd\n","from deepface import DeepFace\n","from torchvision import transforms\n","import numpy as np\n","import requests\n","from io import BytesIO\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ------------------------------\n","# 1️⃣ Load Models\n","# ------------------------------\n","print(\"Loading ViT (appearance)...\")\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","print(\"Loading VideoMAE (action)...\")\n","action_proc = VideoMAEFeatureExtractor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","print(\"Loading FER (emotion)...\")\n","def extract_emotion_feature(image):\n","    result = DeepFace.analyze(np.array(image), actions=['emotion'], enforce_detection=False)\n","    emo_vec = [result['emotion'][k] for k in sorted(result['emotion'].keys())]\n","    return torch.tensor(emo_vec, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n","\n","print(\"Loading trained GPT2 captioner...\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","VOCAB_SIZE = tokenizer.vocab_size\n","INPUT_DIM = 2304  # adjust to your model's input dim\n","\n","model = VideoGPT2Captioner(visual_dim=INPUT_DIM, prefix_len=5).to(DEVICE)\n","checkpoint_path = \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\"\n","state = torch.load(checkpoint_path, map_location=DEVICE)\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","\n","print(\"✅ All models loaded successfully.\\n\")\n","\n","# ------------------------------\n","# 2️⃣ Helper Functions\n","# ------------------------------\n","def fetch_gif(url):\n","    response = requests.get(url)\n","    response.raise_for_status()\n","    return Image.open(BytesIO(response.content))\n","\n","def gif_to_frames(gif, num_frames=8):\n","    frames = []\n","    total = getattr(gif, \"n_frames\", 1)\n","    step = max(1, total // num_frames)\n","    for i, frame in enumerate(ImageSequence.Iterator(gif)):\n","        if i % step == 0:\n","            frames.append(frame.convert(\"RGB\"))\n","        if len(frames) == num_frames:\n","            break\n","    return frames\n","\n","def extract_appearance_feature(image):\n","    inputs = vit_proc(images=image, return_tensors=\"pt\").to(DEVICE)\n","    outputs = vit_model(**inputs)\n","    return outputs.last_hidden_state[:, 0, :]  # CLS token\n","\n","video_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","def extract_action_feature(frames):\n","    processed = [video_transform(f) for f in frames]\n","    video_tensor = torch.stack(processed).unsqueeze(0).to(DEVICE)  # batch x frames x 3 x H x W\n","    outputs = action_model(video_tensor)\n","    return outputs.last_hidden_state.mean(dim=1)  # pooled feature\n","\n","def generate_caption(model, visual_feat):\n","    input_ids = torch.tensor([tokenizer.pad_token_id]).unsqueeze(0).to(DEVICE)\n","    with torch.no_grad():\n","        outputs = model.generate(visual_feat, input_ids=input_ids, max_length=50)\n","    caption = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return caption\n","\n","# ------------------------------\n","# 3️⃣ Load Test CSV\n","# ------------------------------\n","test_csv = \"/content/drive/MyDrive/FYP_Full_Project/splits/test.csv\"\n","df_test = pd.read_csv(test_csv)\n","\n","# ------------------------------\n","# 4️⃣ Run Inference\n","# ------------------------------\n","print(\"🎬 Running emotion-aware captions...\\n\")\n","for idx, row in df_test.iterrows():\n","    gif_url = row['path']  # column with URLs\n","    try:\n","        gif = fetch_gif(gif_url)\n","        frames = gif_to_frames(gif, num_frames=8)\n","        image = frames[0]  # first frame for appearance + emotion\n","\n","        # Extract features\n","        f_app = extract_appearance_feature(image)\n","        f_act = extract_action_feature(frames)\n","        f_emo = extract_emotion_feature(image)\n","\n","        # Concatenate features for GPT2 input\n","        visual_feat = torch.cat([f_app, f_act, f_emo], dim=1)\n","\n","        # Generate caption\n","        caption = generate_caption(model, visual_feat)\n","        print(f\"GIF URL: {gif_url}\\nCaption: {caption}\\n{'-'*60}\")\n","\n","    except Exception as e:\n","        print(f\"Error processing {gif_url}: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhE_pvbBrLHu","executionInfo":{"status":"ok","timestamp":1768800894364,"user_tz":-330,"elapsed":1220446,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"cab96f25-f775-43ad-e9bf-5493c3e787a4"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ViT (appearance)...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loading VideoMAE (action)...\n","Loading FER (emotion)...\n","Loading trained GPT2 captioner...\n","✅ All models loaded successfully.\n","\n","🎬 Running emotion-aware captions...\n","\n","Error processing https://38.media.tumblr.com/tumblr_m5bsogjFSi1qzc18no1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1de4b2cfe3c39f0b8923eaa883f0de71/tumblr_nodj8jxg791qkqcdko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2b7c307a664fd23700534deaaffda905/tumblr_npy2w5VDCU1qdj2rpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/24f7c4fbfca82ab9a6774fa944af428b/tumblr_nkq1w3A69N1scqhj0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/dfa581fda9495664dfb89b44c16d974d/tumblr_nok2yhuWT61ryk8f6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/93ae53e3cc4be753da2f9fafa7dae930/tumblr_npcone7Cia1tya5iuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c565a1b8beda87bb2b0682e76027a762/tumblr_mqwfvv3M6E1qgw55do1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4fb990ba65c3a02459471ba575245bfd/tumblr_nmqnepJkya1tq4of6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/05931810bd9a899d9b15ca3096098bbc/tumblr_n0l20kweK51trdwjco1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/3d092be4b53578e8bbae98b7f1a74e20/tumblr_npoy5kDaVu1re8dnwo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bf43e95965c254bae9586aa6248d03ac/tumblr_npszg32Pa61rg38w2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f1d66e3745b0d59e143af003f5f21566/tumblr_nph5m7rqD11u7o7rgo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e000bc0697dcf5b85ca6d53ebb8f919c/tumblr_nobxavASYm1tgetb4o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_lxbmb0HZjh1qcsgk1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f5cc0bea26103e6dff24b06fa15b03a6/tumblr_mjgobyf7Ar1rkcwnbo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/59f93dfdd0a8f71952b5b2678f94e636/tumblr_npa9ekm8EJ1qkbzlao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0460c197ea40da2a35473a61d345ea3e/tumblr_nnusabbmJF1sy1vy7o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m6mdoj7kDF1rug9d0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/cb39c164b148eaa604ed076fb1bcc63a/tumblr_nf59rj3Tt51u3j5yto1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5f655a6c688838f340c80d721049cec2/tumblr_no9y7w9B5p1trm5m9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8958f27e85dd1b1f24bf24ba45176d77/tumblr_noqy8lDPUK1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2328f1d1b9f8df4f6f67197329ef6985/tumblr_npf65vqysy1s0grcyo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/dfeb4b9b09d5a7f6f0132e0d75d65165/tumblr_now7uh06ef1uwvtpjo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/76bc9279ab8cd0c69127202d9abb4e6f/tumblr_nia3tpNRiC1r5zj1yo1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/43dd236d146b5f14e579613cfc24012a/tumblr_nq2qei6up11rnbl09o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a9dbb1aa1b8e11ebe600c5bd8826e6fd/tumblr_nqfbatbtej1rp3nyxo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/40dd06024b10c755788865c8e41eacef/tumblr_no3cpzI5kS1twzkcuo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5571318ff2d4755aff0df90d75a0faaf/tumblr_mzvs72v8lV1tpkrt5o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c5dfad656879b1ed5f2ff6259d905eda/tumblr_nq5bpkvR0q1tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9b46a3c0e2d445e94fd6be75c654e062/tumblr_npdvu4qcXZ1u39oozo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e3a9e85a01eef280a56231adc20c0151/tumblr_npgduaSU3q1t5h21vo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7275838f5f3c4ae2493d64f86558f458/tumblr_npi0laXVha1s3att3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c7f5d9d6732752a4fc2a71f26e15a9dc/tumblr_npo2rvDZvl1tl4ayzo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a77e2eec3f0e01407883422802eaf660/tumblr_my88eogOSc1rcxor0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d57f39c112186c6cf84f1199864ae04c/tumblr_nogk9sluFg1tyncywo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/73e716cedd3ed8925d25c6a128f12887/tumblr_mfelrsDV9l1rd09wuo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2557b00a4ec50c7d9662e84bfbc5e249/tumblr_npr4vdfIjm1uv7b6no1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/51491b8660942ef6dbe8cf16aea25046/tumblr_np4g1hA0PP1uwcefeo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1a1896b84776c314c3c05102b5b4423d/tumblr_nmbwt3gp6i1uog9zjo1_400.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/0a05863da681c8a02e137eaac7871a33/tumblr_noxg9czmbg1rcc6ipo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8f502f3817ec10321285199b56535223/tumblr_nowu1yW8Xs1uvj92co1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/d5550d5b98c7bbdbc2d195ccee7012b2/tumblr_nqmumvJJBD1usf060o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a7fe1e1d1525d13775042c4f4d480f6a/tumblr_npybchwzUr1ri61l0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/39d8b4845446e0a27fea0e7295b0f084/tumblr_nl4a8wuuzb1tteheho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/40bc81386eb56fdeabbb5f4a6253e004/tumblr_nokhu55NoQ1rhi8mmo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e66585ee5444a4412c6664b6c9f877a1/tumblr_novwe1eC8e1t8hzl8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2326b3de17875471bae101048a9794cc/tumblr_nhdavqhn8w1ry6msio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4b84bfdf1589a84d4346d1162a23c9bf/tumblr_notk57znV91rmkq0so1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/38b2a07daa007a2819ce678168f900a4/tumblr_n7vl7uuugA1te91ugo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2cce8bc5f7b10045412080110cd5b59a/tumblr_n65oq1cZ3z1s0mbfho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d9caba536ee0c198f9639cccbc7779cc/tumblr_mha0wbnphP1qeuzrdo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f50d3986148ebeadafd0c453b220033f/tumblr_nq7ao7U7Rt1sht3fmo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/912827d1d154738400e3b55f70ad0090/tumblr_nornwsq78H1qzuufwo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8e8176ae4dfb5daec105d3d8d419c889/tumblr_nl4a0wxgHM1rfs87vo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f1d58a1455522b242d20f90a4f658f3c/tumblr_nozf52Ie3T1t49515o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/046269354d3a085e329ce9713df7ba46/tumblr_nph72hlSrM1uvk135o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/0964b7c77a87af875f3cff88e066d159/tumblr_noin6e8i4A1usf060o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a74d82c8b7bd4a523cc7407cd2b9ce54/tumblr_npxveuAtrV1uv1i55o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/61e74775e62adfd32bcf3eb3223fdab7/tumblr_nooglpxw3a1tx8mn0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/773226d0dbb1eb537bb53c1c4429b50e/tumblr_nek3psdyAA1u1qld9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/29c89695ac6af6a7d858cd5ec20d948d/tumblr_np0aj64pSV1uwx5g9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8ed616ae63f660326a46cb607fdae44f/tumblr_np12g8IRlk1tnfve1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/5d3c0db6123b68fc90a44a4275f056ac/tumblr_nqgatkowwG1s13lvqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/dedb4a38eb360ccdd3f4ac4e93c861b4/tumblr_np3d5f9uhe1u32q3co1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/285831bcc3a871ea235cbafb309120e6/tumblr_n5cji55JU11tadpcwo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d64c897e145c2d34076be9da4964e7e3/tumblr_npns5xIhMX1uy0sz1o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2cb34d2941556cb94ebd3eec76528cbf/tumblr_noecfpjEBH1sht3fmo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/5b3caee4a93c9528a37ca45c7403e531/tumblr_nq3akvgNkG1rszvkgo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/39eff2352c6364d979245f0da53f8332/tumblr_nokln2kfXw1qhaeoqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f6bd1e791364479a03752be73e888f7e/tumblr_np9uvfw3tp1sp3v0go1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c3af080aea422abf778133f674cc9039/tumblr_npxe6ic6I61uyt7qro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1f47dcedba23acf13a6b30ddb976a2f5/tumblr_np8mwapweH1uwzd1no1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/853fe69a0b15ae75a1211ab1326ae7a4/tumblr_nopy4laa981uqc76qo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b7c847fcd6fb842f07dfb33e91c4c353/tumblr_npi36okfCR1r7vhcpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/87cbd7e312329b592896dd6daa83fadf/tumblr_np1clsO2Ng1rvekoro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f5229d79b039112a29d50199d644a623/tumblr_nn7t50NEUR1u5ap9uo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9c41505222d99b420bec91dc03c23648/tumblr_mftpo9mwwV1qgbtzeo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c7577a5c709cda650fe9f19aa806fccb/tumblr_no6tnsxuvi1tkts8ro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4acced636abbeffc82b02bb50df54878/tumblr_mp6janBO2j1r206ico1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/aa45ffb7c72c7ca645d5c0c52842eec6/tumblr_nplek0bOGa1srvtt6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/93c6fc476fac1668f275ed904f8ebc8d/tumblr_miy822HSxO1rqfa8mo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/31ee5ab5da21a8cec182e5e0852235a9/tumblr_mm4qseqvff1r660gmo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/78947cde3360fe0e1040f9b1c8b6582e/tumblr_nfycslDrel1u4qd70o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8b71630156c44ff4c48749814edcc22c/tumblr_npvj0dWS9A1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/cba4225ab15e294e93eddc9301d44a54/tumblr_ncvt2l5ABt1rp01zzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1bf97a73777087534a45927ba58b502d/tumblr_npqnuwFS0g1uwu5hqo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/04969582e082c42d89e99f8f0576a8de/tumblr_noetjsPpvO1th64ako1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6cac37f0e273ec29e63784e42e406182/tumblr_no6fvqvSt71rwngmoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a75f5635241378daa25adf26b6badf05/tumblr_nq90j9QffG1ux81poo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9c875609d9f3c796ab70936e1eed7b24/tumblr_mzjogsQ6W11ssooz7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/94b8ab3f4ed3360ece1e44362a047a6f/tumblr_nq8iv94iSe1u4e4lzo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/d68dc254eaceb15fb9ef79167c3b782e/tumblr_n8zjdbOQmh1r70le6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/478778df6ecea65d512805304c3a1341/tumblr_ni19tn54sF1t95z9zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4eaa013770cff7a54b1ab4a40120b974/tumblr_nnwy9h8Zlw1qg0or6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c6638013e3fce59ecb789ebeee3f165c/tumblr_nok2r1IzmV1twfmf3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9a7bef6f7759ecc278a4855fdd2bec39/tumblr_no3ozh4N7Q1u1mb9ao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e016c0e8c36c0cb83597629383527712/tumblr_nhfj9jq8HX1rtcpyfo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f8ff4fcbb0f786746bddcdabc3ada80a/tumblr_ndmqneclQt1qky25go1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a0b75d57c30d04ed1bd39d0c9c4b0f89/tumblr_npxqqvAPWc1uyqazdo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4c02c50c842d5f9a175045f9bcb8e35f/tumblr_np655vk8wm1u7q0qeo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6a36e838c88c5f7f8e62958fc17db038/tumblr_njoi6zwCOv1r8tvt4o1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e6c5ce11da168e1e4fdecea2eadf1c1f/tumblr_ne0qf88I2w1rtt5j7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/49f3d3ecc1b0009678fb5128521c3fc6/tumblr_nn0myhgJR61qcxts9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9760e65ff5bbbbe37801ec5bba973753/tumblr_n93hv8EK8J1qit4sio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/94ceae2fd9820edc253b2f013ede9c95/tumblr_npaje0dlqN1rtuocgo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/0be32f964f45211c959319a295cee7f8/tumblr_no3mz7Nnl71tdugojo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_mbowb7eQQi1roshv3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/de9e1ddd5a042950f4fa7ba0a6e028ab/tumblr_nf5bfdmzti1sakbyto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4acbfb0387394505377108dc3b94155a/tumblr_nqfrb2s95v1u9m8xmo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/750d9622f868b6f650163501ca4e6c3f/tumblr_npenx6AJw11sdss0qo1_250.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/a90e6bfdceb7d8db2ffe014ca0690c42/tumblr_npjs2b0jIM1t95h1uo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/21346e5cad77caf52acc5fc4a9574d55/tumblr_nprvfyehvT1tg07vxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/14955ec975ee9795a1f30caeb403618a/tumblr_nnw4xydlVR1rtujo0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d5ae4178b8001a2eda8b51d1f078b547/tumblr_no3dg6F1OU1qik5q3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8f4e2ffac1d19d9ae1c660aaf78bc980/tumblr_noz1t5wuih1u9kj5io1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/322af1237c131c4096b6cee6d4732783/tumblr_np7sjhExcK1upa533o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/838b0ba28a39cd1ba90218f4cade6dc2/tumblr_nic9dlK9Sm1rlvvsno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/033ffcf598f92ad79023c07996982dd6/tumblr_nowy2hSuEZ1tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/911fc0d2074e5b6209d35b3009d991d4/tumblr_mg7tbfwauz1s2as9eo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8004229c1e2be7a9ce10d434dcdd5c14/tumblr_mwb5q2WNes1t0i1e4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/5995b6d7a190ff28d3ca7857e998dd47/tumblr_npudyxjOTb1te94myo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c50319dbe5e20ba21ee9344ac37b7129/tumblr_no5pqde8ni1rifk13o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/512f22d98201dfd2c8e9810609fcacde/tumblr_nqi4q1F7Z71tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/7d1a62b9b64e88173483baa95ad41dd2/tumblr_na9bbyX3y51tf36dpo3_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/512f58dd28a820afbe229c21a349d6f3/tumblr_n6psiprb2X1qzjfbto1_100.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a80d106ae66cb6772890e805e3288971/tumblr_nqn2ozu35v1th2vryo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0aac92c0e49985edf621dcdd04db7ca8/tumblr_nqgjo2pfob1tmnntwo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/605ebbe911da861e5651c48d31ba41b0/tumblr_nqrvkfB5Aw1r6qhseo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/356d90b6fa57e86f37028e0cc0045bf4/tumblr_npor1fLLsm1tf647io1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e45158c990a348c73b8163dfbe3e8e3c/tumblr_n2hrevDZYL1qb7f7zo1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/78b2d8ea949786a91bb9aa63a6600777/tumblr_nqcvymRiO51uz5v3oo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/13f29765b035ad13100e54c931a2b340/tumblr_no3oi2XHF81tjmuabo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/edfb67aea998f39eb0438ac11c3722c6/tumblr_no70touQPp1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7e145544d5aeb03d02fe5ad828d5c6ba/tumblr_npp9ufsugG1uxlh63o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/744ae829720bbd9a1c68f9af9c381095/tumblr_npck03PU3Q1tpmgf1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/60dbc0dcb526e072aa409928f5799278/tumblr_ngl7t9g6Al1smv1p3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e5c7d769813a51308ee54b68df2fd084/tumblr_mwolj0LRLH1szv0oro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a12a81b9e6d55b93a5ddd163e62352c9/tumblr_nnv0bhBdqJ1r3thwso1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b85cd6522c7f94d6512dc5ce17c8cb49/tumblr_no41uaHVfa1uns4v9o1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7822c987b4c9468d9eab3296ff101d75/tumblr_no708ajpSg1us7bx5o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e1183cf2b41ef9720d73d9317f4074c2/tumblr_no299k7OAI1t95h1uo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4a02aea50b1f1e71e204079d91bbc2b8/tumblr_n65ezson981qhii9ro1_r3_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c81d8b2d6dd03cfac6c32a1057f9cfda/tumblr_np8ay8sZHr1urrdc5o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/ed4d06b1dd9c02292b9540fefc7a0cda/tumblr_nodi2rLQXk1tselino1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/df44709c899c0ce2d1edcbbf71457d04/tumblr_no14dnEr141uoyyryo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_m0hie9uEWc1qdcel5o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5d9c447dea9978b9160c97f2d7d052fb/tumblr_no94278CKo1sg2qzgo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/459651bc1c22317b1df6ffad9b102214/tumblr_nprbd9X8QN1uu4cbfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f070c860916b3c6b0b94e295d481e10a/tumblr_npa7rdAsaH1uxpeako1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7479ac7ab5d650a8070597d56e30e8ed/tumblr_no48qjmETO1tz9jaqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/7f02599af926f6fe2b9efbb1162f946c/tumblr_no8vc2D4Vo1ts4o2no1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/729217da6ef44251a8190a70dcd0bede/tumblr_nexcii2coV1tiw3fjo1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/cc0ce63824bbc9d1cffee220babdd728/tumblr_njf7q8KiW71sbzhteo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/133e811f35ffb541fbf969841e1ccef3/tumblr_nqqlguDehp1qcb8dzo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/40416bd0833b519cd85d9e7fe8b1b071/tumblr_nqm15csdvk1uscf21o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a4a7964ab584dbaaaa464ff31ff18b78/tumblr_novuazVMYn1rd31gho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/970ebb9216dd367e11e4428361f198be/tumblr_mlme5oQYZx1snmpfxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/afd0f343623b97be318bbacba7b04de0/tumblr_nowdz2Szth1sk96t7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9c6818502b143b43e86f09ab262d62de/tumblr_nqbbkfAYeW1tkwlkvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9f5add17e162f05ee828b90c58a8a316/tumblr_nnohewxZAc1s9i6j1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/766cf0ac141ed1e02a1529d273f0ef24/tumblr_nnwq4sv6F41u5y043o1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2a0170388596ed5f84318bbfabb46be1/tumblr_nlzwqmfv6l1qlk2lzo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2aa6d633ea6ae8c3842120a289987e8a/tumblr_nodnacNiwH1un7qbto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_lmpcwmdI2S1qfpb3ho1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/40eedc5a225eafb7469b360c55ab2eb9/tumblr_npx35lQNlc1tg6dv1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b63452be38d618c6f4ac517dd10e366d/tumblr_nc78r0NrnH1rxobalo2_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bb459b914ff2645ec8e93821d56eb75d/tumblr_np2x88vskx1ryce90o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/182435470210ad2f4609732f199412bb/tumblr_nmva6qtBRk1u4nbmvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/927bc4266be38bda3ac76e6a3eedaa18/tumblr_npnedgxuEx1u0cc95o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/bf156dd81b2e8a0e0bc6ac56cdec1d55/tumblr_nd5ff3tG9q1snvfqvo1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e06bdc5c293e188c8ace6ba2bb82a086/tumblr_mtab1aEawy1svt8r8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3b6910297ae3f1a96a65ba44f12271f4/tumblr_noxchoMjI21slmhhco1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/eb73695ab4631c04cef07c95d25b2f11/tumblr_np2nkjfdx11se46bno1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/097a9303f009fe68a4b4cef18339de16/tumblr_mvxi7t8aqr1swh3svo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b770250e0eeee76376327082049261f9/tumblr_noi45b5GfU1s4eg66o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/28ad911c0b9a91b18f7111e87577803f/tumblr_nqdbe2fSxi1tk2ngvo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7005f4145a5ee1b005e3b1de3156e8cb/tumblr_n49hywgj551roa7c8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/df0b48a74c7ee1102bb3d7f1bfa45641/tumblr_no4gw9JXyS1tkqim0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1b0c89f4f3c6a52873cd33f6f464e8ed/tumblr_nnw75k9WDm1sp70bgo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/f69b4ae82d26574d13b6ee7bc90dc6d4/tumblr_noipurXqsn1thh6h9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2b7fe800acdb2b6b3b8b7d6f7348b0a2/tumblr_nokgzlBuaO1usepbzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/eefec075e7604e136f5dcbc68b2ba66d/tumblr_ndltizoIrW1tmq20eo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ccfc933cc1a55f07e09286c6765819b7/tumblr_npy7zmMWs71uuu6ydo1_250.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://31.media.tumblr.com/9302f2356480af3da98f9547d227108a/tumblr_nqbvutufkk1qhr9koo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/50c0e21f4e8b31c0b3f9f359564543aa/tumblr_npg8m461qc1uozlxlo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6e6316ab6dd6bc4fae10af3882727b7e/tumblr_ms0kvh9Vjc1swru50o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7d1a4a460123a29a3e8880a8c634ab00/tumblr_n9n5hrb1Pp1rraqsio1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7f80a3486ce97458a5b0f3a41937673e/tumblr_mnsf05wuJC1so32gwo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_mco5onu8Lt1recvs6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7a256601d146834f55166cf5b68ca96e/tumblr_np90i8vijV1ts8k2fo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_m33dp9ONNX1qaej6xo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aeec533be1b255299dca0015947e5e92/tumblr_nql82ysj6k1t0j31do1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6a54664ecfb7fcecf4ee6817e9d30454/tumblr_nn84ooPYRZ1uo144bo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8569f59cbb80fdd05ce52fadde518081/tumblr_npsdccsUht1subslpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1f8617dd1c69996cb3b6587a61c59dba/tumblr_njpvugyAP91tj2lfbo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cf02b55e4684f17410114208229b9cf4/tumblr_muxaj4wsRV1s2w5zfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/298a29b0aea7a7cfeddd3728e8c059bb/tumblr_np76x3SOag1unyhx2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/5a19ac32bb65aa58f453de488bd851f3/tumblr_nq3l8qPPVE1uq5bh7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9176663735f8c32424d04c77f66dcd51/tumblr_nq299xCki41rp8424o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/804e3ea48cde166748b2361954db8000/tumblr_no97ucEIWu1utzy90o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d1c8389e59385d293580453d47b066be/tumblr_n9140vAYCr1qbg05yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/fab2999db29a1112d632c12568f7ecc6/tumblr_nqksnpjz1d1tvq1c4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/17fe3b424dadc501c6941ca5bf67ca0e/tumblr_nnuul5aCgM1rpp7qpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/f366f967ff8bd53e1e60484704b7620d/tumblr_njeuggdSVg1sbzhteo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d3b86007777a3ffdf29e619eade73bb6/tumblr_no44g6qWM61u6momto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/503e5c88d151980cd18ba2630de5b536/tumblr_nql5d1EmdF1r3vrzgo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/958841c5c279440c9e1e33ef2ac92ddf/tumblr_npphooxNgf1tfkypeo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/43bd68f6afa176a4a50a971c243c9839/tumblr_nqp5i6gOcq1uzyc9mo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/eae04158c305250f6f0aa3babc6db3ee/tumblr_ne0rdqgC161qcr2gxo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/tumblr_m8k7phJXCO1rp26cno1_r2_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a0c809d597e324fad0798f6ddf66a6f5/tumblr_npq6tgvGAf1t0zwmco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b2ce5f54a11e8aec0c32a4cbb691ebd0/tumblr_no3inlKHGv1smv1p3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e572273d40e548365d8988c7be2c8663/tumblr_nqpy6gPxzk1uyqwabo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/262fbebe4eb8dce78e938340e7da1ba3/tumblr_nnuuiyD83C1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d35a3efaaaf8974003011f1bb5c7a995/tumblr_nqrzkuhNqv1uslzojo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6cb26a5fd6e9e54c186390b490df4ce6/tumblr_nqiemyMeTL1qz4bpxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/036c251258e795a14a9d055347fc883a/tumblr_nqkdbambxK1sfsa18o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/813dc600ab4df64f0f4506b0c0714b84/tumblr_nq5cnjuFdq1tatohao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/aa1b4811adb49882fce63ed6544d72e6/tumblr_nob0vjhRU51t13lj0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d3d3130d2d4197c003a28be6f514910d/tumblr_nokd8d1yCX1u1sb80o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/05f7b0fbec3e59d0d79c09d639c0a172/tumblr_notek4Znd51tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f1315de65cf6fc5c2066ee2cde10dabc/tumblr_np4p9zGErw1rhaehho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bd088c53f290fab6445fd74c533c4cf2/tumblr_np36daemEV1t0vz2to1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/659b7858f2a5a30eeff736a488b8495d/tumblr_noemog1sQN1uvdyzqo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ca3cf8e8dcd7a52e7248e9b1b54b37af/tumblr_navwrhiCMv1ssite1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/677c2ec4497cb16b70c7d072c47bd0d7/tumblr_nowl1nSiyc1tyncywo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9d563697050b0a4273762659dae64fa8/tumblr_nqncnjLR8K1sulxk8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2e1ac74044eda8fa2a49925b9677c06b/tumblr_noxsb5sUTy1uwdt3po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7223b402cd9af434f0880fadb11e3cd1/tumblr_noa1rbVx991rz9e0oo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/039a04e8ca02a2b5d1feade3dcbce2b0/tumblr_no62yynzOy1tmemc1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7fd26bdcd5aad218b7641df91c62993e/tumblr_no1d8f6RmU1uv6sqao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/6062195a5d686168a2cda4fada5e7f79/tumblr_no85smfcMb1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6304192bd5eb46c14ab300a3bd5e5599/tumblr_nqb98vu7ws1usj03do1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e99dab2e5ec64deb157369a48bb6cc28/tumblr_noux6h9jXQ1rljj38o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2880370e0954e1e1f16b04a75ce0f5ff/tumblr_npt6wee8iA1tj3r8so1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/fc4cefe9b1fd5842f9a420a79cf8c63b/tumblr_ncan9vl7VA1skim1bo1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5b80b97598fe2f0d57f8b158d97f56a8/tumblr_npqvr5wGNG1tatohao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7e61635b23c4e994a5725debf0bf2367/tumblr_nka4c7zpTS1qa6um3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/07f29bc1dfa45565b59b7ebc6d811a3c/tumblr_n8n0s6Zq8L1tq8hdho1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/30f06df62d653997f98778de4b91784f/tumblr_nqlhqpaWhG1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0d3b797d9225482b21925d406af694b7/tumblr_nps2lgkNyV1u6w3s2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/13cb25b121b66254f6b795d0c89cb24f/tumblr_nnz7w4XjYg1u2jj66o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/28c1dc6b6df05e6cc7cf7aaaef5b8cd3/tumblr_n99wfr1Mow1trf9llo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/11b60be1e18101c77207cb39d28eaa2a/tumblr_notmuuWCm41s2hz1mo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/44037f353e40cc372ebec252f25d70d9/tumblr_ni3xd21DUb1tmfpq8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e41e39b54a976a0c482568d161c293b0/tumblr_npv5a2M9m91r64178o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b02b294126a0faeec7cb4b01c1839551/tumblr_n4pcxy8IYn1ql8t12o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6ef6af46e56f291988557ee72cd8eb31/tumblr_noezkdBDPA1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7dc12674f8e86b5629372244ed7c4576/tumblr_nqk7tiYViw1tyncywo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/05b60f489c0a1a80d9103eb2ed89019f/tumblr_nnxozzcLFa1tkvqk7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/09de844bbf3e195069a39afd04d733b7/tumblr_noukfo5klk1s52ddao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/87c039c8dd226e3c8f00984432acda46/tumblr_npcpv8Heya1twfmf3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/dc5d53b34be88fb94615008ebb8ec027/tumblr_nf6tz7IlG71t6nd1vo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/000baad9dd6f4649917e8ea6c215e6e9/tumblr_nq9fazD7YL1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/eaa1077553a4b89906554932eb6c3f27/tumblr_nq795tCCOo1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a53426f2be652304a6cf1857c7dca052/tumblr_np5aw09Aa31shzpsuo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2508b18b4d7b41a8930e495297712810/tumblr_npkr9thhgN1uv9yxeo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/fd3ca9dbf7391b01aed71f8c9da74770/tumblr_noskd9MSPQ1splikxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/169af767e1ca0c16407c5be188f9dab8/tumblr_mirwrl0Oul1s3g7rco1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6913d38d4f171d7274e8cdb4d9aac610/tumblr_no4re9nlrE1use8l1o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/60a4aed7411b20da9405a6c2f4b5bdc3/tumblr_nooopgwvwr1utomnjo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c15479c9872730113b47da2532eff566/tumblr_npdysqRzec1r4c4nxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5827bf68b7abb99cc676a0551bb0705b/tumblr_nqqkpgcInu1tho2ako1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c442b2d1125e58819b98d904b2cdb8cb/tumblr_n8k1fun9f41tv7yt8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f8cd68986ceaf247f88d57b68c8a6a8f/tumblr_n87br4n1rf1sxa63vo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/27e1253ba8809a0106285b55b233b34f/tumblr_nob0jkWpiI1t95h1uo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c5c85dd2129807153666d7ebd70e459c/tumblr_np62ekg9ZP1ta8o4no1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4d10c8aa67d8c5221b431445718f3924/tumblr_nonm3mWvpb1s5964mo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7183b42e6e9c2aeb2207fe5d555f0f32/tumblr_n5dtds5SMm1twu18ko1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/19510856d0661c459461b41cf6984fd5/tumblr_nnn5gc4B281uraxnio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/11341e737b1c0260088cd281008ef655/tumblr_noj1b3yw1d1uvkr19o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d57069f39943d422f53702b589a4ad87/tumblr_npk182p9Oo1u5gmzao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6431ba28bdb00f7262218ccdf94ff3b5/tumblr_np8iwfAsYl1u9kj5io1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d216cbabc000ebf7052b8ec8ba7631e5/tumblr_npyaunbgQj1tz9jaqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/13e2f95d6760df54a859ba9b562b7f6a/tumblr_nlkdllyPVb1suwc3ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/7778a1a9491bd61e60e26382dde0d582/tumblr_npfup8IJsd1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/670d6fd3017b820de6fcf4d9f3f9e203/tumblr_n9plrihFhk1rg73dbo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/66e58fd690cc381eb23b697157548016/tumblr_no7x3fVDR61t0zxouo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ba89a847002445316b930ec321d2d103/tumblr_npdpkt4GF61uxw6f6o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/3d93c74d3631858d60d16a6ad5d6d888/tumblr_nqjgzjMZu01s7096po1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/55b9217aed4fa298c061a94ce8501e27/tumblr_nq7d95vwO61rqa80mo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bb06beb45c31e6eb196efabe468b5ee1/tumblr_no7watOHXE1uo9sz4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/530a2089b8e85825e4b4f2b9e675bfb7/tumblr_nodncmZjlN1u7d548o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8b71630156c44ff4c48749814edcc22c/tumblr_npvj0dWS9A1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c03221d4d256308bca07cf3306f75dc5/tumblr_npzyfi3JBQ1uxivveo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0a609e35f9afaeecbf20f274848575ba/tumblr_mz8pyxnbr41qlk7iko1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_lvmztsQ52r1qeuw8xo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cf9026757b75d0f53a7dc5628a4ee2a3/tumblr_nqk99ldDRr1rf7ulto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a96db5d58dcfef4053a4d3eecb9ee23e/tumblr_npdoychBWl1tzt1nso1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_lwa1t58F5s1qj72mbo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/403a9a34c2fed27c002b5760f1301d05/tumblr_naadmnnxCB1tpl2evo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/93192d4458a776698760d3c3dd5f57be/tumblr_npasxy9FFP1uox2sco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2160dbf2a481ae5d4bc00e5788bc2b72/tumblr_nqgcqci2WO1taipboo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0fe220e61ff03d521ba86430e61ef5ab/tumblr_noq24qeJZN1u8lu82o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/6bb1c18d40101d312c59145b940d6de0/tumblr_nipcn2okhF1rk09qho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_mch6upi5uT1rcp2pyo1_r2_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8c4ee5c0338ad534042e85605b70c927/tumblr_npqraj6f5R1uuxd1yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3c04970978ca72ec64bb5609d7495deb/tumblr_njmjxb7k221u7jlepo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/404e120865ced58d5886308f417a3e9f/tumblr_nnmrbzohW11tl3gaso1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a04a40161e36be425bf9a6eaaaa01f9d/tumblr_nq0rh75RhD1uywu1ro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c3563ccf981dafc28f326a19b53f251c/tumblr_noei93bJkg1ri61l0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/367541e6c4c42a4d57602b42a331ca5d/tumblr_np84galvUX1rkaxwxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e04041667953a44a178077486eca706f/tumblr_n5sn7o8ReN1r4ueyro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ee4f1003263f85cd20f6f69e76ce0a92/tumblr_njoihzjLuJ1tv7yt8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e92ab474ef32390e5cb6aaac7c7a2e24/tumblr_np806zw6uX1u5fkwxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/98b7f8959f144c92634ded015b8c7464/tumblr_npj2vzgxGF1tkkgpso1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/29c900641450c638bf240877a4d25631/tumblr_nq9lseiERj1uz0qnyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3d1fb9031cb9146aa9318108c8f3d173/tumblr_npueoahi571ri27aeo1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/df454f9dd2c2f85013c9b7def9401407/tumblr_npbkure3Cc1qj0ctto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b1b14b9662e8a38c02ab4fe18ee3371b/tumblr_nodb5jW3wU1r03eaxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/766742bd1f212a9b143df0734b121727/tumblr_notz62FBEt1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/51983ecfd8a8b14ae817f75e7c019c82/tumblr_nbe0gnjJiT1regz06o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/74289f9664814a927d60bdfab156c850/tumblr_nekcpe0M4x1rt5rnmo1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/472979d4fe2eb1fb5de611053d0af9e1/tumblr_no4s1f7uTg1urlrpuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/33e1e3654d08b80330da409cf40257d8/tumblr_ndqxwyY0DE1tw2ybvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/211dcd6a507eaf73161126349da4aeba/tumblr_mjv06oykET1rscmfho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/16798597a3f5cd6e2e22620679efefcf/tumblr_nffzlmdBIG1tecyy7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b65b247fc10f7daf5689dc5d4426849b/tumblr_np0s0v4Vg61s5030co1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7d48d44b8e169205b043691727f53797/tumblr_no5d61S3C71sizknzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ec2717cf315672b08b2564aec209bca8/tumblr_mkpn0t6X7X1qg6w1ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1bacdbad9df6e0756257b34fbde16572/tumblr_n41xq5Tmni1qc7kxbo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/257a668dd1ddb12ee0ffe7439366f549/tumblr_npbxguhXFr1uot1e7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c429b6bfb8ca0a2560ae70e080eeffe9/tumblr_npt77cfh9l1uxtx27o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a59d070f45d454ca84e6c4a10998781b/tumblr_nohxwkupdR1u4rffto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/eb5f0fc91e2be6077e9d5e49872bf65b/tumblr_np68eoY5R71uwug8oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/86c54df0c7b0fc291654fb4e2169dbef/tumblr_mjp7v1yUcU1qbz8wxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d2934337834f63fece355f06394c1ef2/tumblr_nhhgtnK6b31u70170o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/19dfcb70b9e328fa2244c0ea68beeb8a/tumblr_nnwgqn2ASV1qdfhbno1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4a64aade72f10b86769f65ceb831b217/tumblr_nq4hqvxOiz1unyhx2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ec9cc3c333f8b9f98dcfe18a6f6d1191/tumblr_n1hzpzfjvF1sj8f9jo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_mbxyok04Nb1r9jp9so1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a60eb88e26f605cc932b22d1f396e1c8/tumblr_nouo9jFDya1u9fb2po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b48cd6fbdd889f914e28ba8c858df56c/tumblr_nnwj6lwzep1u9uqido1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/506dc70574f3a76e46c14a705131ecd8/tumblr_nohe6z6uwB1u9fb2po1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1a8d3c273b8559f2f182e869ad0857fe/tumblr_mo6q9nIENz1rdunkto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4aa22959447735889a0baa4a084e4f9c/tumblr_no3fi4QHpD1u3iti5o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d67067205bb99a94f16b11b688ac02a5/tumblr_nq5ydpt7tp1t95h1uo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9147e31c0b1e2e6240c5bcd7890ce7ce/tumblr_nhima0TFwx1rjxoico1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/182f40b5cb26864c58f3b0c109d1b2b1/tumblr_no1wttRgBO1tkhxdko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/07b8f69824f33263490955a5d253fb18/tumblr_nemeixSdXJ1sargpvo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8ec5d58a3d105b84d35c38370c624715/tumblr_nphc99Wyww1rytew1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6c358bec4182eafea3491080c0c9e2ba/tumblr_np7lyq3Gpw1uo58t1o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2fda7164aaef12f4bce8d81645a0f528/tumblr_nqp93ivl1G1te94myo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c0c3bb997c62e07a1f41792b5198f585/tumblr_nc4asrQYHI1tkengwo2_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/de504d7b371fbac1c9aed13dfdf967c9/tumblr_no1uggsbCX1t090qqo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cc015349de6b1515521ab5bb800c8e7e/tumblr_mfng74vDAN1qgmlbeo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/21fe18efb2e34a6e1cb0acedaaab27a7/tumblr_mxs170PgH81rzvsjlo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0c0a196fca6ceab9baa2be8d9dbef89b/tumblr_np1kxvuxMJ1u6iefyo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m9ouzbwFNN1qmr2l1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bc5bece064d9d9c888775f988304f292/tumblr_n2k0umOY2M1tvlwilo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/af27519bf332812872fa0ef558bcd660/tumblr_nocnpiHCE21s94k0yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_m5v7dzbJUp1qmbg8bo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6c327da20a288412f377c4a60e59c050/tumblr_nq5895bM9o1uxvfroo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/afa0ce989be3c14475520ab0bcf5ebb9/tumblr_nqjx8n084f1un7qbto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f0e7da06d6831d88d1b6f619befd4926/tumblr_npi600GQ0E1utxmmqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8e0eb360e453c789794cc69d60325bac/tumblr_mwl1p3Nsh41r8d2j9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d1024e05cd077f61f7ec9c3c7dbac202/tumblr_nqcs6s9iuj1uykbq4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8279441e1826075f14905462077084ee/tumblr_npc6v49jBd1u2xe60o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/71c60f94a669e4ce75e64b72e86f92c6/tumblr_nnvlhfJwvw1smoes3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/15d17da7567559b948ea6c8d6579c43e/tumblr_no7zxrrWqh1uuiwgho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9f6b45ba359a7a2f06147b22dba87da1/tumblr_no5g7mcoml1t95h1uo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/cebebd4b810530bdd498dda5c862039d/tumblr_np7asmTAIX1qepb45o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/fae1a643d5ed28b3033f4d6e04672f5f/tumblr_nqfulbPdXv1uq26omo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e24013e7fa061db66eaecc3b385d5cd0/tumblr_np3ezmeN2k1tl1uheo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4e4feed73c261293dd730cad835e5c13/tumblr_mm51lfqqEa1qat2q6o1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/675588bee81e88588f58cfda5d24c084/tumblr_np8vq8ZDc91u0siymo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1e63ea659f3f64f0185be586cedb2e6b/tumblr_no3aefxteb1unfvrwo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3e1f7b2e7bb403b5072f0a32d9377da8/tumblr_mv1d9uzrbV1rxrj6io1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a201816db27d15a2bd10ab4a0bf2bc84/tumblr_np2fz5cvxL1u7nit3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e0d11baad5b250c1cb7219efb6d14c8d/tumblr_npdq1e8kLc1tqw3t4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/cfdb5acdf573fd7cbccceef938d31234/tumblr_nqo4fsnj941uqz4z7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aae3129de69a797c79fea8f2c298bb15/tumblr_noz89kdcvQ1sljn2so1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6379b5252777998b0ddfa85f3b446948/tumblr_nphmm1dTbB1ut18y0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/65c93c4975a255e7b794e596fa412bf7/tumblr_no3swt5pjq1s6ooqoo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_lzcthugd7Y1qk5118o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/13d9e3bdeb89276e8c0bbeb50c82caf2/tumblr_npl1x1BJH91tbt8i3o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0d70d578b81a2d97d7fa890ac96f806d/tumblr_nl0p6pB7H71upv3ruo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ad63789a59056579771e3578dc8539e9/tumblr_nq5yhfCCFg1tm1h5po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_mdf93fDPuQ1qe7lq8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7744f388eadb86a74888caddc67e8c7c/tumblr_nnu6thfdXU1uuiq8ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8daf974b78eb823847c3a9933eae9fb3/tumblr_noatwbKFcy1us5dico1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9cd20c356d865a2ebae4a0bd4044a50f/tumblr_no1jlzYbVs1uv6e61o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/67261282413c2d5441069119dbc5f75e/tumblr_npvn1dwdQM1te94myo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ed570b1301c880987d14b0ec9d4e47dd/tumblr_np2no5ap0t1upy9vho1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5e14f5544cdc78be45ad44633063e439/tumblr_npa02uS6Qa1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/372e74dcf76b0229a6ec915943e88fea/tumblr_mmpsui8E0Y1s2x7d2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/138a6c4a6ecb4d174214d12de90fbf2d/tumblr_nost048eg41tlczuxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5baa94f6df964b50776f9c781bd2d9e5/tumblr_nor0nzZMTk1twrka3o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bf4f0899adc2d844cad3afcbc9fda1bc/tumblr_nnv8efkDCK1rqru0yo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/55c9d4e6e0b0a119a4c2de89e1ca7d30/tumblr_noygx8HxR41u3dob9o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aaf97458ccecf22c7504c6744b2e39d5/tumblr_npydhakB501u2nl1lo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3ac8d1464994b81832d65949237e1b28/tumblr_nprfvxFqtR1tgzp5eo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/896d4bc21bb32d589d1f94e1c1dacf35/tumblr_npbx8sIsp91r7h56fo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e6bcf36c40b23022f1fe3509115dab28/tumblr_mo1mt73niR1s9r1lzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a86f0d4e943162ddb8a44dfc7206b52b/tumblr_nqbvhwvCRy1uyu8wlo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/af8fe3cd995f90bb63a4c99d42386dd2/tumblr_npo2qxZw4N1tuh8cno1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b51ad1d785c95c77b3ce215a6424c8f5/tumblr_no8uz6s5HC1utw5ydo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/493b15c7d9796c01c3c0126710f8235d/tumblr_nin2qcSgvZ1si8bj1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_mdnh7dcU8Q1rbc7gwo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c9b02791eebd01cce3392af7bfb9e18c/tumblr_noij67d4Hx1qfozfoo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a6cab9e995b589b015d1342a2e1a29bd/tumblr_nph3phsaS31tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/50c83402723fcd13ebde6ebb0ae75ae6/tumblr_nprnkokv421sngy5mo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/25b691d003977013a0cbcc6d62f33e84/tumblr_nqj9wr1Mwh1r70le6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c2324622a7a657b54534e354736ae879/tumblr_no8w6r0kgc1txfv4oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a5545f556025155d6b9a38af6099d03c/tumblr_myhegnaFKB1slobv6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1a4e83bbe463c6689f1c4f7bb57e6cbb/tumblr_nqbmixUhpg1r6lru6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/bb97c61c17b16bfe32836726339e3ff3/tumblr_npn4huku251rntwxto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ba1208bc5acdd346793a7f359830301d/tumblr_noiwa3hOh71uvm34co1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b86d0a51f9871fe7faf9392b119d1aea/tumblr_npkk29puDd1sd04ewo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/71a06c3669b9719bc2bccea681ec5579/tumblr_nq1n7aSs0x1rauov9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c9d56f1ecd6d570b0942e6ae348eea32/tumblr_nptkcvpUzR1sfwwm4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m2645rmFcK1r94e9jo1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7f8216a86a3bdc7a7347aab68676cd73/tumblr_nnvvpgeXHI1slwpo8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/03d099d2259a73c8562b577947a078aa/tumblr_npo6owzrlu1t95h1uo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/350c0c3e0de6835700501fde3c16c0e6/tumblr_nod668bVJm1uvb6v7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/81882e5c4efb6255d0cdf632ae625d62/tumblr_nkngeqipdt1rq4ld4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c872849119f3d657909d559dc554ea0f/tumblr_npdfhkVmMZ1tqub6no1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1c4db88316da722130e4bbb6c8c0e25f/tumblr_mfik4bLm001qjczh3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/367541e6c4c42a4d57602b42a331ca5d/tumblr_np84galvUX1rkaxwxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/38837a9027695d5453aa576e37aa25e3/tumblr_nq58t0seaP1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/aafe5639b9fc700ca3f8dd6aea16e6e0/tumblr_nosceorkcT1rp5femo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2894463a3fad27b5a9679273b3427ad0/tumblr_nnn52k4JF01tkylpxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4f24c5e8191cd00515af09e9c73ef1c9/tumblr_npl5x0kQMG1tpg4boo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/17ba6a7eef62024c0c5d09d1d37b916f/tumblr_nig2grFiUO1u8baqdo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d51c5b192b07b8272fcb359fe8acc4ac/tumblr_nnxe5tev4O1sxv56eo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/66f27a2bb92e76d45cf13769541781b2/tumblr_nfpvg83c5g1sqopwho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d1fd0776d6ff16f6c48110cfb11072ac/tumblr_nqawuytuK51uoysw0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bb7423391d2de502c0e9d53f300738ff/tumblr_nhu4k5vnhr1r05f8xo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3131618c1c5f384ffb594185824e0eb4/tumblr_nnw1ctQgiC1uox5rio1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7411a1c1ae9e05b51c1f7bb3586a44b6/tumblr_n54127N4QS1t1lt21o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/fcd4e9527a45b31a5193cf64c76908c1/tumblr_nptcqsYgIq1uy9d0uo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_m7yllsVgyn1rc8f3qo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/d42e218054b2efa08b689b32716f2be3/tumblr_npe5207K371rhqumko1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/63f538bd6529ef275654cd383decbd4e/tumblr_np72ardvOR1tsjw7po1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ebd4f5bf5e7bd0f9fc38c9a388df5b46/tumblr_neqq1vuaSM1r5pm10o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/70146871b3e1040757f5d55ff05c1fce/tumblr_mmv4uikxLK1rbvowbo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/11dbc74801046d27826ad18056fbfd39/tumblr_npszdte7gG1up6w4ao1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4c84c1e27fa75a4cdbd51ac12d52c366/tumblr_np9rqzP58k1r8weq9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f4f8795df99d22bdee117d45f42188e3/tumblr_nqjlvybCH11uv0y2ro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/442c4ecceaad0f8cd93f8c67d6e0a1b5/tumblr_no3mwfQ62p1sp70bgo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0292744e16be4ae2a7871c1c536a80d8/tumblr_noghc2g61J1ruqqm0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/374b67a33ff5a4d5fa55fd9fe3a20f2d/tumblr_np2ze5ZWJE1roilp1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5667438be4f76c2cda46b8f53338727a/tumblr_nnz67r1sex1tku1meo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ef3fff74b9067427671a157717f3e282/tumblr_nn0hufJNj61tvn50co1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4497a60e9c2b198b10f88fff39e2d090/tumblr_nqdzq4zl7A1tk2ngvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c93926cd5646094f69cae457af8f12fc/tumblr_nq1vj4DCUa1slwrsuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/894de66bc954c102c069aad15e41a7bd/tumblr_no5x5wmcd91u0hk7xo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/f468f90e015e9f89e8f339a9ef172081/tumblr_npu4dnNtOk1urnbuuo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/67fa341cff1fbd2e7b2b401c16fbd656/tumblr_n2pfhf5IAr1smjqubo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1b7396f4fe5267c39006615b82dbc6bc/tumblr_nplm4cPCqX1uucgjuo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/4833589feffc335dc90099847d4e31cb/tumblr_nqez7yS8NC1u89d16o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e3cd1bb021ad25fbe6ca08bada9aac17/tumblr_npu9m4sY631tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/66ac212895905f0a4268e2681f057c6b/tumblr_nd3xt8Whbs1sntdkko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c4a6d5f8730581b9219057e6ef581d0c/tumblr_n9r069pca81sacjxfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d024fdb057a1b21de4da5a98c904e5b3/tumblr_no7n2p5CZB1uvtfd6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0024e9be14003da1f28643fba2ba2f1b/tumblr_nqn3eyzyrn1tselino1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/5ac70a6b273db6ddb1cfa75b15985b63/tumblr_npohotQkDj1uxv5f2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/45edcb08d6278faa71cdc6e88cdc76ad/tumblr_n74kikuGnc1qjpgmeo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f8427eee21befc56b9f22845704a1598/tumblr_np9i9hSQMO1upoknlo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d67706e605bd02672f1667a6cf0fa07d/tumblr_n0sn6maIdf1s1uj0qo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/49c0fe7f5a2fa0cc787cec63621f663e/tumblr_np2lt5DBYL1szth46o1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ac239c829c5c1584f708c78c45016bd7/tumblr_npsvmlDFg61uxd2coo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/26fcd29d3da5e1818e1514a97a2ff761/tumblr_nougb2mKcn1uqufpwo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d02ccf7810d744e9386d796c0e6db269/tumblr_nocx09SAOB1tzlueoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9772475d5479834c099d753957d6d589/tumblr_movfcwjaec1qava1zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/cbe4f8271688731dbe008d446a5e221e/tumblr_niy50ovJpn1s6bb65o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/46af22a613c2a3903d87355be6d72b22/tumblr_np9o3pUg8j1t0z8f3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0e75a481176b9e0300cb5e1e77760371/tumblr_nqil8vs2n71u9ap80o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/eec8de9a1e98124b8d31b2d61d7e5a52/tumblr_nip33gx8Ln1qdm98co1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/50fe75f114d480f27bcc49667b738b9f/tumblr_n8f1olgorW1to3k6do1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/18c2152d696f74d2732ab1fb8dbdf1aa/tumblr_np189opV7g1u3umtco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/808240253a0ff9b71304a2c36ac98ed4/tumblr_ngcvagFxlM1tbfwy8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c085068a444ad350a0745d043d796741/tumblr_ng2w2w5Oxv1qb2u78o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b57bedb2a5f30a0c39f3557ba2330764/tumblr_nqrrzgHyRU1sqjubao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bc1956c713ead3fd607aaa240314b40b/tumblr_mz1gcr5boL1sn5jpfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/795a0c69ab0437e0eb1698d53707d13c/tumblr_nqhakleoPb1uxc1ago1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e9cdec442c711eeccbd7b895f0f40159/tumblr_nnzybyK9Bz1tkvac3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9f83fa08620f9729d60b0e1985b5074e/tumblr_noxmebNE9w1uwd216o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5635ffb7fb25f8c867a423d42117aa1a/tumblr_npqq0usR4B1sp3sqvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_md2uwjINqb1rpvilho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f9552304fb64616f774329a0465aabe6/tumblr_npoca1RD9h1s71nvbo1_400.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/161a9877fd6a374ea72b952647a2be3d/tumblr_ng13ccS6iq1teec32o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/56eb09a0c6af5245998b5195d38d529d/tumblr_npasdlAiyR1tne2lto1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3608b1ce6021324ebb57636dc3dd2b0b/tumblr_novdf8kwu01uwyz2oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/396f16db941b1993ded585858fa4b237/tumblr_naio3qWvug1r2g49zo1_r2_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6898f8aed7279b5fe04281a28ed3eef2/tumblr_no5zcnCMcl1txhkc5o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/acc12f006e71be87536dd41ac9d5a3f1/tumblr_nqqezx59Ru1uzh88so1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d18226fe2d85bf5b82266ed03547554f/tumblr_non0fbApsl1uw7ajno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4d7fb3e1075fab484690f37a4d509957/tumblr_nj16mb42EW1r50znuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ed6b6b02cb4dc976000ca9162f4d306a/tumblr_no0i05LacN1uu3jjvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4331e28135fec81629d514231f5a6107/tumblr_mvbg1aL8v61qdlh1io1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/22da37fc1e6b13edc8e4cc24222ea4dd/tumblr_no5nu88blP1usf060o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d09a55135a03fe19f9eb090a6a6edca1/tumblr_nnv9deHxOY1rndkq5o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c2e8f5d8fb6845f21ba9c2716f91bc44/tumblr_nq2dvqTBQ91uytwf8o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3c05725c5baf605ffe50a5a2956ecfcd/tumblr_n7oijsC2Z71tve0jvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/607ed2d68322102ddc036bf8f496febb/tumblr_ncill2T0341spm17no1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e99f6919eea2fc1c39ca792d44312a55/tumblr_mwd768fdJN1qewtvno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/df72b26dd287df22954fad13e22b789e/tumblr_nokmg9hG141te94myo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/741884aff1fc197a7055847d0c857462/tumblr_no2mmk39TA1tkbelmo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5531528d91703fa75961bfc7056b741c/tumblr_ncdut2tTzy1rsxiako1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/560c56b7147de9c6ae8d0fc752e98aba/tumblr_novgbrdty21uqxkqfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7af31b06852f52080266cc9f052e624e/tumblr_nqhs01DwwV1uzs0cpo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/5a317e6abf2034945390e2927ea03c7c/tumblr_nplrrspv671uryi9bo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c8f5f821689b71936c3c37e87b56f5e6/tumblr_nnvjl6NflU1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/66eda1afde8f3c09e04f242ee500c454/tumblr_npmt5dX7031uw5dp3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1eb9fd58e9bc9c4285769bd2d8a984b4/tumblr_n5x0rknMUv1tcna09o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bb8353c31f143bcd95d819c3dd24465d/tumblr_npybepEjlJ1tecyvoo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e54d8a13f96b0e920083b496bfae5bfc/tumblr_nolvhmIOwm1s7cat2o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/238b245d723057b845f0ef4e1f26aaa3/tumblr_nqa4ojOOPH1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a5f27adf06dac45af78b4976707a2f55/tumblr_mrmmwo38f01qc03ipo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/404763853cdd099898ac4077c0a14f21/tumblr_np30s1AKvL1s3y0ayo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2b38c5840d412c59237860cf6b697ea2/tumblr_nq8f7oHxBE1u4hllco1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b7a33b56ae44d718d17e29f37b70b41a/tumblr_nqh3xcdbZi1sbjlqoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a3210847439a8e5701b0a4fc816d0602/tumblr_n0s9vrH0m11sr8ofxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6be9b86cff91b24828d25faa4631d250/tumblr_npwsn2Uzkh1sz8ro8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/bcf2aca7cc6dff9f7107d1d5f3576aca/tumblr_nox043k4vz1u7o7rgo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d315e35c97cba778d14793e327f7cf70/tumblr_mztaqeiiRL1sl27ddo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/da9da2385416aa3695a77039cc6d157b/tumblr_no0uw51Jtc1uu8arro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/fa6a31e326066bb27776066150c8c810/tumblr_np38ipgJPd1tkkgpso1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b9117bb1ac28ea912a7e6598657c1c2d/tumblr_mny4wktdKW1qlydolo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ea49238f4921f31cfd64a154dc48d347/tumblr_notnk1Kf2u1tyacdbo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c103510572ed3b2121e301ab24660daa/tumblr_nnrn7cYyac1tdtmbso1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d7b46386dfd8e751bdf68659eba649bf/tumblr_nqieolzDh21rg8fy9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6bb66071d6ace2fb7a06ff46989a441c/tumblr_noh16tVb9m1uvie7bo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/52d85a0172807144b2bc62064044dad1/tumblr_nogcrjNszc1ssgyoro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/171ef13e1f7e869a7a96870dd58ad80f/tumblr_nah1byCUTO1sq1l9mo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a7bc8552da5e187a28901f6ead947149/tumblr_nn83xcCkOE1txriapo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/52efe2708863b4c8aab9f87811cb4dab/tumblr_nqfec1K7HW1tbo6e7o2_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/106102de8fb00692e27e4fdcd8f65adc/tumblr_noe8ecaBNK1u29slho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/5eaa8ebc821392ae9e5f8ef90e59d73c/tumblr_nq8r3xmtQs1uyair3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/05a7e0ca2e769ac8095f12ee55705713/tumblr_mltmlqlzt01s84wqco1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a98d8eb5c8ee1f21a2a4ce379d9ede0c/tumblr_nq0ixfZLc21ssgyoro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c629f71a3449a7d1c9d3eb81d4cb2bb9/tumblr_n0qzgepUdI1sncaa3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0830b6b74ab1953c05abe37f6662a6bd/tumblr_noonacr4Me1u6iefyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/bf0e6698e8d4442c0623755cf47c65b9/tumblr_mxs6m4xP7D1t7xlyto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8875014de50539edb03bf8f993dec7df/tumblr_mp9b7xBAKe1rxvpseo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/cd30c810f51084cb670892d138a761a9/tumblr_nq69x3q6iJ1u29slho1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/146152f45679fd5432f59a3b85c467fa/tumblr_nmg4mhTtMz1tmq1g7o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b08685e4cfce0024fc62c7cec73e0713/tumblr_nqb8mvjuPU1tqmfzto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1ac2fdc202611fa3ad5dd6a8447415ed/tumblr_mrpcm2QTvD1rkqbego1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4e7d6627cb29553e71dd4d2f244927e9/tumblr_nco9m2EwE81s82sh6o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_m0cu9m317a1r0jbbho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2b194e3623e7bfac4e3d21f6f69116c2/tumblr_nmb4ptKWVt1u1vo97o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3dc9a6fb83ad3bac0a881bbd0cced08d/tumblr_nq4o8ratc11tpg4boo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/62320abced6303a004f9e23d64922589/tumblr_nqrfg6vJdz1use8l1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c8c21480ef1580b27b29165e361040e4/tumblr_nog9hjJi1o1srzlr1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/417e315e900d6a75d908934e29d4447f/tumblr_n3jhculo1r1r4s0hao2_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ffed64cbf6a67185efd37b4650de89ea/tumblr_no71pqFVFb1uv2r7so1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/53d81b25b6b2e339084f194aa273babb/tumblr_mtxi16Fm3z1qzcey8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2e9b920cc2320413f8ef0d6013bce3f3/tumblr_nonyfiJ9p51tgyhk1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ea63fe62e8b71da9e1da013df1a33e11/tumblr_novnhymy7Z1tqwtb6o1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/faa880b8c717b6293341aea7bcd31cc1/tumblr_nob2gbuEYN1tgz3uto1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/59990df18cb744bab133cacce0c8ec57/tumblr_mm2xctspjA1s5fcf0o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ad103546f8ba9f9a3fb635eb6c5f8bf5/tumblr_np0yjqi9Ca1qa8o34o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b3264b6b232b6c540cf45c28d67aca51/tumblr_nozo03ztEt1uwzm31o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/dfa439f2e73bddf5a9a7cf54a365eee0/tumblr_n5ecl17WVT1s580k0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2c8c143b4772f143df2beb0c2f552c7e/tumblr_no1yulTILG1u4kw04o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/abdebab61102ac4852c17a62e00558eb/tumblr_nqq2uzCFCt1sogahco1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/633e1248c6103295d88d52e802dd860e/tumblr_mx0qn68mIL1r20fzqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f832ec07d678af46999ff9f1a3e7aef0/tumblr_noq3u5dbYb1qb5wflo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/508dd186c5a7edcf57cda10d8eff6d39/tumblr_nog3t4zdNy1tdjr4vo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/88bd6013c943b41c93f685e0577b451c/tumblr_noxbsuCyAg1tjhed2o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d5ce68d861c494402bc78f4c6804940c/tumblr_no9p0f8OG11sj6iyxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/11a0d99e5a3b0596c9e068db03a0d810/tumblr_noc4m0HufW1sb4egbo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c582957c697e5143ff023f62f99d2222/tumblr_nm7amzNbkB1u81ym4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e90918cd5f8d2714416ce3136f4d24b7/tumblr_nmigumGk8n1r5nnz4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/bd55d1e8a95872b75030caf660d46da3/tumblr_nogmchIez71uny182o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8f5d9f86ebefa35baeadaba5337d09fc/tumblr_nox28g9fv41tfkobto1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/154bc524bbd43b0df4dd79de8b64232d/tumblr_nowke8FVo41tyncywo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/072f1d53af076ae85823ad45bfb80da6/tumblr_npw23oocqT1toltdso1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ccb8d425902cbf2f342005e075f72714/tumblr_noet4fOC0J1un9j0io1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6aceb7b51c92b48ecac954cce85033f1/tumblr_np1dtaj9rl1tamfd9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6dab30764640bd3d1e2dab022a35fc55/tumblr_n39qazQRvB1qesf6mo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/ea3da39376ac2631c5b22a2c74c97b0f/tumblr_noo44a3mpW1uu3esfo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9f659499c8754e40cf3f7ac21d08dae6/tumblr_nqlr0rn8ox1r2r0koo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9f172fa5099d21a645058f69ca24eef4/tumblr_noym30fa7b1s71nvbo1_250.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/0718d453611b72676725ec8c8cacd7e4/tumblr_np950bMmkG1rvr6bmo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c061b02f4fa3ec998d548d16b5033d0d/tumblr_notk8nwiEJ1tmekg3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/06b373fb5d11b795451d61ec07ff7a35/tumblr_nq54nxjgmO1uqgleao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8e33548d3fc0f23b5f3eb2b2e92dbc59/tumblr_nohqoipcTO1uv0bw2o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2779e46bf99b587f6c62c0b1a38445e8/tumblr_nhkgz7lCxi1to7xq6o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4fb9948234558db20315f992345cedac/tumblr_nmn8zkxwZV1u76ef6o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d9e6db86ffe051d114af5e203041c663/tumblr_nq60vu5V2P1uyhug8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_lg89u9I1yC1qzagdho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/25bf109e98dfced0826fa310c558ff25/tumblr_nhntovlghb1sg3akro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c983154bf0058f8ce07161d0948679ec/tumblr_nq7wfaeON51tm0lv8o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/be9e0d95d1e904b8f8c74fd21acc7acc/tumblr_np3zf3PmG41u93ikoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/58f3daf1b8916c4f6212f1483317e01d/tumblr_npzelmySvO1tokp0lo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/41d53d769a33ede11d545c31639f9e3b/tumblr_nonroxdmHE1u8k5swo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b944ae33a2152083459237aa8a4ecf6c/tumblr_nol81xzgup1rt7we3o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/abf5b2e37ef0203e84b84947a7e0378c/tumblr_nplflyKBGP1uv6aqwo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/544d6ca1016396a732a3beaa9af0b2c4/tumblr_n73bd8z29V1rl3565o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d10c1a6d259e0f644d143cb4b8a62dc9/tumblr_npdondSdMD1rj2k6ko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/83e671f730920f3b283ecc01108e0125/tumblr_npnpnlvai41rggrn8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_lpvsjbAFyA1qin3szo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m49cbaDDkJ1qmhggvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f123a073b9f258bd8220e452eb9fdc43/tumblr_n59x3vrcIu1solxm8o1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/ac9d14d12d4a179a8b801b3d9c00021b/tumblr_nnxmrdJm901ttstb6o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/36b62236f4ed01f2e1b05a1d51dc922f/tumblr_nq3o5k36jI1u4yuwoo1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/08d4d3594803da1d8c14054621a8d7b5/tumblr_nhzcc9ojkY1tq8n90o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bf91b65df630087b6c6b6f9c1c33a9d2/tumblr_nny58jHdaB1sv57zro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/32385ff5a1c499508f794d190b4f664a/tumblr_n1ax498PC01s43mluo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8473173dd5fb1dd4f3e14841366bd34d/tumblr_no80pnyruc1urwkppo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6883664ec3645bb33ff7429403f7ecec/tumblr_nqfluog3d41uxae7wo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/fa5ec759c7a88c9c73c4f8fa14c12e58/tumblr_nk4fsnvA881stl30xo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4b0a51a342a5cda6b185b5dfa9160663/tumblr_npl8vsisug1raojyho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/56dedadb9bec93411e9030ee10a0e1e7/tumblr_no3ockQmcH1rchh3lo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/48ca3d68ef52f13e71296d675c9588db/tumblr_nogdse2ArH1terwlso1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4204524ef8b672c5b4a019426a16d31c/tumblr_np7yhp0tC01skdg6eo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b1d5af944b6a978a1890e166ef2dfb50/tumblr_nqiiyyW62R1u1s60do1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/35c40b626e9bb059401b76a9f68fc762/tumblr_np501x7i361uwnw3zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2a9e13b9fee2c9a839b87717451359e1/tumblr_nnncvfE8HF1r1zo9yo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0808103518c44cc93aef5447d4ae237c/tumblr_nod582L6cs1r34usso1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/7a128a446bcb1618e6cc64ddee65d4f4/tumblr_np60tm1zkr1suf707o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4cfec4cca4e9a39d622d194bab3530cd/tumblr_novqk8pQ3u1tni8izo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/467f5cd52529ef0443a06206e4f2d85f/tumblr_nnlbx6Q4D71rycw13o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ee43df90426c77afc389accf98838f02/tumblr_npkqpsxahN1trgnw9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cfe94f57f33ba5ce72b401d516b4605b/tumblr_npfqeasmon1tpg4boo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bb260b7a7b5adad80016679aea7581d0/tumblr_mgy1z5TC251s3uwoao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/8081960648bd834b2d516b3caa754fc1/tumblr_nokwt1ZuPX1u5ha5do1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9f60bb5bcc146662dd2e870d434753f9/tumblr_nnwa6owraP1u22uuio1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/206bc1dbe1d90bda92525961c3b68599/tumblr_nofugycyXw1qlufgjo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1d5c7608b2ab26a57763eae6f2ef0a60/tumblr_np4l4imctT1svos5ho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/703e090fef75de48b5643f97a56f0e19/tumblr_nnq3q4XRgn1qasriyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/458441eb072d79c7f2e4b116e8f4f3b4/tumblr_nosc2tb3IA1uwtn8oo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/81243a6a1f96a1487117cfab7a3a043f/tumblr_nohk3qcxJF1tlq8yzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/568723fc6d9f4d2ba0a88ef41a307607/tumblr_nplkb9vK5m1uxibfho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6e96a0d836c3f58c903d8106ec03db54/tumblr_npuofnTqv91ux8j9oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cc6401dfc3745e3423bbbea61e151bd4/tumblr_n4otdiiSUU1qk8tnmo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c34bd4a859e23c5e92ff229281480868/tumblr_nmfm8c3YAw1tdgyr4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c39e313d7c00de535710b0f545f4d576/tumblr_nova2lDzB81ts6xq7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/374df17464dc976df42426d36c782ab7/tumblr_my8ye2xNbb1r21jqzo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a000160dc78a6734d0c602aa92f76e0c/tumblr_nlbwz28PW11to5toio1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/21d9ed82de70b2c291351e063dd6b679/tumblr_no621zaINk1upeu3bo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m8iylcLVHX1qkiilno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3004d581cfac1308c5c8bfc85aa39bab/tumblr_nnneazNSxY1tgetb4o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a1b9d0d4dee6e062e9c88402a9715961/tumblr_np9lj0gvyC1ssgyoro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3e7f7607c6da7af9ad466fa852966795/tumblr_npprslpjMc1tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2ca2872148b2eec7ebdccbb2add24c0d/tumblr_muxwtvSy9l1ru15a3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7eb4e7b2e54dc2f94102ca5685831915/tumblr_nnc30ryZVP1s6ayelo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2a862168104d5db4f4b89a1db47d28ab/tumblr_np4gztuD1M1siha6co1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/08f8bea4551feee1eeadd55144d6a3bd/tumblr_mgp2k8kDzV1s00n1ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/438b763a7b4d38b3a383f4c4a302bd49/tumblr_noft0xhoTM1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/48de53dd09ee8de9404002e3fb95cc2e/tumblr_nqr991zaOa1u6w3s2o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e77d66d22e8db54154ee18e36a07c995/tumblr_nown6vFH1O1uvl7i9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3cc8a677e4c0921ca38887a7200a2dde/tumblr_np14sfWui11t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9119541a127b3d7d70b4c50dbaffd5c7/tumblr_nod1on0UIa1tnrxaoo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ad1dc77293205a5d3e437d4ce4bb7e05/tumblr_no9qsrA12P1sos5oco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2539a391e02c1e9c5024f9c3ae721b5d/tumblr_mnqf46GrUd1s25srjo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m4zaegalzE1qkr9s8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/5ea6c49afcea1b7c73ee0a8fd4d0325c/tumblr_nour3aj5RW1tx8mn0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a0346be658dc8951df321249ac3b66c6/tumblr_nndo47uAtt1u6ot8to1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/3bdc8551bd5b79b314293e28d719330d/tumblr_nheapfEsDO1rs6d2go1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2e105e55bdd3320bb67c8912fd15b0ca/tumblr_np66kkAWzs1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/446c5de3fcbd74e443b420934caf4875/tumblr_mik6evvCLD1s51nvto1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/20f1e38c1a421966f6b343a88472c82b/tumblr_mi51e446aO1rpv1n4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/da10637bdbf1995637048fb700c4960f/tumblr_np84qdCchT1uwawnfo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/35bc5bf1f887d56094aa90683081a174/tumblr_nqgkogmbfZ1uyy4qpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8dc9dd11fd77e14914307542e9606d08/tumblr_nq6wkzewLk1u48f13o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/dde47dbe37823d9e9de60bdeb4eee0b7/tumblr_nok9l2MwSM1tkkgpso1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3d63d23e24177e6ae90b947e3c34a2c5/tumblr_mhx2acNSi61rlp86po1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6f7d2752922c1edd236ed9db017a1270/tumblr_nl2gbdwW8x1sp7rs1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3a248a1cb68ab9a9b560179e470829a7/tumblr_nqct5tGUJO1u4i90so1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2338dec6645150803ff476950932484c/tumblr_np721hktS41tnz60vo1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_lzkbdsC14p1r1iaulo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m13poc0nOL1r8jpx2o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/10ff23009e114283e45e0f493cb117e5/tumblr_npwrzzGcNQ1uv0y2ro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/46d92a34925c1b212d72015950d2024e/tumblr_ndk3u1KQ9h1r3z3gbo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f64e7741b29c1274bbbdc95471d1cacd/tumblr_nnvn1iwIjA1rxlfkeo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/83404aacb72969a3ec46b0975bcda617/tumblr_nqoefbHBuY1uzdp9zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0704014c7db5f606ae2d257505df1223/tumblr_nqf422ExQZ1qlzrezo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/59aaf4e1b321004926c1e1547db8089b/tumblr_nooqxpCvFo1s8ypszo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/07302c85d3e8e3594bfbfdca6f589f09/tumblr_no3d79GBdg1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cdfe1f4a484d5bd34fce192cd58c0776/tumblr_npqnrvnEI71uvie7bo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/354dd532533a4b71b2dc3287099c4e9c/tumblr_no3hzg8rMP1tul3cpo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3e10710b8729c85bc286dc91d6a376d8/tumblr_noej1hUM2L1u9aocto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/133fc150d1cf430e5ee1676277af6948/tumblr_nnw03hUFar1ten6vvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/2d09a5b2ba806e9fde5d20b481f25742/tumblr_npueuj9nIc1twcscxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/25ab3dc0f47bbe5cf04e38c06dd23b4b/tumblr_nnk474G8Vo1tkkgpso1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/629a76f43f0101af51037c7d5de04d64/tumblr_np4da51MMA1u1j0hao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b8949ec957d985c7ec66783d37dc3f27/tumblr_npbt3pBjBE1u7b84fo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/eaced7202cf913e9b6bedff6a82b2fca/tumblr_nnoyzkr5PV1s06q5zo1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m91o5qidUh1r9lt9ao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/36b1146c0b56267a9c67239601cac7cb/tumblr_n4w7qaljhg1rjep1fo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7839792c368afdb9ffa9852a632ac271/tumblr_nq3rraJpfW1sht3fmo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c42ce4fdc04b6ed1c3979ebe08bca2fa/tumblr_mlsffcWywq1s6x0pho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d113acbd1b915773aafdc23ccdccf19f/tumblr_nog2syUjN81t0zsnio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/43f14c08187681f7bd736e3462e68a99/tumblr_noibf0CU4k1s6v6jdo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/84e9877843d42ea159f54852fb0f7da5/tumblr_noqxsb2Z4p1tmfnato1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4c2c15eabfa367d48640a3c03965dd9e/tumblr_nnq5ioPqq71tepnxco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/4f46879682406195468715d2f35b4922/tumblr_nqf8bkXvo41uv5k2do1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/170db9d24a18f337a7b4d1cc9b351846/tumblr_nof07svJs61qjglnpo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/df05226dfedc193a3564d7cf249bf474/tumblr_npxyd2fi7X1u18r6mo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/034de0c9c86c0447eead4c1b0837e6c9/tumblr_n3kmlp0wRt1qcgu4mo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d425889915fb8e65f23a2ded661e9c7c/tumblr_nbslefg5jB1qfyqv8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/603c3f4db926d1c54c568639a62b528a/tumblr_mtw1pvgOJL1sjxg2io1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b4aa3da1171826291d5584ac131b0840/tumblr_nqbfnv4u5d1r8h6u4o1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/2ef7883dfeeed298bcd99de6d7222aa2/tumblr_nqit84r72i1tfqo7yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bdffeb590e7a2a023f00bded9c9cdf00/tumblr_n3y4w9MaPb1qhndw9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f006067fc0a89de1dcb307f06604d0a9/tumblr_np0wsp8ZxI1sjj4l1o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d39d5ac86f09fa4784ae3ccc3a0511d3/tumblr_nptbixyok11uqiq16o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/62583bc8883ed07b8e201219314b8773/tumblr_mu9v89AwEN1ssjkcoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6a57725109cb20bed2f449368828049a/tumblr_nqfifbetxH1qizbwho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/635bda3bb8750b29cbb125b1c1e8ab86/tumblr_np4ihmx4am1u52uyyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/da800245af68aa0c651374b9a249ec93/tumblr_nocut7STZO1uubg06o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7204aa60a352908e5a3045b2ff37b5e2/tumblr_notmvlIMxJ1u1zy0oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/60b90ca650c88796739efe254dbf6f40/tumblr_nocdb57GDe1uuldsro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/76ecd2437cdbe2a0a91780d71c03b8ec/tumblr_npbrfwDYDH1qm3a1jo1_400.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/bd05db0f1310d650162202fd5972bf7a/tumblr_nnygrzw8l51rxvwz1o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/bd7c6f9d6e14ff25f1ceac4f9ff56ad0/tumblr_noxmn1uTNX1qmtfiyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/fd7af19c7d2f67a2d847b92f10c11088/tumblr_npncljKp4U1uv0fwfo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9871ca9040114c3f66c915ba47815f75/tumblr_nq75scH2191up2hw4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1cc985bf9ed0eb0f9944c4d84aa9ce33/tumblr_nns8l32IXH1tw2si5o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/66bab7078b5de6f679db73c0a5e88ef6/tumblr_nn9t6ushtq1sf2a1uo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/400edd731178f6bc0b9825749bc06e7b/tumblr_nomm7svQkP1uw5wvvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/67600fcaf85d14a30c4915776146260f/tumblr_nny2x0HXEO1u7d8xzo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ee32e994c8d94407953ad5ef1c00c4ba/tumblr_npg6yaewak1utmlppo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0e6853b267e77457f9e8fcbd88e0e736/tumblr_no13pjE02h1tyncywo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0d61c831a34bd043c8fe379a08e8cd54/tumblr_np38uy6IIG1qfozfoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6d13cd7bb62afcaff0e01c7ef12443eb/tumblr_npy3zp1xax1uv0y2ro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_m8iceoaCKJ1qai089o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/52b5c071d2c7fdac01c01b7b5a83fd11/tumblr_npgrvxfAZV1ti3vf1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/548db1068178c66ab276c440d6ea8292/tumblr_n0sdqa5FNm1swpjkio1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bf1e870609dcc6f7db269170e7a9110d/tumblr_ms4zqyor8S1sotkxeo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/4c5339797709327802997a83b9e4ac95/tumblr_mydwxizDuv1s2arcko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/7b3166541af313c3871c94f58eadfd4a/tumblr_nnxm7tMHAs1tqce4io1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/46358fde3f99f9fb2ac5137bf1976c43/tumblr_np8gj2R3oQ1usxqmpo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ada0d51756b100f39c80de0a99ba93a6/tumblr_np3gazsr9n1sx0b62o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/95d832b90dd6b2ab27f72b523877fa6a/tumblr_nq31h6FLRp1tv7hiqo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b2bcfae28178d94fae86665559ede509/tumblr_nq4m24sK8C1ssgyoro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ebb5967dd5e66d72d8bf9699359faeed/tumblr_npa6soLP1u1s6sjtho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ce4ac5fefdb1db35ef515220fda76a3c/tumblr_nmu0mpj65K1tm0lv8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f81a5e18de479d2760e03274ac41f5c2/tumblr_npz2mnilXX1uu6kufo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/aaa23bcbd4c6092b8af8b1281bbe5120/tumblr_nebw46qbQg1twu5h7o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/35a28d9eab754b276e01e0b3ebe5d1ce/tumblr_nowlzwZJA31utzfm4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/10605f270aea010a476428774a31da12/tumblr_nqcd1jMdaz1srh93no1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/493894249979defff2025a4007c96ed3/tumblr_npwa0350JF1u677wzo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e1f37fd852f89c69dfbd2eb247c04c5c/tumblr_mrwxgcfVZP1ryb02yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/16fe1e2e58d0afc70e0500f716a7cc0e/tumblr_nq5fxy4BfN1uuv7f1o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/669f3a6676e42334ca199358d56723ce/tumblr_npdhwhZt281sxvd87o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d4107502b817b352cb05d592240d1241/tumblr_no3dj4BWPc1tmxwnao1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e93b9880095a4172eaefdb2c6f6f359c/tumblr_nb89stvwiE1rzmhj7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a3dc61bc05be3a60aa8e6dd0792936e8/tumblr_mgahriFgY71qi7ul8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7dbbc375111772b3a198b3e408b83615/tumblr_np5dq8G2aX1s0bfsio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/62dd09a4d6d386d2d98bd414cc0c88b2/tumblr_nqq50rYEHt1ursow6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ed5429cee777dd980c9d7e44b36d9e9e/tumblr_nq759mTCGS1u9gl9bo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ac55a0d6a5fc49258ca838866aa69981/tumblr_np4o6mxToj1siha6co1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/68cba0f227dd23862267f1d386b5c33d/tumblr_nqj300hiOV1tx8mn0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/17d2a91afef8a07768fa846cd400a9aa/tumblr_nqfczbLLBg1uuvxsao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/131e1068070619857a9247f2ee77c46a/tumblr_nh6pdt0zcP1tbse9vo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cea5117c803955b4c60865ec45d1a10a/tumblr_monxtodQwn1srtmdao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/624fbaafdf6f3f6a6930e461c44cf829/tumblr_nosj3gJY1D1tr734qo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ea8b2a4aa8102b38ca60c71b19a9bb0a/tumblr_nq9y1ecJMs1ur5o2oo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/227087b8a6369e0fb570ef660d688064/tumblr_noz7p7OzY41uvie7bo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_lrdhcv4qkC1qchde8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/58dc0c6ad3f86d7fb1d41d64d5713878/tumblr_nottsrOsgv1uw6u2jo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/76795c5d44f8e5a4a549f494339906d3/tumblr_nowzu5MZZg1s3att3o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/719701f685f39fda9010fe28b74a3495/tumblr_nogs2xEehE1slkc31o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/fb2ee95dfe0a8f340040715c2c3d525b/tumblr_nqf700a9xo1sxp6k0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/7dd6fca24f6285df44778a17c9ac4340/tumblr_nocyedqEkK1r74hm4o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ae3778ba9a1365be4e31468a010a4331/tumblr_nq737gAqg71sk96t7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6d5d2bd63f5303dbb4651db76df89976/tumblr_npa0fhkoBp1uq9ss4o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6b47f2a5b95d706323f67e6a7a9fc024/tumblr_np2eanyUmm1uujapyo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e0a0addab0e835cca166f07977cacb7d/tumblr_n6ksyhJU0x1qi7wceo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c59dd38cdf38909991c52f60f5382b35/tumblr_nqdi6p4Oe31s18hd1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/debcc7bb96b33c231ed70aacf4fa8b85/tumblr_nnetx3ygrp1tyncywo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/447653d1d67d26a54bbeee662c0efb9d/tumblr_noxzppi0tu1qanghvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f2874c40710d9e803f457422819ac2cb/tumblr_no470gjBjE1uvnyzyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/33b9d3e36c8873b73a3bc1425ad7055a/tumblr_ms7ond3YHq1sfxvkjo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/5dbf49bacfb4236b7bef3644f32d55f0/tumblr_nfaxk2MmGt1s4hjb0o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aed6ec8ce0abdaa71e2d9fd0c4c02d73/tumblr_no1mymaXxa1un86uao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/46215f80885b4b8198d492c54b38618a/tumblr_mn483woWOb1ql8g5no1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c12ed03b076865b4a431378fc0b3a3cc/tumblr_nnupra7cyJ1u7uyv3o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a72dfbfbd15ebdfe7592ecfea3626ac6/tumblr_n7en08dZn41sq1ru9o2_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/73f150a80ca6a2cf54bb9952f341c471/tumblr_npswqzERhk1rir6ico1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8c7486d02f73d5e5a11e8e04a2e315e4/tumblr_noym6cnA5o1uwe1o1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/da72cdfe4c0f192610a21b4474ac1040/tumblr_mmsrglhouj1qlpa51o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f62bea0d755eb1de6936cae84ea45954/tumblr_n62qhyzKze1qf5do9o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c9d4ce90b819c372dd953e42422fa150/tumblr_nqo3zpNWV51tyncywo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1ab91937696bf13772f60b67b02ff57e/tumblr_nonl7wcsBr1tn8u6no1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a56359972856860dae178804cf85e363/tumblr_no22jv00hd1th31wno2_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/161a32dce66137aca7590cc17940a37c/tumblr_nqh9wfEWyh1uzqg52o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/58ce809287f95f922bf1d84e0db59721/tumblr_nhx4fim7F01rjq3xeo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a9b3833f76f34628a7960472372104e5/tumblr_mx07f9b0S21qbixjvo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a4db891b9346c124d75b6b544181e6fd/tumblr_n8s6xrgY2R1r2a24bo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/90d8005c52916c19af9273d75aecb734/tumblr_n6bcubivX51rnczq1o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/39314180a6da4188c227ddf6a7963f0c/tumblr_mr0tedrh151s7m6b9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4819c0ba677f46cdcef66b366506b627/tumblr_noita1Lx0H1rfiaiko1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/628c9644add996bafd646ec98aeac8f7/tumblr_nojv04ixsJ1uogow0o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/cc015349de6b1515521ab5bb800c8e7e/tumblr_mfng74vDAN1qgmlbeo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/4907ae368111ba3fd8d7f68eb710b829/tumblr_nqo3ntxkJG1tyncywo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8bde093f2dc7e8068d86e5117f2bd311/tumblr_nnzr7iBptv1twbw0ao1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/69ac802f5d2f29d148a07396d661e2bd/tumblr_ncwifvqwH71r4dtqwo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/d10b287d27f2a15786b4035f67f9eb7f/tumblr_noz887Gi3H1u4op99o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/dab63ad31ec9a000c707f116a54e1796/tumblr_nofj9dopJz1uvhr54o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e79707c4fff6bed54341b5e9062f7200/tumblr_nqcy3vDYvq1uz66aqo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6b59224c9dde99adcdcb3b28863ba09d/tumblr_nmz45mfJbB1txriapo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://31.media.tumblr.com/67c09ab7a24e4320d2612cac3c07a728/tumblr_n9nzyasJHp1s4eppeo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/df1eea953db9ffabcab51068a94e2daf/tumblr_nps6hy6L9i1tbn1tto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/473e25daad9f03e7bcff5b8683722c23/tumblr_npubzgvm3P1uy8wtro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3a5167f608a1faad0278f58c3e3106f5/tumblr_nd38ujB5QU1r54sqpo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/99a212f949c0aa7aa9f122a24604294d/tumblr_np0ppkwkTg1u2jj66o1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/06651172ce4f16117a946b128efac82b/tumblr_np85aycg7h1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3b9bcf71c20716ea391866c195b6edf7/tumblr_nowaflSELF1un86uao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1474d82276c22cb6ddf2a51000ebe197/tumblr_npbcj8PAh31qzqavpo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3210a08f864ba74cbe225c6b16a13a40/tumblr_nozfj5XXMG1ssgyoro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2e48ddb7fd99864695e264feb5bb1d1c/tumblr_msiu8tOfJt1s1fedro1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ec5c17f6d6469b9bd2a9ec0e90c33f5f/tumblr_npk15dzlsi1tkhxdko1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/51fc72a8fe35403cc619776e29e0a619/tumblr_nq2qsjdDw31rawuuio1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3176c2e650bcf2d7a61d74ee039f1cad/tumblr_neii7dBvyP1rbqh6zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e1cfa9139d1a9a3ba2365807c13ecc8e/tumblr_ncl7d2DRMe1qbv408o1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/aa4ae0dec95be0ff596d57805ac9a298/tumblr_nnvnpjUaYW1rl7g4lo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6e44caf283157e4c9da10d40d98a60bb/tumblr_nqkig8n6kV1ruvp0co1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/b34dfe94eba2677c09f8107cd822db3b/tumblr_npswzuXNTP1tk15f6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1a071799be01d93a7aef5bf6b1d688c3/tumblr_no39diamj71tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/820ec342e12334d8875b4de14610ab2e/tumblr_nplo6cJC1p1tavcqno1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/dcddd71e154594566b7841df231a618d/tumblr_nnxda5gaLD1sk96t7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e40d19b8dba694aa7d4783f383333f4b/tumblr_nphzvnpw0X1urqm0mo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/31949a2553c0368169cc68437653c39e/tumblr_nqd7omIVkp1tyncywo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/ce487d12a28db0910e1fe7ebbf6160e4/tumblr_mw4jm6GkDw1r81ck0o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/4d5827968ff59f7aa0be1e22c9e05367/tumblr_mki3hzAc1c1qzxepjo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/3d92b6b9ae5653d1c0223209dea6a829/tumblr_nqd55sRu1Q1sp10zmo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e3eb2857f08fb3944d6dc07994d7405b/tumblr_npe0uh9DUI1t95h1uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1b0c89f4f3c6a52873cd33f6f464e8ed/tumblr_nnw75k9WDm1sp70bgo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/dc36e1c20a1317481a63ee7fee7a6872/tumblr_nos4x3jR5y1u97nl0o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/71a30f71159da28fee1c12a5522cac74/tumblr_nqn0x0UXMh1tc7o0io1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6802bd334e510c03b02448487414c4da/tumblr_nonzteuxkm1u1lr6yo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d261a143d385da97a429fc003e043278/tumblr_nq0dlflpc41su33lco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7a9c2e7c56530c328fdc39def5113d61/tumblr_np5ms6jV1m1u1j0hao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/bf10dc987e114934d97a954c436488aa/tumblr_nqc9g2CP6U1uz14aio1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/65693f227c612d9867a0e921e9e34e64/tumblr_nogao57y2O1uvizqwo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/838a4bfdf717fbcb9f54e939fae2c715/tumblr_njmcgm94XE1u8h2nto1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a4f1cc7cc7cec90c0523c67ace538d37/tumblr_nq0dljO8xg1tfzp64o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a27468be43a2d4e35ec11cf30477090c/tumblr_noe7jz3RSc1uqbtlxo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4ee437e7d39c9b81b8593cc1dc5543f9/tumblr_nqm0f1sKEy1tatu74o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ef52c095a986959854ad28201f41a1a0/tumblr_nk31e2Gs8u1tbvxwdo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ce3564ee0428e253d576d47b60e96437/tumblr_npfnor7NrQ1u7r4j4o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b014d15162e9f53ba08ad0d831605495/tumblr_no557g9u1B1sh5ngxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4fac4125b79310bbc70c2435a00c7beb/tumblr_mszyl11pL51sej04uo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b25b67e59bf7ded8cb155b535972943a/tumblr_mfu49oLuVv1qfdh8qo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/fdfad4f540005c2e4f12eb4bec367549/tumblr_nmst6n2rYy1urpssuo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/39fd938649b1ae08067ea24623af6a0c/tumblr_no1ph4Iwqk1to3k6do1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/59dc5ae32d07fc4fe22b9b798a2e8321/tumblr_nn5zkrrTNs1rkpz4po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b7ace93c4db40fb7d068e7a4e7e26de9/tumblr_npl1nb7vhf1r0c7xro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f5c6c7c4d10ed2d183b343e4f363cd7a/tumblr_nofejelhMy1qhkbk8o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1c45dd30a4cc819ce9d214b97686f338/tumblr_noh3tel9iw1tnl9i2o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e1515b759e2240b745a7467b3c0c2a34/tumblr_nof302WAjH1tmemojo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9ea2d3267ea4debcae9b1c2af5e83c2e/tumblr_not2mzWG3Y1up93i3o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/81a386aada30959b5431d3bfbc9692c7/tumblr_nh60qtKtp41r9rffqo1_400.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/486bd48118c5078b0761126915756c61/tumblr_no4pi6ZhBh1twbnt7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/ba5c5c2d772100ecdf5b5c16054845ba/tumblr_nnxy2hwox71ttstb6o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9693258ab69f3b77b1c4dc21969b770d/tumblr_npbbhj444c1ur6rrgo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/21db5b2eaf0a1654f8a8f8ea4584e051/tumblr_nqd0saY9331qg25mto1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4fcdcd5290029d6af25e7054b4b602f0/tumblr_nobcxyCgg81uuxd1yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/31aa4364934ff71ff9a6afe809b66a4b/tumblr_no8x6b6rWk1u9sthuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/05325e2d891e893fc8443b4e113d29cd/tumblr_nnq3udISMI1tvlahxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/93e927626dd70481bf13b868def50bf3/tumblr_npuowrgPje1uth6yvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/9f6c25cc350f12aa74a7dc386a5c4985/tumblr_mevmyaKtDf1rgvhr8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/dcc146d77fa421d322fdd3e92b60e15a/tumblr_mma1pp0JpJ1s26ehyo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/72ba8466d0605d41b6c59fcede80783f/tumblr_nnv643VW0W1tkkgpso1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/e02aebb8b1cfb35980f7299ae1410f18/tumblr_npwvzdenxQ1ro917lo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/tumblr_m0a6cg8zC41rpavuyo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e65ca8fb6e74b1b8cd816f143d90e13d/tumblr_nmyjwiCfzS1ruxfazo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/4c1118e3ab67299567a1649b9d4b2cd8/tumblr_mzzge61dX11sar34to1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4f4e1c281e8bd63189a9cb22304ce033/tumblr_npyyhkm5I61uw3kv7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1faca3a77a83f7c16dee82ca23c5b401/tumblr_mo3tm0K8to1qzfebyo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/43bec99aa1c29618519d2815065b958a/tumblr_npg5enXGvm1ribrkoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/53079ee6ca0acf643446d99e2dbd8475/tumblr_np61e7spyx1tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7d2cb9ccee00dffe60237c2eefeede08/tumblr_mepd430TAF1rosr1ho1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3f341c4acad27d070cec5e23f7a7d030/tumblr_no46fgtMTY1tatohao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c9b609df68e364c767ce80f4d41ddbab/tumblr_npwt0ow1on1uv0y2ro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/b93675920935fb41aef8674fd7912609/tumblr_mzrer7UmYZ1s0udieo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a91bd7a8d4dcd04b4273d6e2f94a0b1f/tumblr_nptbugIfp51rumb88o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/67fbb0b292c74018362421e0153b161c/tumblr_n76bg5hchJ1so27d8o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/377ffadb99781f98b409dfb871ba22b8/tumblr_nnridz2GVl1s2gb48o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f05b0067eca755676d6e0186a66f9876/tumblr_mr4px7lTHy1rt2bm8o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/08a79d3d7cf84434095560b7003e5cf4/tumblr_npr5xqa4vX1rpq9z8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1137c40884e12f5d40077c0a0e0d3a18/tumblr_nnw8u9hNdc1qfgbtao1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1e6ad2f14579f6e5452084b7d8254a3c/tumblr_noact8Znx61rnfni9o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8a0143eba162e6a39cdc129c2c120baf/tumblr_noe6m6veNG1tb5d92o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/29f904562d49174778139bef55eba9c3/tumblr_mzj1lrCVCn1rdm5edo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b417b81d9b74dd9c9bdf246d1cf0727f/tumblr_nq7yglFdmK1uvie7bo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1cdd6024da01fa23eaef7272a09976aa/tumblr_no9nr0gP331tx8mn0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/abdbf665de2ac5de3428d50c36954c01/tumblr_nolpziRW2t1tv6zu7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/5a7501b081d76cfe842a52441b3a6d7b/tumblr_nnsrura64c1uu6kufo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/b16562076bce67fc50334d7579ab8d74/tumblr_np2xurbKbe1rkr23zo1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/127aa4ead5857174628fce1340d9a33e/tumblr_nmlmwlc2B71tddzwlo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/abc07ffae7879511c124e94881c57021/tumblr_nnxiznxiKY1tqwtb6o1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://38.media.tumblr.com/03dcbdedd021090dfbc5241bb43d0e0e/tumblr_nqezqis5X91u667fuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/95e22cb6b3f77fa106c80233b2778e08/tumblr_mpgfe8W0Uj1sylt4uo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/0ee77e38cdcf260316b8c870a185300b/tumblr_nowncixyFL1utjbuho1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/71d8146acaff12c1317cfbfd1b4eb47d/tumblr_mwf7hmQZ9P1s2gg27o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/28f035fa67313f8999bf2a80ac3aad6a/tumblr_npqrcu6J5u1uuxd1yo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_lmig3n09Qg1qe2rp4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/de27499c4c67d6290a7efcf79903589d/tumblr_nnjgeb2Gwo1rkpz4po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/051b44e46b1f6de386605ca81003a009/tumblr_nm540mbDdk1rnxesso1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6cec147a23d853bc5d3c7da94874fe57/tumblr_nqiymnxooj1uz0736o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/beb589af5f8101286ebb607b204f7b09/tumblr_nor7fcVOwg1svwr57o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aecb858fd43a8aa423e612da14aabbec/tumblr_nnzjg5FEBN1r1ikako1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/a88a67f3b08ed77a48560c042721eb76/tumblr_nqcohznVnE1u3dwpfo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/385f46f22d8db69c3f358003007fb4d3/tumblr_no62rm4dDC1tx8mn0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/e9f1215649624fdab2d87d1f0591a11a/tumblr_nf3t2kNplS1u3fedno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/088f433d139fcca1320a8a43ae64a2b4/tumblr_nqgj6kBkas1ts4j3zo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/bef43f2fd2dd3a3e9759f126c87bc216/tumblr_no3y7n7vyg1u4442bo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/8f53c46d4e2a40bc8dfc458fbd145cf1/tumblr_nq541zHa5n1uy63pco1_r1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/3892d208edf9de2ea1f61f7682a321f2/tumblr_no133lDczU1tyncywo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/c9990cef79291e2f57dd5ad6e7cfd026/tumblr_nippaia6EW1rruv38o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/061b13ca642fa5c106453499b3919bc4/tumblr_no4x6zIX4T1sxw2upo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e38c1e00b1b4243539ff12d6efb718f6/tumblr_np90m2uPpY1uvpvrno1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_ly4q9efVC31qgpeddo1_r2_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/52db6f8059401b70c3bf0e87b59acfbc/tumblr_npyc5uu4xm1su2whbo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/48791f3fc698d1febd894292d4c6a270/tumblr_npcb1zaFNC1qc85nuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d13f6ba3ef94ec25d2bc72446f71a8ff/tumblr_npth1hQINo1twf5fho1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/318f95171a0c989f97636a467cda19db/tumblr_nqrd8jidra1tul45xo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/909879972d6c2cf8d2795e07f1ef9ba4/tumblr_nqodpt5v6K1u6pfheo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f027e2c4e1e23fb50d5fff16d21c942b/tumblr_mw8u3icPd31r5xtr7o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5dd30a37a2a9a4a0f08efe89bbb1a878/tumblr_no3yv0kIuM1slw7lxo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c1a9ec237e5158a65d364472b59c099f/tumblr_nq4c0mWBt21u1mb9ao1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/be0a3b976bfb03eb7085093a66d34bf9/tumblr_n04hi57n7h1s5mtxjo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/14988ff5eaf9066c592adea6075bf190/tumblr_nouwoms0101tpg4boo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/327e861bf3afcc823dac42c563262cf8/tumblr_nmf2ngYwQx1uq8pi2o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4327df4de6d4ab8ce30de447996a28de/tumblr_nqiviwQ2To1qh2opmo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7e2e0b99b99977c6b6196dcea20f9656/tumblr_nojrcfvWll1shch57o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2a7881f556a9a7b8c52f195d24a23954/tumblr_np901lfbaT1rxyszio1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1bd8cdcf014f6a4587b579b3a5cc6d6f/tumblr_no0awmkrXG1tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/55c07af359d932fcde59238b08aed4e2/tumblr_nq3c2iYlDB1uycnk7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0015c635d20f2db0c537e495d54e6b8f/tumblr_nnzzkgCtcQ1untzumo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/5d05181493e4351b2fd652885a07bad8/tumblr_npfmzu6imm1uvf8p7o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/00aced5799235163fbb8cba368ea8d13/tumblr_nqiqsbd1BJ1tqw3t4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/86d4ff05ac029182c305d93b4660a5b9/tumblr_nor474fCEo1slwrsuo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/17a836e2c1e28d3e199774b181b26b19/tumblr_nq3qalChFT1u5d8nbo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/790fd63719e607f550d6f62128b20f9e/tumblr_nqdw3lqWm11uot1olo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6c26a27c3944d02aecaed06e3924f2ca/tumblr_np91dzej8Q1ux9jido1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4962f6c32959ab7565e16cdf9631745c/tumblr_npyiirZNon1uyp4auo1_540.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/a54f528e0dc20af6982a459d788cd477/tumblr_not9zcAaHu1uvzbfuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/afc8ecfc3857193c43a98f4ef8a04cc9/tumblr_mjyrakXrER1r1y0g8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/tumblr_lypbdvljrZ1rocgh8o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/4566e588a457218cbf921bd98f93295c/tumblr_mxjglgd8Bh1qahdsro1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/456a04e747a7928215b2ae5b1e956d2c/tumblr_nodyv5NB0I1urw140o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/c71d975a11322fdfbd0428cfc5aa6033/tumblr_nqaucyijPU1so9smno1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1b51d07c3fd1c3f96f802d5781edfb05/tumblr_nobp70avYb1ushktro1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/88f372477b8be103b0cfb00e06d0a827/tumblr_n8ioxs9aCl1r9eqm7o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/87b347527dcf215594894248b14481df/tumblr_npqaloBcWJ1t0ojyvo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/ba56f35698a9d4e8b04f723cadec40de/tumblr_npa0h5r3A81ssoe4no1_1280.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/c15f7c428004324c73ff29b7950e7de7/tumblr_mwbzkuLk3z1su2tyco1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6c5e123f23390cf8110b4da9cbbff703/tumblr_nocmwzapmB1tsqdy0o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/545df0ff39a6a0a9cf60969311c56edb/tumblr_no7rx3IwRG1uoevhpo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2654a9e8fd4d458424cc9ae8fb8a2a9f/tumblr_ni6hvnaJfV1qmcj0to1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/a1e4a60b826bbfb66b1696df91f3e56f/tumblr_n4phtdbSdA1sd73gqo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/1db70e2e3313e512ca7dfe74273c8a73/tumblr_np8hvu7yCr1u4njk6o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e3d4ed8881d6e9b821fe3ce9b80b291a/tumblr_noizkqcXoi1ta3tzdo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/3405545b23259ebecb7ce221a6206000/tumblr_mpuuiuohZa1sttfzzo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/20cee8b60e287a6bc68adbdeefa24313/tumblr_noykn4LMtM1uvyb0co1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/d89fb822dce42bd968c1504a50a2bd94/tumblr_nm2vpklZJe1rnxn7co1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8acfc5f138a0954c38932218172bca0e/tumblr_nqm9y4vCXr1tps70yo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/48ff272acf89d5c6d9cc172940087774/tumblr_nq4iyp1bdn1u6oxp7o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/d2714918ee3f89e408472ccb300fbe86/tumblr_mpzyfc7gyv1qkzl7oo1_500.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/a4b0995b1dcfe1045b3e407439160469/tumblr_nq5474KbMK1slwrsuo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m2zuexfPIS1rrq7bvo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/08ec97fad7a7a211efb8084f8795b20e/tumblr_mhcf0c3g0m1qcg5dbo1_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/54faa509f579ee598e367120eb1d89d9/tumblr_np2fpdZtdW1uwflxio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/77b9a687f62f379a9d4b61fc40a573ed/tumblr_noi7lmhmbF1uqf2zyo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e23ca909cade2593f0b68b8bee0f2b94/tumblr_nozfuqZ4MQ1rg5iq4o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/9e265fdf700d0ef97865efad78f53aa4/tumblr_nmkgza9OU81ryzqpmo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/640d703fa1eee12cb28cc91d5c0163fb/tumblr_nopy34PTGM1uqk9ixo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9ec8460b4120fe5325257b767c58f207/tumblr_nobxqkQ9G11tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/d2922646de51402605767b591d9ecd87/tumblr_njscbklonk1rtpgsxo1_r2_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/536259222b472fccf9f0c45a4ac1f8b4/tumblr_nq4htufR3F1twfmf3o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/05220c3baf2090eda1dc765467ff5453/tumblr_ng6ku16TTn1sivw65o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/86f3b8908dc99e0d5ddd23348a900f97/tumblr_nq24dzfGA71sbmryxo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/2fe75b53e33f9394b74799e985578830/tumblr_np1oltv5F41te6s3so1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/1d79c5941af6ac21d73e8b9b6df24091/tumblr_nqghiiwUcG1tmnntwo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/f9d1fc9a23c7ab161cd3085c572916c4/tumblr_my2gd2RYh01qisaxao1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/aaf3d7b2d0c69b06c44a219f7827d631/tumblr_ni5b7i3Ljt1rff6oio1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_m592bumySi1ro2q19o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/22582722437994255c58a9030363e26b/tumblr_nqk6rvYep01uz2cnjo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/f33a2188a3fa74a3d6b4249fe924c193/tumblr_mnuk9mf4K61qiwt8po1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/89ca54f7d2fc73dc09030a77908b2517/tumblr_nogvsvQa0f1u7aolto1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/28ce4eda0c7bfdc2d1f6ea1618f7bcba/tumblr_nq36gqEAXa1tpg4boo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/564cb90c467c1d696c8ec92cf332729a/tumblr_nqfmnxJ0TQ1sho94oo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/75ca4f9618fe2b75b253dcb888097ce1/tumblr_npoc1tnALy1uwhbn9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/8de6db981ecc257cabc49616314dc63c/tumblr_nqo4axIZy31t0jlixo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/680fc40d9bb4fbaebaba00ae8c12a995/tumblr_noknryXOOL1uvuispo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/03024adbf231d43ea1251e19d61a51de/tumblr_npwgrnxoyh1rd18ueo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/2cceefa27f920a7aef41ec843bccb063/tumblr_ndvas1yeTQ1s4bx7jo1_r1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/83aa365bf5179714b6170a75661244e1/tumblr_np842emiSe1sgwg9go1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/53102dfe9ba18e8210c37ea3e7eeb7c3/tumblr_n6qxdoqk0v1qikmd9o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/aa3496d61ce7b47063667bf53c993466/tumblr_mw1x1s8Kpr1slm15go1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/9a94cc347db7a12d95871d702447ed0f/tumblr_n8pqdkYlt81qc9dmlo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/6c16ef74e8691dabe8c9d36768d3f7c3/tumblr_npbrx10q8a1tg20rqo1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/1b2a6fe1212fb927f032555c76a724a1/tumblr_mvpcvwr5N21s3df36o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/0766150725211fb33009537444986005/tumblr_n6tjp9Ot8W1rumu9ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://31.media.tumblr.com/0be7205e4c3ed4c3b3c6020776e1ac38/tumblr_mnofz6jQx61s2qup7o1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/01fe585ecf9a781485d460b79b66c8d4/tumblr_notg1ihGJ01tpg4boo1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/7fc9896355ac2f76bc94bcde1308b3b0/tumblr_n9xmymlrzd1tic723o1_250.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/e6287b984b105b289b4c3adb213bbcc3/tumblr_nqg2blfPoX1sgnjt1o1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://38.media.tumblr.com/tumblr_lwmqjti5Uj1r57a9ao1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/6f32625a39384d42a83d311bdf8bdb16/tumblr_npn6p5UDHH1sdss0qo1_400.gif: Calculated padded input size per channel: (1 x 224 x 224). Kernel size: (2 x 16 x 16). Kernel size can't be greater than actual input size\n","Error processing https://33.media.tumblr.com/f7e807a5a01355423a35ef2875a1115a/tumblr_nomx99SsUp1tm02leo2_r1_500.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n","Error processing https://33.media.tumblr.com/665205a92e3a9638fcd558689da574d7/tumblr_nido1fsSqg1sydbxoo1_400.gif: The size of tensor a (784) must match the size of tensor b (1568) at non-singleton dimension 1\n"]}]}]}