{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":195222,"status":"ok","timestamp":1768758830978,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"},"user_tz":-330},"id":"BHxVmat2q-_1","outputId":"e0dc50d4-1343-4e3a-cf63-21c8472d30c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n","Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cpu)\n","Collecting numpy>=1.17 (from transformers)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n","  Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Collecting torch (from timm)\n","  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n","Collecting torchvision (from timm)\n","  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->timm) (1.3.0)\n","Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, decord, nvidia-cusolver-cu12, torch, torchvision, facenet-pytorch\n","  Attempting uninstall: Pillow\n","    Found existing installation: pillow 11.3.0\n","    Uninstalling pillow-11.3.0:\n","      Successfully uninstalled pillow-11.3.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.29.2\n","    Uninstalling nvidia-nccl-cu12-2.29.2:\n","      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.9.0+cpu\n","    Uninstalling torch-2.9.0+cpu:\n","      Successfully uninstalled torch-2.9.0+cpu\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.24.0+cpu\n","    Uninstalling torchvision-0.24.0+cpu:\n","      Successfully uninstalled torchvision-0.24.0+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pillow-10.2.0 decord-0.6.0 facenet-pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"02f0f7f39e3a432198b7f39734f11e06"}},"metadata":{}}],"source":["!pip install transformers timm decord facenet-pytorch"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40682,"status":"ok","timestamp":1768758897161,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"},"user_tz":-330},"id":"VVU5EyMXrmZZ","outputId":"fb8f18c8-58a1-4656-cdb5-dfa2cfffacd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Collecting transformers\n","  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.2.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.9.86)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n","Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.57.3\n","    Uninstalling transformers-4.57.3:\n","      Successfully uninstalled transformers-4.57.3\n","Successfully installed transformers-4.57.6\n"]}],"source":["!pip install --upgrade transformers accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":251596,"status":"ok","timestamp":1768759165804,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"},"user_tz":-330},"id":"vjFt5_lfrsBn","outputId":"712f254b-2a86-4b1b-ec8c-c1408258bc58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.4.1\n","  Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.19.1\n","  Downloading torchvision-0.19.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n","Collecting transformers==4.44.2\n","  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.34.2\n","  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n","Collecting facenet-pytorch\n","  Using cached facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Collecting decord\n","  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n","Collecting filelock (from torch==2.4.1)\n","  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n","Collecting typing-extensions>=4.8.0 (from torch==2.4.1)\n","  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting sympy (from torch==2.4.1)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch==2.4.1)\n","  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting jinja2 (from torch==2.4.1)\n","  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n","Collecting fsspec (from torch==2.4.1)\n","  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n","Collecting setuptools (from torch==2.4.1)\n","  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch==2.4.1)\n","  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Collecting numpy (from torchvision==0.19.1)\n","  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n","Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.19.1)\n","  Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n","Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.44.2)\n","  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n","Collecting packaging>=20.0 (from transformers==4.44.2)\n","  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting pyyaml>=5.1 (from transformers==4.44.2)\n","  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n","Collecting regex!=2019.12.17 (from transformers==4.44.2)\n","  Downloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests (from transformers==4.44.2)\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Collecting safetensors>=0.4.1 (from transformers==4.44.2)\n","  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n","  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting tqdm>=4.27 (from transformers==4.44.2)\n","  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting psutil (from accelerate==0.34.2)\n","  Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1)\n","  Using cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting numpy (from torchvision==0.19.1)\n","  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.19.1)\n","  Using cached pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","INFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n","Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2)\n","  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.1)\n","  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n","Collecting charset_normalizer<4,>=2 (from requests->transformers==4.44.2)\n","  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n","Collecting idna<4,>=2.5 (from requests->transformers==4.44.2)\n","  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.44.2)\n","  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n","Collecting certifi>=2017.4.17 (from requests->transformers==4.44.2)\n","  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n","Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1)\n","  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl (797.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.19.1-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m916.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.20.3-py3-none-any.whl (16 kB)\n","Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n","Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n","Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, safetensors, regex, pyyaml, psutil, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, decord, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, torchvision, accelerate, facenet-pytorch\n","  Attempting uninstall: mpmath\n","    Found existing installation: mpmath 1.3.0\n","    Uninstalling mpmath-1.3.0:\n","      Successfully uninstalled mpmath-1.3.0\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.5.0\n","    Uninstalling urllib3-2.5.0:\n","      Successfully uninstalled urllib3-2.5.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.15.0\n","    Uninstalling typing_extensions-4.15.0:\n","      Successfully uninstalled typing_extensions-4.15.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.67.1\n","    Uninstalling tqdm-4.67.1:\n","      Successfully uninstalled tqdm-4.67.1\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.14.0\n","    Uninstalling sympy-1.14.0:\n","      Successfully uninstalled sympy-1.14.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.2.0\n","    Uninstalling setuptools-75.2.0:\n","      Successfully uninstalled setuptools-75.2.0\n","  Attempting uninstall: safetensors\n","    Found existing installation: safetensors 0.7.0\n","    Uninstalling safetensors-0.7.0:\n","      Successfully uninstalled safetensors-0.7.0\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2025.11.3\n","    Uninstalling regex-2025.11.3:\n","      Successfully uninstalled regex-2025.11.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0.3\n","    Uninstalling PyYAML-6.0.3:\n","      Successfully uninstalled PyYAML-6.0.3\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.9.5\n","    Uninstalling psutil-5.9.5:\n","      Successfully uninstalled psutil-5.9.5\n","  Attempting uninstall: pillow\n","    Found existing installation: pillow 10.2.0\n","    Uninstalling pillow-10.2.0:\n","      Successfully uninstalled pillow-10.2.0\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 25.0\n","    Uninstalling packaging-25.0:\n","      Successfully uninstalled packaging-25.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.1.105\n","    Uninstalling nvidia-nvtx-cu12-12.1.105:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\n","    Uninstalling nvidia-nvjitlink-cu12-12.9.86:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.19.3\n","    Uninstalling nvidia-nccl-cu12-2.19.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.2.106\n","    Uninstalling nvidia-curand-cu12-10.3.2.106:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n","    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n","      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n","    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n","    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n","    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.6.1\n","    Uninstalling networkx-3.6.1:\n","      Successfully uninstalled networkx-3.6.1\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 3.0.3\n","    Uninstalling MarkupSafe-3.0.3:\n","      Successfully uninstalled MarkupSafe-3.0.3\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.11\n","    Uninstalling idna-3.11:\n","      Successfully uninstalled idna-3.11\n","  Attempting uninstall: hf-xet\n","    Found existing installation: hf-xet 1.2.0\n","    Uninstalling hf-xet-1.2.0:\n","      Successfully uninstalled hf-xet-1.2.0\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.20.2\n","    Uninstalling filelock-3.20.2:\n","      Successfully uninstalled filelock-3.20.2\n","  Attempting uninstall: charset_normalizer\n","    Found existing installation: charset-normalizer 3.4.4\n","    Uninstalling charset-normalizer-3.4.4:\n","      Successfully uninstalled charset-normalizer-3.4.4\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2026.1.4\n","    Uninstalling certifi-2026.1.4:\n","      Successfully uninstalled certifi-2026.1.4\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.4\n","    Uninstalling requests-2.32.4:\n","      Successfully uninstalled requests-2.32.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n","    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n","    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n","      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 3.1.6\n","    Uninstalling Jinja2-3.1.6:\n","      Successfully uninstalled Jinja2-3.1.6\n","  Attempting uninstall: decord\n","    Found existing installation: decord 0.6.0\n","    Uninstalling decord-0.6.0:\n","      Successfully uninstalled decord-0.6.0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n","    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.36.0\n","    Uninstalling huggingface-hub-0.36.0:\n","      Successfully uninstalled huggingface-hub-0.36.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.2\n","    Uninstalling torch-2.2.2:\n","      Successfully uninstalled torch-2.2.2\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.2\n","    Uninstalling tokenizers-0.22.2:\n","      Successfully uninstalled tokenizers-0.22.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.57.6\n","    Uninstalling transformers-4.57.6:\n","      Successfully uninstalled transformers-4.57.6\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.17.2\n","    Uninstalling torchvision-0.17.2:\n","      Successfully uninstalled torchvision-0.17.2\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.12.0\n","    Uninstalling accelerate-1.12.0:\n","      Successfully uninstalled accelerate-1.12.0\n","  Attempting uninstall: facenet-pytorch\n","    Found existing installation: facenet-pytorch 2.6.0\n","    Uninstalling facenet-pytorch-2.6.0:\n","      Successfully uninstalled facenet-pytorch-2.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n","torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.4.1 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n","gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.1.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed MarkupSafe-3.0.3 accelerate-0.34.2 certifi-2026.1.4 charset_normalizer-3.4.4 decord-0.6.0 facenet-pytorch-2.5.3 filelock-3.20.3 fsspec-2026.1.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 numpy-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 packaging-25.0 pillow-12.1.0 psutil-7.2.1 pyyaml-6.0.3 regex-2026.1.15 requests-2.32.5 safetensors-0.7.0 setuptools-80.9.0 sympy-1.14.0 tokenizers-0.19.1 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 transformers-4.44.2 triton-3.0.0 typing-extensions-4.15.0 urllib3-2.6.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","_distutils_hack","certifi","numpy","packaging","psutil"]},"id":"0314a970426b4084b17a4070e59acde5"}},"metadata":{}}],"source":["!pip install torch==2.4.1 torchvision==0.19.1 transformers==4.44.2 accelerate==0.34.2 facenet-pytorch decord --force-reinstall"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52527,"status":"ok","timestamp":1768759230593,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"},"user_tz":-330},"id":"OiNCUxvttuIF","outputId":"400c1de2-9e35-4e04-f6c4-88a694ead9a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Loading dataset from /content/TGIF_v2.tsv...\n","✅ Data Splits Saved:\n","  Train: 8000\n","  Val:   1000\n","  Test:  1000\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","# 1. Mount Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 2. Configuration\n","# Where to save the split CSVs and the feature tensors\n","BASE_DIR = \"/content/drive/MyDrive/FYP_Full_Project\"\n","SPLIT_DIR = f\"{BASE_DIR}/splits\"\n","FEATURE_DIR = f\"{BASE_DIR}/features\"\n","\n","os.makedirs(SPLIT_DIR, exist_ok=True)\n","os.makedirs(FEATURE_DIR, exist_ok=True)\n","\n","# 3. Load & Split Data\n","# Assuming TGIF.tsv is uploaded to Colab or in Drive\n","tsv_path = \"/content/TGIF_v2.tsv\"  # Update if your file is elsewhere\n","print(f\"Loading dataset from {tsv_path}...\")\n","\n","# Load dataset (handling potential bad lines)\n","df = pd.read_csv(tsv_path, sep='\\t', names=['path', 'caption'], on_bad_lines='skip')\n","df['gif_id'] = [f\"gif_{i}\" for i in range(len(df))]\n","\n","# Split: 80% Train, 10% Val, 10% Test\n","train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","\n","# Save splits to Drive\n","train_df.to_csv(f\"{SPLIT_DIR}/train.csv\", index=False)\n","val_df.to_csv(f\"{SPLIT_DIR}/val.csv\", index=False)\n","test_df.to_csv(f\"{SPLIT_DIR}/test.csv\", index=False)\n","\n","print(f\"✅ Data Splits Saved:\")\n","print(f\"  Train: {len(train_df)}\")\n","print(f\"  Val:   {len(val_df)}\")\n","print(f\"  Test:  {len(test_df)}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":947,"referenced_widgets":["cf5b65284d3645bc9f60d3d8866e5779","2da89dfa9dfd482e8c763527d6d522d2","70ab6aa6610746b886c91032c9bcfddc","1ef11ae64cef41309043bdb4629c01b2","01d8c86dafd2409fb4eb36a73fbaf6e6","4548f9ff3542488c93d0a63aea398489","8d4d338d585e4db18b4d0f35bd249fb5","72fb189bda954e19b67a586147f7f4e8","38992c448bc44d9da84585412251cfcc","d79c5063973d467b9ab36009e0ea1137","20717987484f4234a603ebbb7504c697","57ba33909e0c434ebdb0a9f5ee7dd6ce","f18a078505eb45de992761e8bd88b8f9","afdd17d14e8847b2b59990ef1b4bf311","07525ba48a10412fb9a337b0fb226037","0016ff00e986491e8c47d66638781e78","2065dea7dd6d47cab8a5952f03addd6f","c797ca43975c4e31869c0f19625da270","609bc9d983fd402e904d5c35a263ec48","aa2d26fd38644a38a30747b66bfa14f9","1af8a2a513f6403ab184ee60d6865e29","d2d766e311604d168df7527a280278eb","7077c542b96c4f9f91d0d7a2dd3919df","d1c2bf2514a647e4bbaa88084aa43fd6","eb36c45d0a9c4f0ca827b1febd9a3cbd","7f5103c79a604749b7ecce1230cc9d22","9338ded922d748aa99eec866d6a637a1","8b83207a688648489704024bd13d552c","7efffc19c18d4314a5e6edad83141520","91c60acdf7834496946507a1b3cb1d6a","6a1d13602aa2411785ffb502c7fd7ce1","c6cdf1a2880c4a9ba9c107c2d48f0417","11631777d890407c9a0943653b4a3a57","6d82bde4bc0b44e3bf50cb6f7fa3add7","9dc272fde4e24634a48cf11fd4bc7aa8","248e1477f1d049609af864ab19af33bb","748dce86fd444d42a50c7da040895d09","54218444600b477991b68f36585010d9","7c52ce6957f14e579905f5cf753e9d1f","9446f400b55f439ea691406510882071","2bea4488d21a4f4bb2bb40e035ab469b","d841b0a28c3f441a90ad9f3b13a75316","473d6058ce5a4a21aedd834eb342a67e","cb0b62e7edc5471b8bcce959517f30f7","95ee2857e3384793bd89aed5345d269f","131b039da5e04c73b4881d8901008234","5d2e3b5a4bac47ca8fa118313199cd97","15c0a64ec57f46e4981e04f2563fcc4e","ba4b0d89932e4e51b2910801d6d1ff0c","a0d26d1e66f34003a4b69f0847d0f651","ea00954c603b456eba7d5d6ac5ccd55e","493e30a612c94ffda684d8f54335c761","8c5235515afa4653a3bd855167eb1f0e","aeb121d48ae34e60994776bdaed0992b","ba52b095abd64fb999b8201281552a21","a630fcc600674919bc05ef87afb2bc79","d46ff6f4be2e42eca8857f70f853bfbf","51774a35c2c14c99911f1bec4e6871a9","b0af730271554f27a9d192163346f559","43da26795961453db03dca61e0648b27","b5fe6d18056d4a4da75aaa5148ba8f8f","0234ce25b4ff4565aecb990f57ce22be","648b4c02ed494abd8f4eefd87a3029cf","fefa9250949249be9fa598300db24c11","515c0c394531452ab4cc916bcb9c5f47","7e552a279bc44e719a3b9503e234109a","f0d75c690c0c4a2fa20e7b3151b78671","30cbd499c196402d93b76b62cd2cc543","ba6f1ba468b743bb8d389c972ad3d99b","393dccab3a9e4bb2bece830fc778c43a","903a435c419b474ebe92eed97435931f","988784c78cdd4ccbbdc125e75ce9f2d8","bc0e9ab8173b4423a4b42d3f44665351","4d22ce1c20774dcb9149113e4d2c1b06","b0ba88a367f34595aa25c6867f82e50b","cf4336f78c154d80ae479b88a050c09e","0003f2ae5e7e4180bb52bee51b457098"]},"id":"q_b8Cm1duBlT","executionInfo":{"status":"error","timestamp":1768635151262,"user_tz":-330,"elapsed":3130668,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"0f37769a-d47c-42e7-dd69-77b5ebb1cc61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Feature Extractors...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5b65284d3645bc9f60d3d8866e5779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ba33909e0c434ebdb0a9f5ee7dd6ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/377M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7077c542b96c4f9f91d0d7a2dd3919df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d82bde4bc0b44e3bf50cb6f7fa3add7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ee2857e3384793bd89aed5345d269f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a630fcc600674919bc05ef87afb2bc79"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","🚀 Processing val (1000 samples)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n","/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n","/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d75c690c0c4a2fa20e7b3151b78671"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n","  return torch.tensor(value)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3760233375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# --- D. Run Extraction (This takes time!) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Uncomment one by one if you want to verify progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mprocess_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{SPLIT_DIR}/val.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Start with smaller val set to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mprocess_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{SPLIT_DIR}/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mprocess_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{SPLIT_DIR}/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# The big one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3760233375.py\u001b[0m in \u001b[0;36mprocess_partition\u001b[0;34m(csv_path, partition_name, batch_size)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 current_batch.append({\n\u001b[1;32m    108\u001b[0m                     \u001b[0;34m'caption'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3760233375.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(gif_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mact_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mact_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mact_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# --- 2. EMOTION EMBEDDING (Face -> ViT) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 )\n\u001b[1;32m    480\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# in VideoMAE, layernorm is also applied after self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_after\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# second residual connection is done here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/videomae/modeling_videomae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import requests\n","from PIL import Image as PILImage\n","from transformers import VideoMAEModel, ViTModel, AutoImageProcessor\n","from facenet_pytorch import MTCNN\n","from tqdm.auto import tqdm\n","import torch\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# --- A. Load Extractors ---\n","print(\"Loading Feature Extractors...\")\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","mtcnn = MTCNN(keep_all=False, device=DEVICE)\n","\n","# --- B. Helper Functions ---\n","def download_gif(url, save_path):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        if response.status_code == 200:\n","            with open(save_path, 'wb') as f:\n","                f.write(response.content)\n","            return True\n","    except:\n","        pass\n","    return False\n","\n","import numpy as np\n","\n","def extract_features(gif_path):\n","    # 1. Load the GIF with Pillow\n","    frames = []\n","    with PILImage.open(gif_path) as img:\n","        try:\n","            while True:\n","                frames.append(img.copy().convert(\"RGB\"))\n","                img.seek(len(frames))\n","        except EOFError:\n","            pass\n","\n","    if len(frames) == 0:\n","        raise ValueError(\"Empty GIF\")\n","\n","    # 2. Sample 16 frames uniformly\n","    # (We use numpy directly here to fix the \"slow tensor\" warning)\n","    idx_list = np.linspace(0, len(frames) - 1, 16, dtype=int)\n","    sampled_frames = [frames[i] for i in idx_list]\n","\n","    # --- OPTIMIZATION: Stack frames into a single Numpy array first ---\n","    # This prevents the \"list of arrays\" bottleneck\n","    video_array = np.stack([np.array(f) for f in sampled_frames])\n","\n","    # --- 1. ACTION EMBEDDING (VideoMAE) ---\n","    # Pass the numpy array directly\n","    act_inputs = action_proc(list(video_array), return_tensors=\"pt\").to(DEVICE)\n","    with torch.no_grad():\n","        act_out = action_model(**act_inputs).last_hidden_state.mean(dim=1).cpu()\n","\n","    # --- 2. EMOTION EMBEDDING (Face -> ViT) ---\n","    mid_frame_pil = sampled_frames[8] # Use the middle frame from our sample\n","\n","    face = mtcnn(mid_frame_pil)\n","\n","    if face is not None:\n","        # Permute [3, 160, 160] -> [160, 160, 3] for ViT processor\n","        face_img = face.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n","        emo_inputs = vit_proc(face_img, return_tensors=\"pt\").to(DEVICE)\n","        with torch.no_grad():\n","            emo_out = vit_model(**emo_inputs).last_hidden_state[:, 0, :].cpu()\n","    else:\n","        emo_out = torch.zeros((1, 768))\n","\n","    # --- 3. OBJECT EMBEDDING (ViT) ---\n","    obj_inputs = vit_proc(mid_frame_pil, return_tensors=\"pt\").to(DEVICE)\n","    with torch.no_grad():\n","        obj_out = vit_model(**obj_inputs).last_hidden_state[:, 0, :].cpu()\n","\n","    return act_out, emo_out, obj_out\n","\n","# --- C. Batch Processing Function ---\n","def process_partition(csv_path, partition_name, batch_size=100):\n","    df = pd.read_csv(csv_path)\n","    print(f\"\\n🚀 Processing {partition_name} ({len(df)} samples)...\")\n","\n","    current_batch = []\n","\n","    # Calculate how many batches needed\n","    num_batches = (len(df) // batch_size) + 1\n","\n","    for i, row in tqdm(df.iterrows(), total=len(df)):\n","        batch_idx = i // batch_size\n","        save_file = f\"{FEATURE_DIR}/{partition_name}_batch_{batch_idx}.pt\"\n","\n","        # SKIP if batch exists (Resume Logic)\n","        if os.path.exists(save_file) and (i % batch_size == 0):\n","            continue\n","\n","        # Download & Extract\n","        temp_path = f\"/content/temp_{partition_name}.gif\"\n","        if download_gif(row['path'], temp_path):\n","            try:\n","                act, emo, obj = extract_features(temp_path)\n","                current_batch.append({\n","                    'caption': row['caption'],\n","                    'act': act, 'emo': emo, 'obj': obj\n","                })\n","            except Exception:\n","                pass # Skip broken GIFs\n","            finally:\n","                if os.path.exists(temp_path): os.remove(temp_path)\n","\n","        # Save Batch\n","        if len(current_batch) >= batch_size:\n","            torch.save(current_batch, save_file)\n","            current_batch = [] # Clear RAM\n","\n","    # Save final partial batch\n","    if current_batch:\n","        torch.save(current_batch, f\"{FEATURE_DIR}/{partition_name}_batch_final.pt\")\n","\n","# --- D. Run Extraction (This takes time!) ---\n","# Uncomment one by one if you want to verify progress\n","process_partition(f\"{SPLIT_DIR}/val.csv\", \"val\")   # Start with smaller val set to test\n","process_partition(f\"{SPLIT_DIR}/test.csv\", \"test\")\n","process_partition(f\"{SPLIT_DIR}/train.csv\", \"train\") # The big one"]},{"cell_type":"code","source":["import requests\n","from PIL import Image as PILImage\n","from transformers import VideoMAEModel, ViTModel, AutoImageProcessor\n","from facenet_pytorch import MTCNN\n","from tqdm.auto import tqdm\n","import torch\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# --- A. Load Extractors ---\n","print(\"Loading Feature Extractors...\")\n","action_proc = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n","action_model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(DEVICE).eval()\n","\n","vit_proc = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n","vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE).eval()\n","\n","mtcnn = MTCNN(keep_all=False, device=DEVICE)\n","\n","# --- B. Helper Functions ---\n","def download_gif(url, save_path):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        if response.status_code == 200:\n","            with open(save_path, 'wb') as f:\n","                f.write(response.content)\n","            return True\n","    except:\n","        pass\n","    return False\n","\n","import numpy as np\n","\n","def extract_features(gif_path):\n","    # 1. Load the GIF with Pillow\n","    frames = []\n","    with PILImage.open(gif_path) as img:\n","        try:\n","            while True:\n","                frames.append(img.copy().convert(\"RGB\"))\n","                img.seek(len(frames))\n","        except EOFError:\n","            pass\n","\n","    if len(frames) == 0:\n","        raise ValueError(\"Empty GIF\")\n","\n","    # 2. Sample 16 frames uniformly\n","    # (We use numpy directly here to fix the \"slow tensor\" warning)\n","    idx_list = np.linspace(0, len(frames) - 1, 16, dtype=int)\n","    sampled_frames = [frames[i] for i in idx_list]\n","\n","    # --- OPTIMIZATION: Stack frames into a single Numpy array first ---\n","    # This prevents the \"list of arrays\" bottleneck\n","    video_array = np.stack([np.array(f) for f in sampled_frames])\n","\n","    # --- 1. ACTION EMBEDDING (VideoMAE) ---\n","    # Pass the numpy array directly\n","    act_inputs = action_proc(list(video_array), return_tensors=\"pt\").to(DEVICE)\n","    with torch.no_grad():\n","        act_out = action_model(**act_inputs).last_hidden_state.mean(dim=1).cpu()\n","\n","    # --- 2. EMOTION EMBEDDING (Face -> ViT) ---\n","    mid_frame_pil = sampled_frames[8] # Use the middle frame from our sample\n","\n","    face = mtcnn(mid_frame_pil)\n","\n","    if face is not None:\n","        # Permute [3, 160, 160] -> [160, 160, 3] for ViT processor\n","        face_img = face.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n","        emo_inputs = vit_proc(face_img, return_tensors=\"pt\").to(DEVICE)\n","        with torch.no_grad():\n","            emo_out = vit_model(**emo_inputs).last_hidden_state[:, 0, :].cpu()\n","    else:\n","        emo_out = torch.zeros((1, 768))\n","\n","    # --- 3. OBJECT EMBEDDING (ViT) ---\n","    obj_inputs = vit_proc(mid_frame_pil, return_tensors=\"pt\").to(DEVICE)\n","    with torch.no_grad():\n","        obj_out = vit_model(**obj_inputs).last_hidden_state[:, 0, :].cpu()\n","\n","    return act_out, emo_out, obj_out\n","\n","def process_partition(csv_path, partition_name, batch_size=100):\n","    df = pd.read_csv(csv_path)\n","    print(f\"\\n🚀 Checking {partition_name} ({len(df)} samples) for existing progress...\")\n","\n","    current_batch = []\n","\n","    for i, row in tqdm(df.iterrows(), total=len(df)):\n","        batch_idx = i // batch_size\n","        save_file = f\"{FEATURE_DIR}/{partition_name}_batch_{batch_idx}.pt\"\n","\n","        # --- DEBUG LINE: Run this once to see what's happening ---\n","        if i == 0:\n","            print(f\"Checking for file: {save_file}\")\n","            print(f\"Does it exist? {os.path.exists(save_file)}\")\n","\n","        # --- THE RESUME MAGIC ---\n","        # If the batch file already exists in Drive, skip this row immediately.\n","        if os.path.exists(save_file):\n","            continue\n","\n","        # --- ONLY RUNS FOR MISSING DATA ---\n","        temp_path = f\"/content/temp_{partition_name}.gif\"\n","        if download_gif(row['path'], temp_path):\n","            try:\n","                act, emo, obj = extract_features(temp_path)\n","                current_batch.append({\n","                    'caption': row['caption'],\n","                    'act': act, 'emo': emo, 'obj': obj\n","                })\n","            except Exception:\n","                pass\n","            finally:\n","                if os.path.exists(temp_path): os.remove(temp_path)\n","\n","        # Save the batch once we collect 100 NEW samples\n","        if len(current_batch) >= batch_size:\n","            torch.save(current_batch, save_file)\n","            print(f\"✅ Saved {save_file}\")\n","            current_batch = []\n","\n","    # Handle the very last bit\n","    if current_batch:\n","        torch.save(current_batch, f\"{FEATURE_DIR}/{partition_name}_batch_final.pt\")\n","\n"," # --- D. Run Extraction (This takes time!) ---\n","# Uncomment one by one if you want to verify progress\n","#process_partition(f\"{SPLIT_DIR}/train.csv\", \"train\") # The big one\n","#process_partition(f\"{SPLIT_DIR}/val.csv\", \"val\")   # Start with smaller val set to test\n","#process_partition(f\"{SPLIT_DIR}/test.csv\", \"test\")\n","#process_partition(f\"{SPLIT_DIR}/train.csv\", \"train\") # The big one"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507,"referenced_widgets":["cfbfce0ebfd446bf978640dca59946a8","fd80dcfaa8ea4cb98614d33371e1118c","0862b87ad5b844a6a21d79357a3835b1","fe1dd68ec501400e8d067dfc0c94ec49","1289c9f56ba642cc8bb70e20612a09e4","4d516a9ba9a04e46b8793db3de2dcfd5","66945552bb2449e582cf106d039afb4b","1531534ac77a4ad4945ace8a93a7bbd7","105a9a2de49d4238a0b91bc764b78fb1","212bbf48e47c4696aa23b7a9a85abdc5","b03fdff47d57471d9702e46e40fcf6f7","0fbcc22aa7e144f89b2ab43d7a93012f","2c2069c0e09c4f779ec64cb7bcbf91c6","1671f828d3244085a686da43db41b358","2a125fd3aee44217a0643178567af3e3","6299af09540045afb38a7914141b23dd","154ae141622b4c62851ac21673f66094","259cf34a4f4a48eb82b2865acb8b7b20","9590274916e74d439aa3f06a1644131d","1dde1420078b482d90cb40195fd3335e","26a9df2da9e74c7285f1b7aad33caf25","239e5873f5c44f2fa64f8b7b2ee0f454","8fe17b601b85454b93c173cbf0c5a670","a12283985e7043049777cfb676190f93","6168c2d759b646e2b09cdc4308ef5345","e70bc72359964c8d8aa5ad9c84215604","66ab41b2f40d4bbb96131d34b8d9584a","08694a8765c44deca14a65ec8301ce7b","bfc885c856a34becbf978b81cc62306b","6b4c19ea4ec340bd9bbb44f91a50483f","710b973b8fc343af8c3bf23e94ac1c39","309807a8f2d64510a84b5d9a09025f99","a80425041f21449d918fc9ec55e96153","87997d482d0c475d8376d1946edc1b2f","49e06f79585746ac9d17d7535299b05e","cfc7b177da2d4a0dac7d0b897e416c65","15dcdce983814350ab9c107a44ec31c6","e81d4602ae194598b079679b967e4cbc","b11c5385a3d54bb199baafef90c97402","ec966b71db7f45a9a2f435f7af3d09fd","b60ca0f8ecc0450ba761fe77da1fd9ae","fd7a9705c56148c49834369b69afc74a","b4fc948b2dc54de187ad5b6483829276","d65e613faa53410c8f010bb624e333e6","5a60a3f7faea4f4bbcb80289bfbf72c7","0466ba3a2a524ff7a647eb21cd3e623b","60e040d6080a482c9bb106dd5e456349","87a834881f4b40f2b78a9f33efb710e1","59e96a53fc464dbb81a21958ef85d195","dda257eac70a4d6e9b2b08bc822bfc48","f45514bc57074450ada586cbc35d20e5","efe8dc97a23346cfbcb6374bc11b456b","45eb144e042f489c8a984a10708de259","55a10af8322340f6a43c0145b3c9f832","f383d9aa3bcf4e279e9b3683fc838ae2","1384e930c4e1434db2074fa9bb6b2f21","f7424170445a4d6b877943a766e09ece","6130e9841d29481faa24728ba1298727","55a040a6ee85475997375e402859c05d","a1cc660fe79a41f280607bdf0fdbba3f","1b2970e51f3c433789840105d1f67796","f7223f5ed974438385b3b9a144287f2d","9b1eb361a38142b3b0ba1ec4d0c18fd7","7c1e1bba656e49cd9462f6a8c1775967","b8b3dd402e5a4ebfabb42b2f967f526b","8b477093b7ee48c095a64d69575a14ad"]},"id":"8-kp9ITg3GxG","executionInfo":{"status":"ok","timestamp":1768759295312,"user_tz":-330,"elapsed":35066,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"ca66ed79-5cbe-442e-9c95-47dc419d94a2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Feature Extractors...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfbfce0ebfd446bf978640dca59946a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fbcc22aa7e144f89b2ab43d7a93012f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/377M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe17b601b85454b93c173cbf0c5a670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87997d482d0c475d8376d1946edc1b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a60a3f7faea4f4bbcb80289bfbf72c7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1384e930c4e1434db2074fa9bb6b2f21"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n","/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n","/usr/local/lib/python3.12/dist-packages/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n"]}]},{"cell_type":"code","source":["!ls -l /content/drive/MyDrive/FYP_Full_Project/features/train_batch_7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UB9Do-q59qGf","executionInfo":{"status":"ok","timestamp":1768666142929,"user_tz":-330,"elapsed":208,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"2a095de5-5dab-46ba-8d2e-9f39b160cdb4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/drive/MyDrive/FYP_Full_Project/features/train_batch_7.pt': No such file or directory\n"]}]},{"cell_type":"code","source":["import os\n","\n","FEATURE_DIR = \"/content/drive/MyDrive/FYP_Full_Project/features\"\n","partitions = {\n","    \"train\": 80,  # 8000 samples / 100\n","    \"val\": 10,    # 1000 samples / 100\n","    \"test\": 10    # 1000 samples / 100\n","}\n","\n","print(\"📊 --- Feature Folder Audit ---\")\n","for name, count in partitions.items():\n","    missing = []\n","    for i in range(count):\n","        if not os.path.exists(f\"{FEATURE_DIR}/{name}_batch_{i}.pt\"):\n","            missing.append(i)\n","\n","    final_exists = os.path.exists(f\"{FEATURE_DIR}/{name}_batch_final.pt\")\n","    status = \"✅ Complete\" if not missing and final_exists else \"⚠️ Missing Batches\"\n","    print(f\"{name.upper()}: {status}\")\n","    if missing: print(f\"   - Missing indices: {missing}\")\n","    if not final_exists: print(f\"   - Missing: batch_final\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKTpeFCoBSsH","executionInfo":{"status":"ok","timestamp":1768759298647,"user_tz":-330,"elapsed":29,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"c1bdf18c-fe76-46f1-d2a9-ff4c36ffbc94"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 --- Feature Folder Audit ---\n","TRAIN: ✅ Complete\n","VAL: ✅ Complete\n","TEST: ✅ Complete\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df_check = pd.read_csv(\"/content/drive/MyDrive/FYP_Full_Project/splits/train.csv\")\n","print(df_check.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tF1NTGRu9j1","executionInfo":{"status":"ok","timestamp":1768759301933,"user_tz":-330,"elapsed":345,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"4aff2a05-5380-45db-e4b5-a8f7e29a796b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['path', 'caption', 'gif_id'], dtype='object')\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import torch\n","from tqdm import tqdm\n","\n","# --- CONFIGURATION ---\n","FEATURE_DIR = \"/content/drive/MyDrive/FYP_Full_Project/features\"\n","SPLIT_DIR = \"/content/drive/MyDrive/FYP_Full_Project/splits\"\n","\n","# Based on your audit output\n","MISSING_REPORT = {\n","    \"train\": [62, 69, 74, 76, 79],\n","    \"val\": [0],\n","    \"test\": [0]\n","}\n","\n","def surgical_repair():\n","    for partition, indices in MISSING_REPORT.items():\n","        if not indices: continue\n","\n","        csv_path = f\"{SPLIT_DIR}/{partition}.csv\"\n","        df = pd.read_csv(csv_path)\n","\n","        print(f\"\\n🛠️  Starting Repair for {partition.upper()}...\")\n","\n","        for b_idx in indices:\n","            start_idx = b_idx * 100\n","            end_idx = start_idx + 100\n","            batch_df = df.iloc[start_idx:end_idx]\n","\n","            save_path = f\"{FEATURE_DIR}/{partition}_batch_{b_idx}.pt\"\n","            print(f\"📦 Processing Batch {b_idx} (Rows {start_idx}-{end_idx})\")\n","\n","            batch_features = []\n","            for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Batch {b_idx}\"):\n","                # UPDATED: Changed 'url' to 'path'\n","                target_path = row['path']\n","\n","                # Check if it's a URL or a Local Path\n","                if target_path.startswith('http'):\n","                    temp_file = \"repair_temp.gif\"\n","                    if download_gif(target_path, temp_file):\n","                        try:\n","                            feat = extract_features(temp_file)\n","                            batch_features.append(feat)\n","                        except:\n","                            batch_features.append(None)\n","                        if os.path.exists(temp_file): os.remove(temp_file)\n","                    else:\n","                        batch_features.append(None)\n","                else:\n","                    # If it's a local file path, use it directly\n","                    try:\n","                        feat = extract_features(target_path)\n","                        batch_features.append(feat)\n","                    except:\n","                        batch_features.append(None)\n","\n","            torch.save(batch_features, save_path)\n","            print(f\"✅ Fixed and Saved: {save_path}\")\n","\n","# Run the repair\n","surgical_repair()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7T2UarN5vIyU","executionInfo":{"status":"ok","timestamp":1768689360895,"user_tz":-330,"elapsed":6488053,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"d4832e19-4702-444d-ca96-c097164157e9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🛠️  Starting Repair for TRAIN...\n","📦 Processing Batch 62 (Rows 6200-6300)\n"]},{"output_type":"stream","name":"stderr","text":["\rBatch 62:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n","  return torch.tensor(value)\n","Batch 62: 100%|██████████| 100/100 [16:14<00:00,  9.75s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/train_batch_62.pt\n","📦 Processing Batch 69 (Rows 6900-7000)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 69: 100%|██████████| 100/100 [15:30<00:00,  9.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/train_batch_69.pt\n","📦 Processing Batch 74 (Rows 7400-7500)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 74: 100%|██████████| 100/100 [15:23<00:00,  9.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/train_batch_74.pt\n","📦 Processing Batch 76 (Rows 7600-7700)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 76: 100%|██████████| 100/100 [15:04<00:00,  9.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/train_batch_76.pt\n","📦 Processing Batch 79 (Rows 7900-8000)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 79: 100%|██████████| 100/100 [15:20<00:00,  9.20s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/train_batch_79.pt\n","\n","🛠️  Starting Repair for VAL...\n","📦 Processing Batch 0 (Rows 0-100)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 0: 100%|██████████| 100/100 [15:23<00:00,  9.23s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/val_batch_0.pt\n","\n","🛠️  Starting Repair for TEST...\n","📦 Processing Batch 0 (Rows 0-100)\n"]},{"output_type":"stream","name":"stderr","text":["Batch 0: 100%|██████████| 100/100 [15:07<00:00,  9.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Fixed and Saved: /content/drive/MyDrive/FYP_Full_Project/features/test_batch_0.pt\n"]}]},{"cell_type":"code","source":["import os\n","\n","FEATURE_DIR = \"/content/drive/MyDrive/FYP_Full_Project/features\"\n","partitions = {\n","    \"train\": 80,  # 8000 samples / 100\n","    \"val\": 10,    # 1000 samples / 100\n","    \"test\": 10    # 1000 samples / 100\n","}\n","\n","print(\"📊 --- Feature Folder Audit ---\")\n","for name, count in partitions.items():\n","    missing = []\n","    for i in range(count):\n","        if not os.path.exists(f\"{FEATURE_DIR}/{name}_batch_{i}.pt\"):\n","            missing.append(i)\n","\n","    final_exists = os.path.exists(f\"{FEATURE_DIR}/{name}_batch_final.pt\")\n","    status = \"✅ Complete\" if not missing and final_exists else \"⚠️ Missing Batches\"\n","    print(f\"{name.upper()}: {status}\")\n","    if missing: print(f\"   - Missing indices: {missing}\")\n","    if not final_exists: print(f\"   - Missing: batch_final\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crOKfuYXxHsw","executionInfo":{"status":"ok","timestamp":1768689360997,"user_tz":-330,"elapsed":4,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"0147cac7-0a4f-48a7-f092-18babca099c8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 --- Feature Folder Audit ---\n","TRAIN: ✅ Complete\n","VAL: ✅ Complete\n","TEST: ✅ Complete\n"]}]},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","\n","# 1. Load the tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# 2. Add a Padding Token\n","# GPT-2 doesn't have a default padding token, so we use the EOS (End Of Sentence) token\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# 3. Test it\n","test_caption = \"A person is laughing and talking.\"\n","tokens = tokenizer(test_caption, padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n","\n","print(f\"Original: {test_caption}\")\n","print(f\"Token IDs: {tokens['input_ids'][0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284,"referenced_widgets":["fd0b2576b35040208d5f9530b288197c","abf27b26691a4cac9b3c751e80744a50","edd082db81e7433194584aaf5b2d1507","6d028148079f493cb4bc8b72b71a659c","724d5216b77c4603a96e5d9c107ce1a8","765cbc85ea1e48c2bc07c9fec98fc669","c863d4a05be64982b62e0eb85e63f438","d96546b76a27492cb9e39e6f0534f471","b8801e91f6cb4c8fa890e7cc2e65bdf3","5d3e38e04c2d4e759195d64c584d8cee","3ab7681d664e4caeb6946bf6ea5af842","84e43082860244719316571aca4ddbb2","d4b1f7cf9a9048428751b7cb9cc20e0b","80552b1636d442cb9e47ea693a76ebbc","d8454da7eec743bcb49d87ce554b215d","a6e491fcb7c84e0ab97a19b526ea4522","d15ea08f188d4e319bf6a3204cda26ba","4500fe9b3bc04276bfec2c1c2076e0dc","bca5eae9bf4a4b5292fc2392cfc6e65f","f166ceb967eb440eb434dd3b6c3a4892","ee241c4d1a9944bbabf763fabbd0b4b5","6d4a3321adbb4e0e9536e691d448ba63","193f51dedaa04b2dbc624de98d5f2188","bca3f3951a0e48b7ab9bddfba6b1bce5","426a21e09cec40d39f0d18aaef577cd4","154a8e740311447eb87352471715a0ee","adadff4440654b8a9ad049a45c9ae184","6b37b027d71843edbabc8ceb2ce77ae5","b15f8c5f25b44cdcbbb8526a10d14da9","0bf99133291d4ca4bd00ea7ef71df8da","598bdf4e49324817b8796d1bd01ac879","c6a8d904d7764c98be69e327be690383","917dfedb9b4040cfab38b2136224dd5e","9d341408699241e491cbbee5081e2d8b","72a275f78f754886afca81a9a3810139","1e5bcf8e9e71456eab4bb7597414ccce","25830316f6f74e3e8227e4a286ad0e09","80209317bad44dbfbdddc174ced4c9e2","f1356946b0864d6f805ada0dcd8e40ca","4afe704ac68748e88464e9cffd336981","887dbd880e424dfab75f2b05b7c42e30","d1b75e592b374e8695b2ff19d17abc83","15557fd7207c4adabf03af195fbf0fb5","9e7ec19d068a4385bd68e012ba7bd492","6d82d67573624138b2f0c2a0e81e6592","ad3efb6726314dfca4bdbdc72f948b0e","51b21a1a6f36465496c29274e57897bf","8a30fe9b000c416dba87d73ba14a71ec","1f45bc877fda4101a711152e14df58d2","533afb5fea0942af8a6fd2cafdd7fd2b","97f99a6e33a044dfab8d9c2adf0fda5d","e9b331113d474df58dcc18f903a07829","0ef3e88a2181418dbc163d27cc0299ff","df9e27b00b284e389634c4b99091b28c","454b60aab99d490991dc87ed8b54a162"]},"id":"lRgKQ02HxLww","executionInfo":{"status":"ok","timestamp":1768759317769,"user_tz":-330,"elapsed":3546,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"4af819b3-6d33-4ccc-977d-9bb99cd0b984"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd0b2576b35040208d5f9530b288197c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e43082860244719316571aca4ddbb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"193f51dedaa04b2dbc624de98d5f2188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d341408699241e491cbbee5081e2d8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d82d67573624138b2f0c2a0e81e6592"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original: A person is laughing and talking.\n","Token IDs: tensor([   32,  1048,   318, 14376,   290,  3375,    13, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import os\n","from tqdm import tqdm\n","\n","# --- CONFIGURATION ---\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","FEATURE_DIR = \"/content/drive/MyDrive/FYP_Full_Project/features\"\n","CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/train.csv\"\n","VAL_CSV_PATH = \"/content/drive/MyDrive/FYP_Full_Project/splits/val.csv\"\n","LEARNING_RATE = 5e-5\n","EPOCHS = 5\n","BATCH_SIZE = 4 # We load 1 batch file (100 samples) and split it into micro-batches of 4\n","\n","# --- MODEL DEFINITION ---\n","class VideoGPT2Captioner(nn.Module):\n","    def __init__(self, visual_dim=2304, gpt2_dim=768):\n","        super().__init__()\n","        self.gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n","        # Projects 2304 (3x768) down to 768\n","        self.projection = nn.Linear(visual_dim, gpt2_dim)\n","\n","    def forward(self, visual_features, input_ids, labels=None):\n","        # Project visual features to GPT-2 space\n","        visual_embeds = self.projection(visual_features).unsqueeze(1) # [batch, 1, 768]\n","\n","        # Get text embeddings\n","        text_embeds = self.gpt2.transformer.wte(input_ids) # [batch, seq_len, 768]\n","\n","        # Concatenate: [Visual Token] + [Text Tokens]\n","        full_embeds = torch.cat((visual_embeds, text_embeds), dim=1)\n","\n","        if labels is not None:\n","            # Shift labels to account for the added visual token\n","            # We add a dummy label (-100) for the visual prefix so it's ignored in loss\n","            prefix_labels = torch.full((labels.size(0), 1), -100).to(DEVICE)\n","            full_labels = torch.cat((prefix_labels, labels), dim=1)\n","            return self.gpt2(inputs_embeds=full_embeds, labels=full_labels)\n","\n","        return self.gpt2(inputs_embeds=full_embeds)"],"metadata":{"id":"uWbrmDgNt9FP","executionInfo":{"status":"ok","timestamp":1768759327748,"user_tz":-330,"elapsed":50,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class VideoFeatureDataset(Dataset):\n","    def __init__(self, csv_path, feature_dir, tokenizer, partition=\"train\"):\n","        self.df = pd.read_csv(csv_path)\n","        self.feature_dir = feature_dir\n","        self.tokenizer = tokenizer\n","        self.partition = partition\n","\n","        # Find only the batch files that actually exist\n","        self.existing_batches = []\n","        expected_count = 80 if partition == \"train\" else 10\n","        for i in range(expected_count):\n","            if os.path.exists(f\"{feature_dir}/{partition}_batch_{i}.pt\"):\n","                self.existing_batches.append(i)\n","        print(f\"✅ {partition.upper()}: Found {len(self.existing_batches)}/ {expected_count} batches.\")\n","\n","    def __len__(self):\n","        return len(self.existing_batches) * 100\n","\n","    def __getitem__(self, idx):\n","        batch_idx = self.existing_batches[idx // 100]\n","        inner_idx = idx % 100\n","\n","        # Load the batch file\n","        features_list = torch.load(f\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\")\n","        visual_data = features_list[inner_idx]\n","\n","        # --- ROBUST LOGIC FOR ALL DATA TYPES ---\n","        if visual_data is None:\n","            visual_feat = torch.zeros(detected_dim)\n","\n","        elif isinstance(visual_data, dict):\n","            # Concatenate only tensors found in the dict (ignores strings like IDs)\n","            tensors = [v.flatten().float() for v in visual_data.values() if torch.is_tensor(v)]\n","            visual_feat = torch.cat(tensors)\n","\n","        elif isinstance(visual_data, (tuple, list)):\n","            # Concatenate elements if it's a tuple/list of tensors\n","            tensors = [v.flatten().float() for v in visual_data if torch.is_tensor(v)]\n","            visual_feat = torch.cat(tensors)\n","\n","        else:\n","            # It's a single direct tensor\n","            visual_feat = visual_data.flatten().float()\n","\n","        # Final check: Ensure the size matches what the model expects (2304)\n","        if visual_feat.shape[0] != detected_dim:\n","            # Pad or truncate if there is a minor mismatch\n","            padding = torch.zeros(max(0, detected_dim - visual_feat.shape[0]))\n","            visual_feat = torch.cat([visual_feat, padding])[:detected_dim]\n","\n","        # Get caption\n","        caption = self.df.iloc[batch_idx * 100 + inner_idx]['caption']\n","        tokens = self.tokenizer(caption, truncation=True, padding='max_length',\n","                                max_length=20, return_tensors=\"pt\")\n","\n","        return visual_feat, tokens['input_ids'].squeeze(0)"],"metadata":{"id":"jhwMs69Kt960","executionInfo":{"status":"ok","timestamp":1768759333762,"user_tz":-330,"elapsed":27,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from tqdm import tqdm\n","\n","# --- 1. INITIALIZE TOKENIZER ---\n","# Run the tokenizer cell you mentioned before this one!\n","\n","# --- 2. AUTO-DETECT DIMENSIONS (Filter for Tensors Only) ---\n","sample_batch = torch.load(f\"{FEATURE_DIR}/train_batch_0.pt\")\n","first_item = next(item for item in sample_batch if item is not None)\n","\n","if isinstance(first_item, dict):\n","    # Only sum up the items that are actual torch Tensors\n","    detected_dim = sum(v.shape[-1] for v in first_item.values() if torch.is_tensor(v))\n","    found_keys = [k for k, v in first_item.items() if torch.is_tensor(v)]\n","    print(f\"🔑 Found Tensor keys: {found_keys}\")\n","else:\n","    detected_dim = first_item.shape[-1]\n","\n","print(f\"🔍 Auto-detected visual dimension: {detected_dim}\")\n","\n","# --- 3. INITIALIZE MODEL & DATA ---\n","model = VideoGPT2Captioner(visual_dim=detected_dim).to(DEVICE)\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","train_ds = VideoFeatureDataset(CSV_PATH, FEATURE_DIR, tokenizer, \"train\")\n","# We use a small batch_size for the DataLoader because we are on Colab\n","train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n","\n","# --- 4. THE TRAINING FUNCTION ---\n","def train_model(model, loader, optimizer, epochs):\n","    model.train()\n","    print(\"🚀 Starting Training...\")\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        progress_bar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n","\n","        for visual_feats, input_ids in progress_bar:\n","            # Move data to GPU\n","            visual_feats = visual_feats.to(DEVICE).float()\n","            input_ids = input_ids.to(DEVICE)\n","\n","            # Forward pass\n","            optimizer.zero_grad()\n","            outputs = model(visual_feats, input_ids, labels=input_ids)\n","\n","            loss = outputs.loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n","\n","        # --- VALIDATION (The missing piece) ---\n","        model.eval()\n","        total_val_loss = 0\n","        with torch.no_grad():\n","            for v_feats, v_ids in tqdm(val_loader, desc=f\"Epoch {epoch+1} [VAL]\"):\n","                v_feats, v_ids = v_feats.to(DEVICE), v_ids.to(DEVICE)\n","                v_outputs = model(v_feats, v_ids, labels=v_ids)\n","                total_val_loss += v_outputs.loss.item()\n","\n","        # Calculate averages\n","        avg_train = total_loss / len(train_loader)\n","        avg_val = total_val_loss / len(val_loader)\n","\n","        avg_loss = total_loss / len(loader)\n","        print(f\"✅ Epoch {epoch+1} Finished. Average Loss: {avg_loss:.4f}\")\n","\n","        # Save your progress to Google Drive\n","        save_path = f\"/content/drive/MyDrive/FYP_Full_Project/model_epoch_{epoch+1}.pth\"\n","        torch.save(model.state_dict(), save_path)\n","        print(f\"💾 Checkpoint saved to {save_path}\")\n","\n","# Add this before you call train_model()\n","val_ds = VideoFeatureDataset(VAL_CSV_PATH, FEATURE_DIR, tokenizer, \"val\")\n","val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n","\n","# --- 5. START TRAINING ---\n","train_model(model, train_loader, optimizer, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":543},"id":"PWjKzNTluDly","executionInfo":{"status":"error","timestamp":1768730935980,"user_tz":-330,"elapsed":327441,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"95fd1010-415c-4197-b5f6-5116d0978752"},"execution_count":15,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-3472167155.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  sample_batch = torch.load(f\"{FEATURE_DIR}/train_batch_0.pt\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["🔑 Found Tensor keys: ['act', 'emo', 'obj']\n","🔍 Auto-detected visual dimension: 2304\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["✅ TRAIN: Found 80/ 80 batches.\n","✅ VAL: Found 10/ 10 batches.\n","🚀 Starting Training...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5:   0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipython-input-2330679539.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  features_list = torch.load(f\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\")\n","Epoch 1/5: 100%|██████████| 1000/1000 [1:59:12<00:00,  7.15s/it, loss=2.3927]\n","Epoch 1 [VAL]: 100%|██████████| 125/125 [06:23<00:00,  3.07s/it]\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'total_train_loss' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3472167155.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# --- 5. START TRAINING ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-3472167155.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Calculate averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mavg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mavg_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_val_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'total_train_loss' is not defined"]}]},{"cell_type":"code","source":["# Run this immediately to save the model currently in memory\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/FYP_Full_Project/model_epoch_1.pth\")\n","print(\"✅ Epoch 1 weights saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVzrW3nUl60n","executionInfo":{"status":"ok","timestamp":1768731173327,"user_tz":-330,"elapsed":9275,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"eb4b681d-f1c4-4457-b22c-47adfe4586ce"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Epoch 1 weights saved successfully!\n"]}]},{"cell_type":"markdown","source":["EMOTION BOOST"],"metadata":{"id":"U4GHuG3yR6P1"}},{"cell_type":"code","source":["class VideoFeatureDataset(Dataset):\n","    def __init__(self, csv_path, feature_dir, tokenizer, partition=\"train\"):\n","        self.df = pd.read_csv(csv_path)\n","        self.feature_dir = feature_dir\n","        self.tokenizer = tokenizer\n","        self.partition = partition\n","\n","        # Find only the batch files that actually exist\n","        self.existing_batches = []\n","        expected_count = 80 if partition == \"train\" else 10\n","        for i in range(expected_count):\n","            if os.path.exists(f\"{feature_dir}/{partition}_batch_{i}.pt\"):\n","                self.existing_batches.append(i)\n","        print(f\"✅ {partition.upper()}: Found {len(self.existing_batches)}/ {expected_count} batches.\")\n","\n","    def __len__(self):\n","        return len(self.existing_batches) * 100\n","\n","    def __getitem__(self, idx):\n","        try:\n","            batch_idx = self.existing_batches[idx // 100]\n","            inner_idx = idx % 100\n","\n","            # 1. Load the batch file\n","            features_list = torch.load(f\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\")\n","\n","            # 2. Extract the specific item\n","            if isinstance(features_list, tuple):\n","                features_list = features_list[0]\n","\n","            visual_data = features_list[inner_idx]\n","\n","            # --- NEW SAFETY CHECK: Handle NoneType ---\n","            if visual_data is None:\n","                # Return zeros if data is missing so the loop doesn't crash\n","                visual_feat = torch.zeros(2304)\n","                # Return an empty/padding caption\n","                return visual_feat, torch.zeros(20, dtype=torch.long)\n","\n","            # 3. UNIVERSAL EXTRACTION\n","            if isinstance(visual_data, dict):\n","                act = visual_data.get('act', torch.zeros(1)).flatten().float()\n","                emo = visual_data.get('emo', torch.zeros(1)).flatten().float()\n","                obj = visual_data.get('obj', torch.zeros(1)).flatten().float()\n","            elif isinstance(visual_data, (list, tuple)):\n","                act = visual_data[0].flatten().float()\n","                emo = visual_data[1].flatten().float()\n","                obj = visual_data[2].flatten().float()\n","            else:\n","                # Fallback for unexpected formats\n","                visual_feat = torch.zeros(2304)\n","                return visual_feat, torch.zeros(20, dtype=torch.long)\n","\n","            # 4. APPLY THE BOOSTER\n","            emo = emo * 5.0\n","            obj = obj * 2.0\n","\n","            # 5. Concatenate\n","            visual_feat = torch.cat([act, emo, obj])\n","\n","            # 6. Size check (2304)\n","            detected_dim = 2304\n","            if visual_feat.shape[0] != detected_dim:\n","                padding = torch.zeros(max(0, detected_dim - visual_feat.shape[0]))\n","                visual_feat = torch.cat([visual_feat, padding])[:detected_dim]\n","\n","            # 7. Tokenize\n","            caption = self.df.iloc[batch_idx * 100 + inner_idx]['caption']\n","            tokens = self.tokenizer(caption, truncation=True, padding='max_length',\n","                                    max_length=20, return_tensors=\"pt\")\n","\n","            return visual_feat, tokens['input_ids'].squeeze(0)\n","\n","        except Exception as e:\n","            # If anything else goes wrong, return a zero vector to keep the GPU busy\n","            return torch.zeros(2304), torch.zeros(20, dtype=torch.long)"],"metadata":{"id":"24MzhRaZQ47m","executionInfo":{"status":"ok","timestamp":1768759359472,"user_tz":-330,"elapsed":18,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch\n","import os\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# --- 1. RE-INITIALIZE DATA WITH THE BOOSTER ---\n","# Ensure you have already run the cell containing your updated VideoFeatureDataset class!\n","train_ds = VideoFeatureDataset(CSV_PATH, FEATURE_DIR, tokenizer, \"train\")\n","train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n","\n","val_ds = VideoFeatureDataset(VAL_CSV_PATH, FEATURE_DIR, tokenizer, \"val\")\n","val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n","\n","# --- 2. SANITY CHECK: Confirm Booster is Active ---\n","sample_feat, _ = train_ds[0]\n","print(f\"🔍 Feature Check: Max value in vector: {sample_feat.max().item():.2f}\")\n","print(\"💡 (If this is > 1.0, your Emotion/Object multipliers are working!)\")\n","\n","# --- 3. LOAD SAVED WEIGHTS ---\n","EPOCH_1_PATH = \"/content/drive/MyDrive/FYP_Full_Project/model_epoch_1.pth\"\n","\n","if os.path.exists(EPOCH_1_PATH):\n","    # Map location ensures it loads correctly even if trained on different hardware\n","    model.load_state_dict(torch.load(EPOCH_1_PATH, map_location=DEVICE))\n","    print(\"✅ Successfully loaded Epoch 1 weights. Ready for Epoch 2.\")\n","else:\n","    print(\"⚠️ Warning: Epoch 1 file not found. Please check your Drive path!\")\n","\n","# --- 4. THE UPDATED TRAINING LOOP ---\n","def train_model_resume(model, train_loader, val_loader, optimizer, start_epoch, total_epochs):\n","    train_loss_history = []\n","    val_loss_history = []\n","\n","    for epoch in range(start_epoch, total_epochs + 1):\n","        # --- TRAINING PHASE ---\n","        model.train()\n","        total_train_loss = 0 # Fixed name here\n","        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{total_epochs} [TRAIN]\")\n","\n","        for visual_feats, input_ids in progress_bar:\n","            visual_feats = visual_feats.to(DEVICE).float()\n","            input_ids = input_ids.to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            outputs = model(visual_feats, input_ids, labels=input_ids)\n","\n","            loss = outputs.loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n","\n","        # --- VALIDATION PHASE ---\n","        model.eval()\n","        total_val_loss = 0\n","        with torch.no_grad():\n","            for v_feats, v_ids in tqdm(val_loader, desc=f\"Epoch {epoch} [VAL]\"):\n","                v_feats = v_feats.to(DEVICE).float()\n","                v_ids = v_ids.to(DEVICE)\n","                v_outputs = model(v_feats, v_ids, labels=v_ids)\n","                total_val_loss += v_outputs.loss.item()\n","\n","        # Calculate Averages (Fixed variable names)\n","        avg_train = total_train_loss / len(train_loader)\n","        avg_val = total_val_loss / len(val_loader)\n","\n","        train_loss_history.append(avg_train)\n","        val_loss_history.append(avg_val)\n","\n","        print(f\"\\n📊 Epoch {epoch} Summary:\")\n","        print(f\"   Avg Train Loss: {avg_train:.4f}\")\n","        print(f\"   Avg Val Loss:   {avg_val:.4f}\")\n","\n","        # --- SAVE CHECKPOINT ---\n","        save_path = f\"/content/drive/MyDrive/FYP_Full_Project/model_epoch_{epoch}.pth\"\n","        torch.save(model.state_dict(), save_path)\n","        print(f\"💾 Checkpoint saved: {save_path}\")\n","        print(\"-\" * 30)\n","\n","    return train_loss_history, val_loss_history\n","\n","# --- 5. EXECUTE ---\n","# Using 5e-5 for a more stable learning process now that we have a baseline\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n","\n","# Run the training and capture history\n","history_train, history_val = train_model_resume(\n","    model,\n","    train_loader,\n","    val_loader,\n","    optimizer,\n","    start_epoch=2,\n","    total_epochs=5\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":966},"id":"DBW8hSxRQvHq","executionInfo":{"status":"error","timestamp":1768755447685,"user_tz":-330,"elapsed":22988296,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"9d9c5c6a-dc7a-4481-b0e6-23364c153e56"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ TRAIN: Found 80/ 80 batches.\n","✅ VAL: Found 10/ 10 batches.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2637933326.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  features_list = torch.load(f\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\")\n"]},{"output_type":"stream","name":"stdout","text":["🔍 Feature Check: Max value in vector: 12.82\n","💡 (If this is > 1.0, your Emotion/Object multipliers are working!)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-255861148.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(EPOCH_1_PATH, map_location=DEVICE))\n"]},{"output_type":"stream","name":"stdout","text":["✅ Successfully loaded Epoch 1 weights. Ready for Epoch 2.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 [TRAIN]: 100%|██████████| 1000/1000 [2:01:27<00:00,  7.29s/it, loss=1.7378]\n","Epoch 2 [VAL]: 100%|██████████| 125/125 [05:49<00:00,  2.80s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","📊 Epoch 2 Summary:\n","   Avg Train Loss: 1.7049\n","   Avg Val Loss:   1.7999\n","💾 Checkpoint saved: /content/drive/MyDrive/FYP_Full_Project/model_epoch_2.pth\n","------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 [TRAIN]: 100%|██████████| 1000/1000 [2:01:23<00:00,  7.28s/it, loss=1.7767]\n","Epoch 3 [VAL]: 100%|██████████| 125/125 [05:53<00:00,  2.83s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","📊 Epoch 3 Summary:\n","   Avg Train Loss: 1.5632\n","   Avg Val Loss:   1.7966\n","💾 Checkpoint saved: /content/drive/MyDrive/FYP_Full_Project/model_epoch_3.pth\n","------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 [TRAIN]: 100%|██████████| 1000/1000 [2:01:53<00:00,  7.31s/it, loss=1.5519]\n","Epoch 4 [VAL]: 100%|██████████| 125/125 [05:59<00:00,  2.88s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","📊 Epoch 4 Summary:\n","   Avg Train Loss: 1.4418\n","   Avg Val Loss:   1.8494\n","💾 Checkpoint saved: /content/drive/MyDrive/FYP_Full_Project/model_epoch_4.pth\n","------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 [TRAIN]:   0%|          | 1/1000 [00:20<5:36:50, 20.23s/it, loss=1.2947]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-255861148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# Run the training and capture history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m history_train, history_val = train_model_resume(\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-255861148.py\u001b[0m in \u001b[0;36mtrain_model_resume\u001b[0;34m(model, train_loader, val_loader, optimizer, start_epoch, total_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{total_epochs} [TRAIN]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvisual_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mvisual_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisual_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2637933326.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# 1. Load the batch file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mfeatures_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# 2. Extract the specific item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[0;31m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstorage_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m         \u001b[0;31m# swap here if byteswapping is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbyteorderdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Unfreeze GPT model"],"metadata":{"id":"b3tQKs_moEfv"}},{"cell_type":"code","source":["import gc\n","del model\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"r0eyfghWD8GW","executionInfo":{"status":"error","timestamp":1768759365663,"user_tz":-330,"elapsed":10,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"b3e29be9-0be3-4678-eabf-3ddb566b16b2"},"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3101329110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["class VideoGPT2Captioner(nn.Module):\n","    def __init__(self, visual_dim=2304, gpt2_dim=768):\n","        super().__init__()\n","        self.gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n","        self.projection = nn.Linear(visual_dim, gpt2_dim)\n","\n","    def forward(self, visual_features, input_ids):\n","        visual_embeds = self.projection(visual_features).unsqueeze(1)\n","        text_embeds = self.gpt2.transformer.wte(input_ids)\n","        full_embeds = torch.cat((visual_embeds, text_embeds), dim=1)\n","\n","        # We MUST pass labels=input_ids for GPT2 to return a loss\n","        # We pad the labels with -100 so it ignores the visual feature during grading\n","        ignore_label = torch.full((visual_features.size(0), 1), -100, device=DEVICE)\n","        full_labels = torch.cat((ignore_label, input_ids), dim=1)\n","\n","        return self.gpt2(inputs_embeds=full_embeds, labels=full_labels)"],"metadata":{"id":"WPvK_shSDs45","executionInfo":{"status":"ok","timestamp":1768759378308,"user_tz":-330,"elapsed":30,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 1. Re-init\n","model = VideoGPT2Captioner(visual_dim=2304).to(DEVICE)\n","\n","# 2. Load Weights\n","EPOCH_4_PATH = \"/content/drive/MyDrive/FYP_Full_Project/model_epoch_4.pth\"\n","model.load_state_dict(torch.load(EPOCH_4_PATH, map_location=DEVICE))\n","\n","# 3. Apply Unfreeze Logic\n","for param in model.gpt2.parameters():\n","    param.requires_grad = False\n","model.gpt2.transformer.wte.requires_grad_(True)\n","model.gpt2.lm_head.requires_grad_(True)\n","\n","# 4. Re-init Optimizer\n","optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n","\n","print(\"✅ Model Re-initialized with Correct Loss Logic and Epoch 4 Weights.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["08f7c995bc274ca4924cf81d54731dec","7baed78306294770a7c6410e25f427d6","65e80bd55b6d4e69a682271a01b84aee","2877a356e0424d279c2a54a908f06c89","dcddb2f6b264454d9d2fe5e0132ed521","97d62a0ebadb4f33aab6b1e0f59c1b6c","f367e77914854c48a7b21bc16c08b7f8","3a2376d4c37443bda9187318674a0120","d07d5b73f3d64b7d8ab2fcc270d548c0","a9c4d877842f400db4b472eaf64b4da5","ff77e58e10dc4899a448314d78826cf3","c90ae423e36d43f1bafb17c9458b7fb8","9405c1dd6b9e45f099e2f5eaf1806b5f","d6bd070675bf4487b4bc142c8095966b","24914002f514449681798fde963246c3","ea7976f2eb4d4344be819a5560e25bb1","6c3f4bfb35264bf1956023dfcf04bf43","4b8d71996fbe4ba4a40b0b2442e2704d","d78de0e7c4f645c8986c3b6b91a80d82","849a6bddd42f4dacbc432b34e2640e81","ccf3c7c8b4ac4ae5a0c8e554fcbb4ed0","23fad8ef4b3c4da0b61b5f29125e2d19"]},"id":"J24lZpSGoBaO","executionInfo":{"status":"ok","timestamp":1768759397806,"user_tz":-330,"elapsed":15689,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"fe8170f9-8935-4669-fba1-51292c5e3a24"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f7c995bc274ca4924cf81d54731dec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90ae423e36d43f1bafb17c9458b7fb8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2112170188.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(EPOCH_4_PATH, map_location=DEVICE))\n"]},{"output_type":"stream","name":"stdout","text":["✅ Model Re-initialized with Correct Loss Logic and Epoch 4 Weights.\n"]}]},{"cell_type":"code","source":["train_ds = VideoFeatureDataset(CSV_PATH, FEATURE_DIR, tokenizer, \"train\")\n","train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n","\n","val_ds = VideoFeatureDataset(VAL_CSV_PATH, FEATURE_DIR, tokenizer, \"val\")\n","val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n","\n","# We only need one more epoch with these settings to see the difference\n","num_epochs = 1\n","model.train()\n","\n","print(\"🚀 Starting Final Epoch 5 (Fine-Tuning)...\")\n","\n","for epoch in range(num_epochs):\n","    total_train_loss = 0\n","    model.train()\n","\n","    for batch_idx, (visual_feats, captions) in enumerate(train_loader):\n","        visual_feats = visual_feats.to(DEVICE)\n","        captions = captions.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","\n","        # --- FIX IS HERE ---\n","        # We must pass BOTH visual features and labels to get the loss\n","        outputs = model(visual_feats, captions)\n","\n","        # Double check that loss exists\n","        if outputs.loss is None:\n","            print(f\"Error: Loss is None at batch {batch_idx}\")\n","            continue\n","\n","        loss = outputs.loss\n","        loss.backward()\n","\n","        # Safety line\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        optimizer.step()\n","\n","        total_train_loss += loss.item()\n","\n","        if batch_idx % 50 == 0:\n","            print(f\"Epoch 5 | Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n","\n","    avg_loss = total_train_loss / len(train_loader)\n","    print(f\"✅ Final Epoch 5 Training Complete. Avg Loss: {avg_loss:.4f}\")\n","\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/FYP_Full_Project/model_final_v5.pth\")\n","    print(\"💾 FINAL MODEL SAVED: model_final_v5.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTbLH94GoCTM","executionInfo":{"status":"ok","timestamp":1768766627710,"user_tz":-330,"elapsed":7084363,"user":{"displayName":"Akindu Gunarathna","userId":"01658744784784582850"}},"outputId":"487a38da-98b6-4d69-e1a0-590e1a04c6a0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ TRAIN: Found 80/ 80 batches.\n","✅ VAL: Found 10/ 10 batches.\n","🚀 Starting Final Epoch 5 (Fine-Tuning)...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2637933326.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  features_list = torch.load(f\"{self.feature_dir}/{self.partition}_batch_{batch_idx}.pt\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Batch 0/1000 | Loss: 1.1606\n","Epoch 5 | Batch 50/1000 | Loss: 1.2483\n","Epoch 5 | Batch 100/1000 | Loss: 1.4520\n","Epoch 5 | Batch 150/1000 | Loss: 1.2944\n","Epoch 5 | Batch 200/1000 | Loss: 1.2711\n","Epoch 5 | Batch 250/1000 | Loss: 1.2074\n","Epoch 5 | Batch 300/1000 | Loss: 1.0169\n","Epoch 5 | Batch 350/1000 | Loss: 1.1870\n","Epoch 5 | Batch 400/1000 | Loss: 1.4653\n","Epoch 5 | Batch 450/1000 | Loss: 1.3538\n","Epoch 5 | Batch 500/1000 | Loss: 1.2525\n","Epoch 5 | Batch 550/1000 | Loss: 1.2262\n","Epoch 5 | Batch 600/1000 | Loss: 1.4419\n","Epoch 5 | Batch 650/1000 | Loss: 1.2030\n","Epoch 5 | Batch 700/1000 | Loss: 1.3632\n","Epoch 5 | Batch 750/1000 | Loss: 1.2216\n","Epoch 5 | Batch 800/1000 | Loss: 1.2966\n","Epoch 5 | Batch 850/1000 | Loss: 1.3287\n","Epoch 5 | Batch 900/1000 | Loss: 1.2632\n","Epoch 5 | Batch 950/1000 | Loss: 1.4311\n","✅ Final Epoch 5 Training Complete. Avg Loss: 1.2829\n","💾 FINAL MODEL SAVED: model_final_v5.pth\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_training_results(train_losses, val_losses, start_epoch=2):\n","    plt.figure(figsize=(10, 6))\n","\n","    # Create the X-axis range based on the start_epoch\n","    epochs = range(start_epoch, start_epoch + len(train_losses))\n","\n","    plt.plot(epochs, train_losses, label='Training Loss', marker='o', linewidth=2, color='royalblue')\n","    plt.plot(epochs, val_losses, label='Validation Loss', marker='s', linewidth=2, color='orange')\n","\n","    # Customizing the look for a professional report\n","    plt.title('Video Captioning Training Progress (Phase 2: Emotion Boost)', fontsize=14, pad=15)\n","    plt.xlabel('Epoch', fontsize=12)\n","    plt.ylabel('Loss (CrossEntropy)', fontsize=12)\n","    plt.xticks(epochs) # Ensures only integer epoch numbers show\n","    plt.legend()\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","\n","    # Background color for better visibility\n","    plt.gca().set_facecolor('#f9f9f9')\n","\n","    # Save the figure with a high-quality name\n","    plt.savefig('emotion_boost_training_curve.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","    print(\"✅ Plot saved as 'emotion_boost_training_curve.png'\")\n","\n","# --- RUN THIS AFTER TRAINING FINISHES ---\n","# We use the 'history_train' and 'history_val' returned by your resume function\n","plot_training_results(history_train, history_val, start_epoch=2)"],"metadata":{"id":"J-gg9SRaSbEO"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3pCzl4o4iIKlU1QySxNrW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cf5b65284d3645bc9f60d3d8866e5779":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2da89dfa9dfd482e8c763527d6d522d2","IPY_MODEL_70ab6aa6610746b886c91032c9bcfddc","IPY_MODEL_1ef11ae64cef41309043bdb4629c01b2"],"layout":"IPY_MODEL_01d8c86dafd2409fb4eb36a73fbaf6e6"}},"2da89dfa9dfd482e8c763527d6d522d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4548f9ff3542488c93d0a63aea398489","placeholder":"​","style":"IPY_MODEL_8d4d338d585e4db18b4d0f35bd249fb5","value":"preprocessor_config.json: 100%"}},"70ab6aa6610746b886c91032c9bcfddc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72fb189bda954e19b67a586147f7f4e8","max":271,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38992c448bc44d9da84585412251cfcc","value":271}},"1ef11ae64cef41309043bdb4629c01b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d79c5063973d467b9ab36009e0ea1137","placeholder":"​","style":"IPY_MODEL_20717987484f4234a603ebbb7504c697","value":" 271/271 [00:00&lt;00:00, 20.5kB/s]"}},"01d8c86dafd2409fb4eb36a73fbaf6e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4548f9ff3542488c93d0a63aea398489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d4d338d585e4db18b4d0f35bd249fb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72fb189bda954e19b67a586147f7f4e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38992c448bc44d9da84585412251cfcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d79c5063973d467b9ab36009e0ea1137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20717987484f4234a603ebbb7504c697":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57ba33909e0c434ebdb0a9f5ee7dd6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f18a078505eb45de992761e8bd88b8f9","IPY_MODEL_afdd17d14e8847b2b59990ef1b4bf311","IPY_MODEL_07525ba48a10412fb9a337b0fb226037"],"layout":"IPY_MODEL_0016ff00e986491e8c47d66638781e78"}},"f18a078505eb45de992761e8bd88b8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2065dea7dd6d47cab8a5952f03addd6f","placeholder":"​","style":"IPY_MODEL_c797ca43975c4e31869c0f19625da270","value":"config.json: 100%"}},"afdd17d14e8847b2b59990ef1b4bf311":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_609bc9d983fd402e904d5c35a263ec48","max":725,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa2d26fd38644a38a30747b66bfa14f9","value":725}},"07525ba48a10412fb9a337b0fb226037":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1af8a2a513f6403ab184ee60d6865e29","placeholder":"​","style":"IPY_MODEL_d2d766e311604d168df7527a280278eb","value":" 725/725 [00:00&lt;00:00, 57.7kB/s]"}},"0016ff00e986491e8c47d66638781e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2065dea7dd6d47cab8a5952f03addd6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c797ca43975c4e31869c0f19625da270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"609bc9d983fd402e904d5c35a263ec48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa2d26fd38644a38a30747b66bfa14f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1af8a2a513f6403ab184ee60d6865e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2d766e311604d168df7527a280278eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7077c542b96c4f9f91d0d7a2dd3919df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1c2bf2514a647e4bbaa88084aa43fd6","IPY_MODEL_eb36c45d0a9c4f0ca827b1febd9a3cbd","IPY_MODEL_7f5103c79a604749b7ecce1230cc9d22"],"layout":"IPY_MODEL_9338ded922d748aa99eec866d6a637a1"}},"d1c2bf2514a647e4bbaa88084aa43fd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b83207a688648489704024bd13d552c","placeholder":"​","style":"IPY_MODEL_7efffc19c18d4314a5e6edad83141520","value":"model.safetensors: 100%"}},"eb36c45d0a9c4f0ca827b1febd9a3cbd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91c60acdf7834496946507a1b3cb1d6a","max":376873760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a1d13602aa2411785ffb502c7fd7ce1","value":376873760}},"7f5103c79a604749b7ecce1230cc9d22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6cdf1a2880c4a9ba9c107c2d48f0417","placeholder":"​","style":"IPY_MODEL_11631777d890407c9a0943653b4a3a57","value":" 377M/377M [00:04&lt;00:00, 135MB/s]"}},"9338ded922d748aa99eec866d6a637a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b83207a688648489704024bd13d552c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7efffc19c18d4314a5e6edad83141520":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91c60acdf7834496946507a1b3cb1d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a1d13602aa2411785ffb502c7fd7ce1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6cdf1a2880c4a9ba9c107c2d48f0417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11631777d890407c9a0943653b4a3a57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d82bde4bc0b44e3bf50cb6f7fa3add7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dc272fde4e24634a48cf11fd4bc7aa8","IPY_MODEL_248e1477f1d049609af864ab19af33bb","IPY_MODEL_748dce86fd444d42a50c7da040895d09"],"layout":"IPY_MODEL_54218444600b477991b68f36585010d9"}},"9dc272fde4e24634a48cf11fd4bc7aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c52ce6957f14e579905f5cf753e9d1f","placeholder":"​","style":"IPY_MODEL_9446f400b55f439ea691406510882071","value":"preprocessor_config.json: 100%"}},"248e1477f1d049609af864ab19af33bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bea4488d21a4f4bb2bb40e035ab469b","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d841b0a28c3f441a90ad9f3b13a75316","value":160}},"748dce86fd444d42a50c7da040895d09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_473d6058ce5a4a21aedd834eb342a67e","placeholder":"​","style":"IPY_MODEL_cb0b62e7edc5471b8bcce959517f30f7","value":" 160/160 [00:00&lt;00:00, 13.9kB/s]"}},"54218444600b477991b68f36585010d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c52ce6957f14e579905f5cf753e9d1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9446f400b55f439ea691406510882071":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bea4488d21a4f4bb2bb40e035ab469b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d841b0a28c3f441a90ad9f3b13a75316":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"473d6058ce5a4a21aedd834eb342a67e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb0b62e7edc5471b8bcce959517f30f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ee2857e3384793bd89aed5345d269f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_131b039da5e04c73b4881d8901008234","IPY_MODEL_5d2e3b5a4bac47ca8fa118313199cd97","IPY_MODEL_15c0a64ec57f46e4981e04f2563fcc4e"],"layout":"IPY_MODEL_ba4b0d89932e4e51b2910801d6d1ff0c"}},"131b039da5e04c73b4881d8901008234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0d26d1e66f34003a4b69f0847d0f651","placeholder":"​","style":"IPY_MODEL_ea00954c603b456eba7d5d6ac5ccd55e","value":"config.json: "}},"5d2e3b5a4bac47ca8fa118313199cd97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_493e30a612c94ffda684d8f54335c761","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c5235515afa4653a3bd855167eb1f0e","value":1}},"15c0a64ec57f46e4981e04f2563fcc4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb121d48ae34e60994776bdaed0992b","placeholder":"​","style":"IPY_MODEL_ba52b095abd64fb999b8201281552a21","value":" 69.7k/? [00:00&lt;00:00, 1.86MB/s]"}},"ba4b0d89932e4e51b2910801d6d1ff0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0d26d1e66f34003a4b69f0847d0f651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea00954c603b456eba7d5d6ac5ccd55e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"493e30a612c94ffda684d8f54335c761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8c5235515afa4653a3bd855167eb1f0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aeb121d48ae34e60994776bdaed0992b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba52b095abd64fb999b8201281552a21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a630fcc600674919bc05ef87afb2bc79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d46ff6f4be2e42eca8857f70f853bfbf","IPY_MODEL_51774a35c2c14c99911f1bec4e6871a9","IPY_MODEL_b0af730271554f27a9d192163346f559"],"layout":"IPY_MODEL_43da26795961453db03dca61e0648b27"}},"d46ff6f4be2e42eca8857f70f853bfbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5fe6d18056d4a4da75aaa5148ba8f8f","placeholder":"​","style":"IPY_MODEL_0234ce25b4ff4565aecb990f57ce22be","value":"model.safetensors: 100%"}},"51774a35c2c14c99911f1bec4e6871a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_648b4c02ed494abd8f4eefd87a3029cf","max":346293852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fefa9250949249be9fa598300db24c11","value":346293852}},"b0af730271554f27a9d192163346f559":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_515c0c394531452ab4cc916bcb9c5f47","placeholder":"​","style":"IPY_MODEL_7e552a279bc44e719a3b9503e234109a","value":" 346M/346M [00:04&lt;00:00, 157MB/s]"}},"43da26795961453db03dca61e0648b27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5fe6d18056d4a4da75aaa5148ba8f8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0234ce25b4ff4565aecb990f57ce22be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"648b4c02ed494abd8f4eefd87a3029cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fefa9250949249be9fa598300db24c11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"515c0c394531452ab4cc916bcb9c5f47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e552a279bc44e719a3b9503e234109a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0d75c690c0c4a2fa20e7b3151b78671":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30cbd499c196402d93b76b62cd2cc543","IPY_MODEL_ba6f1ba468b743bb8d389c972ad3d99b","IPY_MODEL_393dccab3a9e4bb2bece830fc778c43a"],"layout":"IPY_MODEL_903a435c419b474ebe92eed97435931f"}},"30cbd499c196402d93b76b62cd2cc543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_988784c78cdd4ccbbdc125e75ce9f2d8","placeholder":"​","style":"IPY_MODEL_bc0e9ab8173b4423a4b42d3f44665351","value":" 30%"}},"ba6f1ba468b743bb8d389c972ad3d99b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d22ce1c20774dcb9149113e4d2c1b06","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0ba88a367f34595aa25c6867f82e50b","value":305}},"393dccab3a9e4bb2bece830fc778c43a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf4336f78c154d80ae479b88a050c09e","placeholder":"​","style":"IPY_MODEL_0003f2ae5e7e4180bb52bee51b457098","value":" 305/1000 [51:44&lt;2:00:22, 10.39s/it]"}},"903a435c419b474ebe92eed97435931f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"988784c78cdd4ccbbdc125e75ce9f2d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc0e9ab8173b4423a4b42d3f44665351":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d22ce1c20774dcb9149113e4d2c1b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ba88a367f34595aa25c6867f82e50b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf4336f78c154d80ae479b88a050c09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0003f2ae5e7e4180bb52bee51b457098":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfbfce0ebfd446bf978640dca59946a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd80dcfaa8ea4cb98614d33371e1118c","IPY_MODEL_0862b87ad5b844a6a21d79357a3835b1","IPY_MODEL_fe1dd68ec501400e8d067dfc0c94ec49"],"layout":"IPY_MODEL_1289c9f56ba642cc8bb70e20612a09e4"}},"fd80dcfaa8ea4cb98614d33371e1118c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d516a9ba9a04e46b8793db3de2dcfd5","placeholder":"​","style":"IPY_MODEL_66945552bb2449e582cf106d039afb4b","value":"preprocessor_config.json: 100%"}},"0862b87ad5b844a6a21d79357a3835b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1531534ac77a4ad4945ace8a93a7bbd7","max":271,"min":0,"orientation":"horizontal","style":"IPY_MODEL_105a9a2de49d4238a0b91bc764b78fb1","value":271}},"fe1dd68ec501400e8d067dfc0c94ec49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_212bbf48e47c4696aa23b7a9a85abdc5","placeholder":"​","style":"IPY_MODEL_b03fdff47d57471d9702e46e40fcf6f7","value":" 271/271 [00:00&lt;00:00, 23.6kB/s]"}},"1289c9f56ba642cc8bb70e20612a09e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d516a9ba9a04e46b8793db3de2dcfd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66945552bb2449e582cf106d039afb4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1531534ac77a4ad4945ace8a93a7bbd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"105a9a2de49d4238a0b91bc764b78fb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"212bbf48e47c4696aa23b7a9a85abdc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b03fdff47d57471d9702e46e40fcf6f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fbcc22aa7e144f89b2ab43d7a93012f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c2069c0e09c4f779ec64cb7bcbf91c6","IPY_MODEL_1671f828d3244085a686da43db41b358","IPY_MODEL_2a125fd3aee44217a0643178567af3e3"],"layout":"IPY_MODEL_6299af09540045afb38a7914141b23dd"}},"2c2069c0e09c4f779ec64cb7bcbf91c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_154ae141622b4c62851ac21673f66094","placeholder":"​","style":"IPY_MODEL_259cf34a4f4a48eb82b2865acb8b7b20","value":"config.json: 100%"}},"1671f828d3244085a686da43db41b358":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9590274916e74d439aa3f06a1644131d","max":725,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dde1420078b482d90cb40195fd3335e","value":725}},"2a125fd3aee44217a0643178567af3e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26a9df2da9e74c7285f1b7aad33caf25","placeholder":"​","style":"IPY_MODEL_239e5873f5c44f2fa64f8b7b2ee0f454","value":" 725/725 [00:00&lt;00:00, 60.3kB/s]"}},"6299af09540045afb38a7914141b23dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"154ae141622b4c62851ac21673f66094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"259cf34a4f4a48eb82b2865acb8b7b20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9590274916e74d439aa3f06a1644131d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dde1420078b482d90cb40195fd3335e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26a9df2da9e74c7285f1b7aad33caf25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"239e5873f5c44f2fa64f8b7b2ee0f454":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fe17b601b85454b93c173cbf0c5a670":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a12283985e7043049777cfb676190f93","IPY_MODEL_6168c2d759b646e2b09cdc4308ef5345","IPY_MODEL_e70bc72359964c8d8aa5ad9c84215604"],"layout":"IPY_MODEL_66ab41b2f40d4bbb96131d34b8d9584a"}},"a12283985e7043049777cfb676190f93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08694a8765c44deca14a65ec8301ce7b","placeholder":"​","style":"IPY_MODEL_bfc885c856a34becbf978b81cc62306b","value":"model.safetensors: 100%"}},"6168c2d759b646e2b09cdc4308ef5345":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b4c19ea4ec340bd9bbb44f91a50483f","max":376873760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_710b973b8fc343af8c3bf23e94ac1c39","value":376873760}},"e70bc72359964c8d8aa5ad9c84215604":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_309807a8f2d64510a84b5d9a09025f99","placeholder":"​","style":"IPY_MODEL_a80425041f21449d918fc9ec55e96153","value":" 377M/377M [00:06&lt;00:00, 154MB/s]"}},"66ab41b2f40d4bbb96131d34b8d9584a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08694a8765c44deca14a65ec8301ce7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfc885c856a34becbf978b81cc62306b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b4c19ea4ec340bd9bbb44f91a50483f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"710b973b8fc343af8c3bf23e94ac1c39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"309807a8f2d64510a84b5d9a09025f99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a80425041f21449d918fc9ec55e96153":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87997d482d0c475d8376d1946edc1b2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49e06f79585746ac9d17d7535299b05e","IPY_MODEL_cfc7b177da2d4a0dac7d0b897e416c65","IPY_MODEL_15dcdce983814350ab9c107a44ec31c6"],"layout":"IPY_MODEL_e81d4602ae194598b079679b967e4cbc"}},"49e06f79585746ac9d17d7535299b05e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b11c5385a3d54bb199baafef90c97402","placeholder":"​","style":"IPY_MODEL_ec966b71db7f45a9a2f435f7af3d09fd","value":"preprocessor_config.json: 100%"}},"cfc7b177da2d4a0dac7d0b897e416c65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60ca0f8ecc0450ba761fe77da1fd9ae","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd7a9705c56148c49834369b69afc74a","value":160}},"15dcdce983814350ab9c107a44ec31c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4fc948b2dc54de187ad5b6483829276","placeholder":"​","style":"IPY_MODEL_d65e613faa53410c8f010bb624e333e6","value":" 160/160 [00:00&lt;00:00, 6.66kB/s]"}},"e81d4602ae194598b079679b967e4cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11c5385a3d54bb199baafef90c97402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec966b71db7f45a9a2f435f7af3d09fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b60ca0f8ecc0450ba761fe77da1fd9ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd7a9705c56148c49834369b69afc74a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4fc948b2dc54de187ad5b6483829276":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65e613faa53410c8f010bb624e333e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a60a3f7faea4f4bbcb80289bfbf72c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0466ba3a2a524ff7a647eb21cd3e623b","IPY_MODEL_60e040d6080a482c9bb106dd5e456349","IPY_MODEL_87a834881f4b40f2b78a9f33efb710e1"],"layout":"IPY_MODEL_59e96a53fc464dbb81a21958ef85d195"}},"0466ba3a2a524ff7a647eb21cd3e623b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda257eac70a4d6e9b2b08bc822bfc48","placeholder":"​","style":"IPY_MODEL_f45514bc57074450ada586cbc35d20e5","value":"config.json: "}},"60e040d6080a482c9bb106dd5e456349":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe8dc97a23346cfbcb6374bc11b456b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45eb144e042f489c8a984a10708de259","value":1}},"87a834881f4b40f2b78a9f33efb710e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a10af8322340f6a43c0145b3c9f832","placeholder":"​","style":"IPY_MODEL_f383d9aa3bcf4e279e9b3683fc838ae2","value":" 69.7k/? [00:00&lt;00:00, 4.16MB/s]"}},"59e96a53fc464dbb81a21958ef85d195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda257eac70a4d6e9b2b08bc822bfc48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45514bc57074450ada586cbc35d20e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efe8dc97a23346cfbcb6374bc11b456b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"45eb144e042f489c8a984a10708de259":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55a10af8322340f6a43c0145b3c9f832":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f383d9aa3bcf4e279e9b3683fc838ae2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1384e930c4e1434db2074fa9bb6b2f21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7424170445a4d6b877943a766e09ece","IPY_MODEL_6130e9841d29481faa24728ba1298727","IPY_MODEL_55a040a6ee85475997375e402859c05d"],"layout":"IPY_MODEL_a1cc660fe79a41f280607bdf0fdbba3f"}},"f7424170445a4d6b877943a766e09ece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b2970e51f3c433789840105d1f67796","placeholder":"​","style":"IPY_MODEL_f7223f5ed974438385b3b9a144287f2d","value":"model.safetensors: 100%"}},"6130e9841d29481faa24728ba1298727":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1eb361a38142b3b0ba1ec4d0c18fd7","max":346293852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c1e1bba656e49cd9462f6a8c1775967","value":346293852}},"55a040a6ee85475997375e402859c05d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8b3dd402e5a4ebfabb42b2f967f526b","placeholder":"​","style":"IPY_MODEL_8b477093b7ee48c095a64d69575a14ad","value":" 346M/346M [00:03&lt;00:00, 171MB/s]"}},"a1cc660fe79a41f280607bdf0fdbba3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2970e51f3c433789840105d1f67796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7223f5ed974438385b3b9a144287f2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b1eb361a38142b3b0ba1ec4d0c18fd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1e1bba656e49cd9462f6a8c1775967":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8b3dd402e5a4ebfabb42b2f967f526b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b477093b7ee48c095a64d69575a14ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0b2576b35040208d5f9530b288197c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abf27b26691a4cac9b3c751e80744a50","IPY_MODEL_edd082db81e7433194584aaf5b2d1507","IPY_MODEL_6d028148079f493cb4bc8b72b71a659c"],"layout":"IPY_MODEL_724d5216b77c4603a96e5d9c107ce1a8"}},"abf27b26691a4cac9b3c751e80744a50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_765cbc85ea1e48c2bc07c9fec98fc669","placeholder":"​","style":"IPY_MODEL_c863d4a05be64982b62e0eb85e63f438","value":"tokenizer_config.json: 100%"}},"edd082db81e7433194584aaf5b2d1507":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d96546b76a27492cb9e39e6f0534f471","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8801e91f6cb4c8fa890e7cc2e65bdf3","value":26}},"6d028148079f493cb4bc8b72b71a659c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d3e38e04c2d4e759195d64c584d8cee","placeholder":"​","style":"IPY_MODEL_3ab7681d664e4caeb6946bf6ea5af842","value":" 26.0/26.0 [00:00&lt;00:00, 965B/s]"}},"724d5216b77c4603a96e5d9c107ce1a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"765cbc85ea1e48c2bc07c9fec98fc669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c863d4a05be64982b62e0eb85e63f438":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d96546b76a27492cb9e39e6f0534f471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8801e91f6cb4c8fa890e7cc2e65bdf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d3e38e04c2d4e759195d64c584d8cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ab7681d664e4caeb6946bf6ea5af842":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84e43082860244719316571aca4ddbb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4b1f7cf9a9048428751b7cb9cc20e0b","IPY_MODEL_80552b1636d442cb9e47ea693a76ebbc","IPY_MODEL_d8454da7eec743bcb49d87ce554b215d"],"layout":"IPY_MODEL_a6e491fcb7c84e0ab97a19b526ea4522"}},"d4b1f7cf9a9048428751b7cb9cc20e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d15ea08f188d4e319bf6a3204cda26ba","placeholder":"​","style":"IPY_MODEL_4500fe9b3bc04276bfec2c1c2076e0dc","value":"vocab.json: 100%"}},"80552b1636d442cb9e47ea693a76ebbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bca5eae9bf4a4b5292fc2392cfc6e65f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f166ceb967eb440eb434dd3b6c3a4892","value":1042301}},"d8454da7eec743bcb49d87ce554b215d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee241c4d1a9944bbabf763fabbd0b4b5","placeholder":"​","style":"IPY_MODEL_6d4a3321adbb4e0e9536e691d448ba63","value":" 1.04M/1.04M [00:00&lt;00:00, 2.92MB/s]"}},"a6e491fcb7c84e0ab97a19b526ea4522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15ea08f188d4e319bf6a3204cda26ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4500fe9b3bc04276bfec2c1c2076e0dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bca5eae9bf4a4b5292fc2392cfc6e65f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f166ceb967eb440eb434dd3b6c3a4892":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee241c4d1a9944bbabf763fabbd0b4b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d4a3321adbb4e0e9536e691d448ba63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"193f51dedaa04b2dbc624de98d5f2188":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bca3f3951a0e48b7ab9bddfba6b1bce5","IPY_MODEL_426a21e09cec40d39f0d18aaef577cd4","IPY_MODEL_154a8e740311447eb87352471715a0ee"],"layout":"IPY_MODEL_adadff4440654b8a9ad049a45c9ae184"}},"bca3f3951a0e48b7ab9bddfba6b1bce5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b37b027d71843edbabc8ceb2ce77ae5","placeholder":"​","style":"IPY_MODEL_b15f8c5f25b44cdcbbb8526a10d14da9","value":"merges.txt: 100%"}},"426a21e09cec40d39f0d18aaef577cd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bf99133291d4ca4bd00ea7ef71df8da","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_598bdf4e49324817b8796d1bd01ac879","value":456318}},"154a8e740311447eb87352471715a0ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6a8d904d7764c98be69e327be690383","placeholder":"​","style":"IPY_MODEL_917dfedb9b4040cfab38b2136224dd5e","value":" 456k/456k [00:00&lt;00:00, 2.34MB/s]"}},"adadff4440654b8a9ad049a45c9ae184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b37b027d71843edbabc8ceb2ce77ae5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15f8c5f25b44cdcbbb8526a10d14da9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bf99133291d4ca4bd00ea7ef71df8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"598bdf4e49324817b8796d1bd01ac879":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6a8d904d7764c98be69e327be690383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917dfedb9b4040cfab38b2136224dd5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d341408699241e491cbbee5081e2d8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72a275f78f754886afca81a9a3810139","IPY_MODEL_1e5bcf8e9e71456eab4bb7597414ccce","IPY_MODEL_25830316f6f74e3e8227e4a286ad0e09"],"layout":"IPY_MODEL_80209317bad44dbfbdddc174ced4c9e2"}},"72a275f78f754886afca81a9a3810139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1356946b0864d6f805ada0dcd8e40ca","placeholder":"​","style":"IPY_MODEL_4afe704ac68748e88464e9cffd336981","value":"tokenizer.json: 100%"}},"1e5bcf8e9e71456eab4bb7597414ccce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_887dbd880e424dfab75f2b05b7c42e30","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1b75e592b374e8695b2ff19d17abc83","value":1355256}},"25830316f6f74e3e8227e4a286ad0e09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15557fd7207c4adabf03af195fbf0fb5","placeholder":"​","style":"IPY_MODEL_9e7ec19d068a4385bd68e012ba7bd492","value":" 1.36M/1.36M [00:00&lt;00:00, 4.81MB/s]"}},"80209317bad44dbfbdddc174ced4c9e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1356946b0864d6f805ada0dcd8e40ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afe704ac68748e88464e9cffd336981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"887dbd880e424dfab75f2b05b7c42e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1b75e592b374e8695b2ff19d17abc83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15557fd7207c4adabf03af195fbf0fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7ec19d068a4385bd68e012ba7bd492":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d82d67573624138b2f0c2a0e81e6592":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad3efb6726314dfca4bdbdc72f948b0e","IPY_MODEL_51b21a1a6f36465496c29274e57897bf","IPY_MODEL_8a30fe9b000c416dba87d73ba14a71ec"],"layout":"IPY_MODEL_1f45bc877fda4101a711152e14df58d2"}},"ad3efb6726314dfca4bdbdc72f948b0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_533afb5fea0942af8a6fd2cafdd7fd2b","placeholder":"​","style":"IPY_MODEL_97f99a6e33a044dfab8d9c2adf0fda5d","value":"config.json: 100%"}},"51b21a1a6f36465496c29274e57897bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b331113d474df58dcc18f903a07829","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ef3e88a2181418dbc163d27cc0299ff","value":665}},"8a30fe9b000c416dba87d73ba14a71ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df9e27b00b284e389634c4b99091b28c","placeholder":"​","style":"IPY_MODEL_454b60aab99d490991dc87ed8b54a162","value":" 665/665 [00:00&lt;00:00, 36.2kB/s]"}},"1f45bc877fda4101a711152e14df58d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"533afb5fea0942af8a6fd2cafdd7fd2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f99a6e33a044dfab8d9c2adf0fda5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9b331113d474df58dcc18f903a07829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef3e88a2181418dbc163d27cc0299ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df9e27b00b284e389634c4b99091b28c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"454b60aab99d490991dc87ed8b54a162":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08f7c995bc274ca4924cf81d54731dec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7baed78306294770a7c6410e25f427d6","IPY_MODEL_65e80bd55b6d4e69a682271a01b84aee","IPY_MODEL_2877a356e0424d279c2a54a908f06c89"],"layout":"IPY_MODEL_dcddb2f6b264454d9d2fe5e0132ed521"}},"7baed78306294770a7c6410e25f427d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97d62a0ebadb4f33aab6b1e0f59c1b6c","placeholder":"​","style":"IPY_MODEL_f367e77914854c48a7b21bc16c08b7f8","value":"model.safetensors: 100%"}},"65e80bd55b6d4e69a682271a01b84aee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a2376d4c37443bda9187318674a0120","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d07d5b73f3d64b7d8ab2fcc270d548c0","value":548105171}},"2877a356e0424d279c2a54a908f06c89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9c4d877842f400db4b472eaf64b4da5","placeholder":"​","style":"IPY_MODEL_ff77e58e10dc4899a448314d78826cf3","value":" 548M/548M [00:04&lt;00:00, 233MB/s]"}},"dcddb2f6b264454d9d2fe5e0132ed521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97d62a0ebadb4f33aab6b1e0f59c1b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f367e77914854c48a7b21bc16c08b7f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a2376d4c37443bda9187318674a0120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d07d5b73f3d64b7d8ab2fcc270d548c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9c4d877842f400db4b472eaf64b4da5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff77e58e10dc4899a448314d78826cf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c90ae423e36d43f1bafb17c9458b7fb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9405c1dd6b9e45f099e2f5eaf1806b5f","IPY_MODEL_d6bd070675bf4487b4bc142c8095966b","IPY_MODEL_24914002f514449681798fde963246c3"],"layout":"IPY_MODEL_ea7976f2eb4d4344be819a5560e25bb1"}},"9405c1dd6b9e45f099e2f5eaf1806b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3f4bfb35264bf1956023dfcf04bf43","placeholder":"​","style":"IPY_MODEL_4b8d71996fbe4ba4a40b0b2442e2704d","value":"generation_config.json: 100%"}},"d6bd070675bf4487b4bc142c8095966b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d78de0e7c4f645c8986c3b6b91a80d82","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_849a6bddd42f4dacbc432b34e2640e81","value":124}},"24914002f514449681798fde963246c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf3c7c8b4ac4ae5a0c8e554fcbb4ed0","placeholder":"​","style":"IPY_MODEL_23fad8ef4b3c4da0b61b5f29125e2d19","value":" 124/124 [00:00&lt;00:00, 9.27kB/s]"}},"ea7976f2eb4d4344be819a5560e25bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c3f4bfb35264bf1956023dfcf04bf43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b8d71996fbe4ba4a40b0b2442e2704d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d78de0e7c4f645c8986c3b6b91a80d82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"849a6bddd42f4dacbc432b34e2640e81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccf3c7c8b4ac4ae5a0c8e554fcbb4ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23fad8ef4b3c4da0b61b5f29125e2d19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}